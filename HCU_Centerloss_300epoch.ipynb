{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from tsai.imports import *\n",
    "from tsai.models.layers import *\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import signal\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 12\n",
    "close_num = 12\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "sequence_len = 1000 * 5 # sampling_rate * second\n",
    "overlap = int(sequence_len * 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "\n",
    "for i in range(1, num_class + 1):\n",
    "    file_path_fil = \"./data/BPF/filterd%02d.csv\" % i\n",
    "    file_path_unfil = \"./data/BPF/unfilterd%02d.csv\" % i\n",
    "    data_fil = pd.read_csv(file_path_fil)\n",
    "    data_np_fil = data_fil.to_numpy().flatten()\n",
    "    # df_fil = pd.DataFrame(data_fil)\n",
    "    # data_unfil = pd.read_csv(file_path_unfil)\n",
    "    # df_unfil = pd.DataFrame(data_unfil)\n",
    "\n",
    "    end = len(data_np_fil)\n",
    "    n = 0\n",
    "    n_stop = sequence_len\n",
    "    data_segs = []\n",
    "    while n_stop < end:\n",
    "        n_start = 0 + ((sequence_len - 1) - (overlap - 1)) * n\n",
    "        n_stop = n_start + sequence_len\n",
    "        tmp = []\n",
    "        seg = data_np_fil[n_start:n_stop].copy()\n",
    "        data_segs.append([seg])\n",
    "        n += 1\n",
    "\n",
    "    data_list.append(data_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.37779185, 0.37960583, 0.38139324, ..., 0.00149465, 0.00150279,\n",
       "        0.00151537])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(data_list)):\n",
    "    for j in range(len(data_list[i])):\n",
    "        if i <= close_num:\n",
    "            labels.append(i)\n",
    "        else:\n",
    "            labels.append(close_num + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3657, 1, 5000]), torch.Size([3657]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_list = pd.DataFrame(data_list)\n",
    "tmp = data_df_list.to_numpy().flatten().copy()\n",
    "data_series_list = pd.Series(tmp).dropna()\n",
    "data_np_list = data_series_list.to_numpy().flatten() # tmp => data_np_list\n",
    "labels_np = np.array(labels)\n",
    "for i in reversed(range(len(data_np_list))):\n",
    "    if len(data_np_list[i][0]) != sequence_len: # 決まった長さでないといけない\n",
    "        data_np_list = np.delete(data_np_list, i)\n",
    "        labels_np = np.delete(labels_np, i)\n",
    "data_series_list = pd.Series(data_np_list)\n",
    "labels_series = pd.Series(labels_np)\n",
    "data_tensor_list = torch.tensor(data_series_list)\n",
    "labels_tensor = torch.tensor(labels_series)\n",
    "data_tensor_list.shape, labels_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(Module):\n",
    "    def __init__(self, ni, nf, ks=40, bottleneck=True):\n",
    "        ks = [ks // (2**i) for i in range(3)]\n",
    "        ks = [k if k % 2 != 0 else k - 1 for k in ks]  # ensure odd ks\n",
    "        bottleneck = bottleneck if ni > 1 else False\n",
    "        self.bottleneck = Conv1d(ni, nf, 1, bias=False) if bottleneck else noop\n",
    "        self.convs = nn.ModuleList([Conv1d(nf if bottleneck else ni, nf, k, bias=False) for k in ks])\n",
    "        self.maxconvpool = nn.Sequential(*[nn.MaxPool1d(3, stride=1, padding=1), Conv1d(ni, nf, 1, bias=False)])\n",
    "        self.concat = Concat()\n",
    "        self.bn = BN1d(nf * 4)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x\n",
    "        x = self.bottleneck(input_tensor)\n",
    "        x = self.concat([l(x) for l in self.convs] + [self.maxconvpool(input_tensor)])\n",
    "        return self.act(self.bn(x))\n",
    "\n",
    "\n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionBlock(Module):\n",
    "    def __init__(self, ni, nf=32, residual=True, depth=6, **kwargs):\n",
    "        self.residual, self.depth = residual, depth\n",
    "        self.inception, self.shortcut = nn.ModuleList(), nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            self.inception.append(InceptionModule(ni if d == 0 else nf * 4, nf, **kwargs))\n",
    "            if self.residual and d % 3 == 2: \n",
    "                n_in, n_out = ni if d == 2 else nf * 4, nf * 4\n",
    "                self.shortcut.append(BN1d(n_in) if n_in == n_out else ConvBlock(n_in, n_out, 1, act=None))\n",
    "        self.add = Add()\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inception[d](x)\n",
    "            if self.residual and d % 3 == 2: res = x = self.act(self.add(x, self.shortcut[d//3](res)))\n",
    "        return x\n",
    "\n",
    "    \n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionTime(Module):\n",
    "    def __init__(self, c_in, c_out, seq_len=None, nf=32, nb_filters=None, **kwargs):\n",
    "        nf = ifnone(nf, nb_filters) # for compatibility\n",
    "        self.inceptionblock = InceptionBlock(c_in, nf, **kwargs) # c_in is input channel num of conv1d\n",
    "        self.gap = GAP1d(1)\n",
    "        self.fc = nn.Linear(nf * 4, c_out) # c_out is 1d output size \n",
    "        self.fc_tsne = nn.Linear(nf * 4, 2)\n",
    "        self.two_vecs_train = [] # list is faster in appending\n",
    "        self.two_vecs_test = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inceptionblock(x)\n",
    "        x = self.gap(x)\n",
    "        two_dimensional_vec = self.fc_tsne(x)\n",
    "        if self.training:\n",
    "            self.two_vecs_train.append(two_dimensional_vec.tolist()) # あとでネストしたものをまとめてtensorかndarrayに変換するため\n",
    "        else:\n",
    "            self.two_vecs_test.append(two_dimensional_vec.tolist())\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCU_Dataset(Dataset):\n",
    "    def __init__(self, dataset, labels) -> None:\n",
    "        # super().__init__()\n",
    "        self.radar_heartbeat = dataset\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "          idx = idx.tolist()        \n",
    "        return torch.tensor(self.radar_heartbeat[idx]), self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.radar_heartbeat)\n",
    "\n",
    "\n",
    "dataset = HCU_Dataset(data_tensor_list, labels_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットでラベルが変わる区切りを発見する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18531/2876418290.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.radar_heartbeat[idx]), self.labels[idx]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0105, 0.0106, 0.0106,  ..., 0.0023, 0.0022, 0.0022]],\n",
       "        dtype=torch.float64),\n",
       " tensor(2))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f0cee1d93a3f453c87d2fc7ea34167ba7e841aa689af4edcc0624fd2f7da055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
