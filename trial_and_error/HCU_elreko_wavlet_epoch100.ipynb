{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from tsai.imports import *\n",
    "from tsai.models.layers import *\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import signal\n",
    "from PyEMD import EMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 12\n",
    "close_num = 11 # 11か12か注意（close numを使ってるとこと整合性とれてるか）\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "sequence_len = 250 * 5 # sampling_rate * second\n",
    "overlap = int(sequence_len * 0.3)\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def ecg_filter(data): # data: 1d array\n",
    "    coeffs = pywt.wavedec(data,'db8',level=8)\n",
    "    for i in np.arange(0,1,1):\n",
    "        coeffs[i] = np.zeros_like(coeffs[i]) # 一番初めは最小の解像度の余りらしい\n",
    "        # print(\"coeff length: {}\".format(len(coeffs)))\n",
    "        # print(f\"1: {i}\")\n",
    "    for i in np.arange(-1,-2,-1):\n",
    "        coeffs[i] = np.zeros_like(coeffs[i])\n",
    "        # print(f\"2: {i}\")\n",
    "    # print(coeffs)\n",
    "    renc = pywt.waverec(coeffs, 'db8')    \n",
    "    return renc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(end_idx, sequence_len, overlap, data_list):\n",
    "    \"\"\"\n",
    "    データのセグメンテーションを行う\n",
    "    segmentation(len(data_np_unfil_norm), sequence_len, overlap, data_list)\n",
    "    \"\"\"\n",
    "    seg_list = []\n",
    "\n",
    "    for data in data_list:\n",
    "        n = 0\n",
    "        n_stop = sequence_len\n",
    "        data_segs = []\n",
    "        while n_stop < end_idx:\n",
    "            n_start = 0 + ((sequence_len - 1) - (overlap - 1)) * n\n",
    "            n_stop = n_start + sequence_len\n",
    "            seg = data[n_start:n_stop].copy()\n",
    "            if len(seg) == sequence_len:\n",
    "                data_segs.append([seg])\n",
    "            n += 1\n",
    "        seg_list.append(data_segs)\n",
    "    return seg_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sampling rate 250Hz 5sで1250 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "data_list = []\n",
    "seg_list = []\n",
    "\n",
    "for i in range(1, 12 + 1):\n",
    "    scaler = StandardScaler()\n",
    "    file_path = \"./data/Keio Hospital/distance%02d.csv\" % i\n",
    "    csv = pd.read_csv(file_path)\n",
    "    csv = csv.to_numpy()\n",
    "    csv = scaler.fit_transform(csv)\n",
    "    csv = ecg_filter(csv) # waveletを用いない場合はコメントアウト\n",
    "    scaler = MinMaxScaler()\n",
    "    csv = scaler.fit_transform(csv)\n",
    "\n",
    "    data_list.append(csv[:, 1]) # waveletを用いない場合はコメントアウト\n",
    "    # data_list.append(csv) # waveletを用いる場合はコメントアウト\n",
    "seg_list = segmentation(len(csv), sequence_len, overlap, data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seg_list[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 8 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2290f93f40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "id_test = 0\n",
    "id = ecg_filter(scaler.fit_transform(data_list[id_test]))\n",
    "id4 = ecg_filter(scaler.fit_transform(data_list[3]))\n",
    "id6 = ecg_filter(scaler.fit_transform(data_list[5]))\n",
    "scaler = MinMaxScaler()\n",
    "id = scaler.fit_transform(id)\n",
    "id4 = scaler.fit_transform(id4)\n",
    "id6 = scaler.fit_transform(id6)\n",
    "\n",
    "# ids = [id4[:, 1], id6[:, 1]]\n",
    "# print(len(ids))\n",
    "# corr = np.correlate(id4[:, 1], id6[:, 1], \"full\")\n",
    "# print(corr)\n",
    "\n",
    "# plt.plot(corr, label=\"corr\")\n",
    "plt.plot(id[:, 1], label=\"ID 1\")\n",
    "plt.plot(id4[:, 1], label=\"ID 4\")\n",
    "plt.plot(id6[:, 1], label=\"ID 6\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 1, 1250)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_re = np.reshape(seg_list, (3072, 1, 1250))\n",
    "seg_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(seg_list)):\n",
    "    for j in range(len(seg_list[i])):\n",
    "        if i <= close_num:\n",
    "            labels.append(i)\n",
    "        else:\n",
    "            labels.append(close_num + 1) # for open set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[-1], close_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seg_list[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 1, 1250)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2204223158.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  data_tensor_list = torch.tensor(data_set)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3072, 1, 1250]), torch.Size([3072]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = []\n",
    "# for i in range(len(seg_list)): # waveletありのとき\n",
    "    # data_set.extend(seg_list[i])　\n",
    "for i in range(len(seg_re)): # waveletなしのとき\n",
    "    data_set.append(seg_re[i])\n",
    "\n",
    "data_tensor_list = torch.tensor(data_set)\n",
    "labels_tensor = torch.tensor(labels)\n",
    "data_tensor_list.shape, labels_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(Module):\n",
    "    def __init__(self, ni, nf, ks=40, bottleneck=True):\n",
    "        ks = [ks // (2**i) for i in range(3)]\n",
    "        ks = [k if k % 2 != 0 else k - 1 for k in ks]  # ensure odd ks\n",
    "        bottleneck = bottleneck if ni > 1 else False\n",
    "        self.bottleneck = Conv1d(ni, nf, 1, bias=False) if bottleneck else noop\n",
    "        self.convs = nn.ModuleList([Conv1d(nf if bottleneck else ni, nf, k, bias=False) for k in ks])\n",
    "        self.maxconvpool = nn.Sequential(*[nn.MaxPool1d(3, stride=1, padding=1), Conv1d(ni, nf, 1, bias=False)])\n",
    "        self.concat = Concat()\n",
    "        self.bn = BN1d(nf * 4)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x\n",
    "        x = self.bottleneck(input_tensor)\n",
    "        x = self.concat([l(x) for l in self.convs] + [self.maxconvpool(input_tensor)])\n",
    "        return self.act(self.bn(x))\n",
    "\n",
    "\n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionBlock(Module):\n",
    "    def __init__(self, ni, nf=32, residual=True, depth=6, **kwargs):\n",
    "        self.residual, self.depth = residual, depth\n",
    "        self.inception, self.shortcut = nn.ModuleList(), nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            self.inception.append(InceptionModule(ni if d == 0 else nf * 4, nf, **kwargs))\n",
    "            if self.residual and d % 3 == 2: \n",
    "                n_in, n_out = ni if d == 2 else nf * 4, nf * 4\n",
    "                self.shortcut.append(BN1d(n_in) if n_in == n_out else ConvBlock(n_in, n_out, 1, act=None))\n",
    "        self.add = Add()\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inception[d](x)\n",
    "            if self.residual and d % 3 == 2: res = x = self.act(self.add(x, self.shortcut[d//3](res)))\n",
    "        return x\n",
    "\n",
    "    \n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionTime(Module):\n",
    "    def __init__(self, c_in, c_out, seq_len=None, nf=32, nb_filters=None, **kwargs):\n",
    "        nf = ifnone(nf, nb_filters) # for compatibility\n",
    "        self.inceptionblock = InceptionBlock(c_in, nf, **kwargs) # c_in is input channel num of conv1d\n",
    "        self.gap = GAP1d(1)\n",
    "        self.fc = nn.Linear(nf * 4, c_out) # c_out is 1d output size \n",
    "        self.fc_tsne = nn.Linear(nf * 4, 2)\n",
    "        self.two_vecs_train = [] # list is faster in appending\n",
    "        self.two_vecs_test = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inceptionblock(x)\n",
    "        x = self.gap(x)\n",
    "        # two_dimensional_vec = self.fc_tsne(x)\n",
    "        # if self.training:\n",
    "        #     self.two_vecs_train.append(two_dimensional_vec.tolist()) # あとでネストしたものをまとめてtensorかndarrayに変換するため\n",
    "        # else:\n",
    "        #     self.two_vecs_test.append(two_dimensional_vec.tolist())\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCU_Dataset(Dataset):\n",
    "    def __init__(self, dataset, labels) -> None:\n",
    "        # super().__init__()\n",
    "        self.radar_heartbeat = dataset\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "          idx = idx.tolist()        \n",
    "        return self.radar_heartbeat[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.radar_heartbeat)\n",
    "\n",
    "\n",
    "dataset = HCU_Dataset(data_tensor_list, labels_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Close Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: 2457, Test Set: 615\n"
     ]
    }
   ],
   "source": [
    "close_train_size = int(0.80 * len(dataset))\n",
    "close_test_size = len(dataset) - close_train_size\n",
    "close_train_set, close_test_set = torch.utils.data.random_split(dataset, [close_train_size, close_test_size])\n",
    "print(f\"Train Set: {len(close_train_set)}, Test Set: {len(close_test_set)}\")\n",
    "train_loader = DataLoader(dataset=close_train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=close_test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Open Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5), tensor(6))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1535][1], dataset[1536][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "インデックスを2つに分ける．それぞれのサブセットで訓練とテストに分ける．\n",
    "訓練は1つ目のサブセットのうちの8割のみを使用．\n",
    "テストは両方のサブセットから2割ずつ取ってきて全て使用．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228, 615)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices1 = np.arange(1535)\n",
    "dataset1 = torch.utils.data.Subset(dataset, indices1) # 0-5\n",
    "indices2 = np.arange(1536, len(dataset))\n",
    "dataset2 = torch.utils.data.Subset(dataset, indices2) # 6-11\n",
    "Unknown_label = close_num + 1\n",
    "\n",
    "train_size1 = int(0.80 * len(dataset1))\n",
    "test_size1 = len(dataset1) - train_size1\n",
    "train_size2 = int(0.80 * len(dataset2))\n",
    "test_size2 = len(dataset2) - train_size2\n",
    "open_train_set, test_set1 = torch.utils.data.random_split(dataset1, [train_size1, test_size1])\n",
    "train_set2, test_set2 = torch.utils.data.random_split(dataset2, [train_size2, test_size2])\n",
    "indices = np.arange(len(test_set2))\n",
    "test_set2 = torch.utils.data.Subset(test_set2, indices[:])\n",
    "\n",
    "open_test_set = torch.utils.data.ConcatDataset([test_set1, test_set2])\n",
    "\n",
    "train_loader = DataLoader(dataset=open_train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=open_test_set, batch_size=batch_size, shuffle=False)\n",
    "len(open_train_set), len(open_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import log\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def softmax_loss(outputs, labels):\n",
    "    loss = 0\n",
    "    batch_size = len(labels)\n",
    "    logsoftmax_out = log(softmax(outputs))\n",
    "    for idx in range(batch_size):\n",
    "        loss += 1.0 - logsoftmax_out[idx][labels[idx]]\n",
    "    \n",
    "    return loss / batch_size\n",
    "\n",
    "\n",
    "from center_loss import CenterLoss\n",
    "center_loss = CenterLoss(num_classes=close_num + 1, feat_dim=close_num + 1, use_gpu=True) # 入出力が同じだと一見変な感じがするが，交差エントロピーと違ってcenterlossを使うと最初から決めていれば，モデルの出力サイズを必ずしもクラス数に一致させる必要がないからfeat_dimを任意に設定できる．\n",
    "optimizer_centloss = torch.optim.SGD(center_loss.parameters(), lr=0.05)\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type='cosface', eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 32.0 if not s else s\n",
    "            self.m = 0.2 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.fc.to(device)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        # logを引き算に変えて計算\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L)\n",
    "\n",
    "cos_loss = AngularPenaltySMLoss(close_num + 1, close_num + 1, loss_type=\"cosface\") # center_lossと同じ理由でin_featuresはクラス数でよい．\n",
    "\n",
    "\n",
    "def triple_joint_loss(output, label, alpha):\n",
    "    # alpha: hyper parameter\n",
    "    output_only_truth = []\n",
    "    for idx, x in enumerate(output):\n",
    "        x = x[labels[idx]]\n",
    "        x = torch.tensor(x).to(device)\n",
    "        output_only_truth.append([x])\n",
    "    output_only_truth = torch.tensor(output_only_truth)\n",
    "    output_only_truth = output_only_truth.float()\n",
    "    output_only_truth = output_only_truth.to(device)\n",
    "    # print(output.is_cuda, output_only_truth.is_cuda, label.is_cuda)\n",
    "\n",
    "    return softmax_loss(output, label) + alpha * center_loss(output, label)\n",
    "    # return softmax_loss(output, label) + alpha * center_loss(output, label) + cos_loss(output, label)\n",
    "    # return cos_loss(output_only_truth, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "mb = master_bar(range(num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6354, 0.6358, 0.6358,  ..., 0.6331, 0.6326, 0.6323]],\n",
       "        dtype=torch.float64),\n",
       " tensor(11))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.92465<p>Finished Epoch: 02, Training Loss:    3.70868<p>Finished Epoch: 03, Training Loss:    3.61727<p>Finished Epoch: 04, Training Loss:    3.34016<p>Finished Epoch: 05, Training Loss:    3.36497<p>Finished Epoch: 06, Training Loss:    3.61757<p>Finished Epoch: 07, Training Loss:    3.15205<p>Finished Epoch: 08, Training Loss:    3.54751<p>Finished Epoch: 09, Training Loss:    3.37568<p>Finished Epoch: 10, Training Loss:    3.58247<p>Finished Epoch: 11, Training Loss:    3.51940<p>Finished Epoch: 12, Training Loss:    3.21163<p>Finished Epoch: 13, Training Loss:    3.33742<p>Finished Epoch: 14, Training Loss:    3.40212<p>Finished Epoch: 15, Training Loss:    3.51927<p>Finished Epoch: 16, Training Loss:    3.26118<p>Finished Epoch: 17, Training Loss:    3.10775<p>Finished Epoch: 18, Training Loss:    3.20643<p>Finished Epoch: 19, Training Loss:    3.18153<p>Finished Epoch: 20, Training Loss:    3.17668<p>Finished Epoch: 21, Training Loss:    3.30429<p>Finished Epoch: 22, Training Loss:    3.39652<p>Finished Epoch: 23, Training Loss:    3.54272<p>Finished Epoch: 24, Training Loss:    3.23966<p>Finished Epoch: 25, Training Loss:    3.31459<p>Finished Epoch: 26, Training Loss:    3.26628<p>Finished Epoch: 27, Training Loss:    3.15753<p>Finished Epoch: 28, Training Loss:    3.17322<p>Finished Epoch: 29, Training Loss:    3.00596<p>Finished Epoch: 30, Training Loss:    3.32407<p>Finished Epoch: 31, Training Loss:    3.11760<p>Finished Epoch: 32, Training Loss:    3.15083<p>Finished Epoch: 33, Training Loss:    3.43363<p>Finished Epoch: 34, Training Loss:    3.23363<p>Finished Epoch: 35, Training Loss:    3.06187<p>Finished Epoch: 36, Training Loss:    3.03915<p>Finished Epoch: 37, Training Loss:    3.13275<p>Finished Epoch: 38, Training Loss:    3.06658<p>Finished Epoch: 39, Training Loss:    3.11205<p>Finished Epoch: 40, Training Loss:    3.44609<p>Finished Epoch: 41, Training Loss:    3.03900<p>Finished Epoch: 42, Training Loss:    3.00024<p>Finished Epoch: 43, Training Loss:    3.00051<p>Finished Epoch: 44, Training Loss:    2.92055<p>Finished Epoch: 45, Training Loss:    2.98839<p>Finished Epoch: 46, Training Loss:    2.68353<p>Finished Epoch: 47, Training Loss:    3.88912<p>Finished Epoch: 48, Training Loss:    3.07561<p>Finished Epoch: 49, Training Loss:    2.90358<p>Finished Epoch: 50, Training Loss:    2.94971<p>Finished Epoch: 51, Training Loss:    3.09718<p>Finished Epoch: 52, Training Loss:    3.09424<p>Finished Epoch: 53, Training Loss:    3.06215<p>Finished Epoch: 54, Training Loss:    3.13473<p>Finished Epoch: 55, Training Loss:    3.05956<p>Finished Epoch: 56, Training Loss:    2.99317<p>Finished Epoch: 57, Training Loss:    3.08775<p>Finished Epoch: 58, Training Loss:    2.97396<p>Finished Epoch: 59, Training Loss:    3.28658<p>Finished Epoch: 60, Training Loss:    3.11747<p>Finished Epoch: 61, Training Loss:    2.79640<p>Finished Epoch: 62, Training Loss:    2.94357<p>Finished Epoch: 63, Training Loss:    2.79437<p>Finished Epoch: 64, Training Loss:    3.29707<p>Finished Epoch: 65, Training Loss:    3.23720<p>Finished Epoch: 66, Training Loss:    2.72426<p>Finished Epoch: 67, Training Loss:    2.89258<p>Finished Epoch: 68, Training Loss:    3.33445<p>Finished Epoch: 69, Training Loss:    2.85576<p>Finished Epoch: 70, Training Loss:    3.19406<p>Finished Epoch: 71, Training Loss:    3.16800<p>Finished Epoch: 72, Training Loss:    3.10186<p>Finished Epoch: 73, Training Loss:    2.83673<p>Finished Epoch: 74, Training Loss:    3.69489<p>Finished Epoch: 75, Training Loss:    3.07013<p>Finished Epoch: 76, Training Loss:    2.93447<p>Finished Epoch: 77, Training Loss:    2.74988<p>Finished Epoch: 78, Training Loss:    2.88023<p>Finished Epoch: 79, Training Loss:    2.82403<p>Finished Epoch: 80, Training Loss:    3.08264<p>Finished Epoch: 81, Training Loss:    3.00662<p>Finished Epoch: 82, Training Loss:    2.77040<p>Finished Epoch: 83, Training Loss:    2.92688<p>Finished Epoch: 84, Training Loss:    2.89401<p>Finished Epoch: 85, Training Loss:    2.99374<p>Finished Epoch: 86, Training Loss:    2.62233<p>Finished Epoch: 87, Training Loss:    2.94842<p>Finished Epoch: 88, Training Loss:    3.24585<p>Finished Epoch: 89, Training Loss:    3.01677<p>Finished Epoch: 90, Training Loss:    2.92914<p>Finished Epoch: 91, Training Loss:    3.21069<p>Finished Epoch: 92, Training Loss:    2.85737<p>Finished Epoch: 93, Training Loss:    2.69025<p>Finished Epoch: 94, Training Loss:    3.39008<p>Finished Epoch: 95, Training Loss:    2.79982<p>Finished Epoch: 96, Training Loss:    3.07299<p>Finished Epoch: 97, Training Loss:    3.29394<p>Finished Epoch: 98, Training Loss:    2.90304<p>Finished Epoch: 99, Training Loss:    3.00390<p>Finished Epoch: 100, Training Loss:    2.96323"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26714/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = InceptionTime(1, close_num + 1)\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in mb:\n",
    "    for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "        signals = signals.float()\n",
    "        signals = signals.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(signals)\n",
    "        outputs = outputs.to(device)\n",
    "        loss = triple_joint_loss(outputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_centloss.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in center_loss.parameters():\n",
    "            param.grad.data *= (1./alpha)\n",
    "        optimizer.step()\n",
    "        optimizer_centloss.step()\n",
    "        # if (i + 1) % 10 == 0:\n",
    "            # print(f'Epoch [{epoch+1}/`{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "    mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase([0.2293, 0.3566, 0.2126, 0.4864, 0.5246, 0.7504, 0.1797, 0.3231,\n",
      "            0.2252, 0.1939, 0.3188, 0.1708, 0.2554, 0.2883, 0.3500, 0.9205,\n",
      "            0.4922, 0.3156, 0.2260, 0.9377, 0.8291, 0.1721, 0.1695, 0.4050,\n",
      "            0.2257, 0.3591, 0.7032, 0.8652, 0.3359, 0.9215, 0.5401, 0.1603,\n",
      "            0.2669, 0.1542, 0.3050, 0.3352, 0.1801, 0.2197, 0.2351, 0.4946,\n",
      "            0.7056, 0.3395, 0.3336, 0.3237, 0.3417, 0.1849, 0.3468, 0.2988,\n",
      "            0.1944, 0.7887, 0.4417, 0.3188, 0.1715, 0.2708, 0.2966, 0.3526,\n",
      "            0.6328, 0.3284, 0.9516, 0.3938, 0.1674, 0.1826, 0.3006, 0.4285],\n",
      "           device='cuda:0') TensorBase([2, 5, 4, 8, 8, 8, 3, 8, 4, 3, 0, 2, 9, 4, 8, 8, 7, 7, 4, 8, 8, 3, 7,\n",
      "            4, 4, 4, 8, 8, 7, 8, 8, 4, 0, 7, 5, 8, 2, 2, 7, 7, 8, 0, 7, 8, 2, 7,\n",
      "            7, 4, 3, 8, 8, 5, 7, 7, 4, 7, 8, 0, 8, 8, 7, 4, 0, 5],\n",
      "           device='cuda:0') tensor([ 6,  6,  6,  5, 11,  9,  4,  9, 11,  2,  9,  2,  9,  9,  7,  5,  0, 10,\n",
      "         1,  5,  8,  2,  3,  9,  1,  4,  9,  9, 10,  5,  6,  1,  0,  2,  0,  1,\n",
      "         2,  7,  7,  0,  9, 10, 10,  3,  6,  6,  7,  9,  1,  5,  5,  3,  7, 11,\n",
      "         9, 10, 11,  4,  3,  7,  4, 11,  7,  5], device='cuda:0')\n",
      "10 / 64 = Acc: 15.625 %\n",
      "TensorBase([0.8949, 0.1692, 0.4384, 0.4810, 0.9625, 0.4275, 0.8521, 0.4791,\n",
      "            0.1743, 0.2124, 0.4291, 0.2393, 0.2422, 0.1587, 0.9126, 0.7002,\n",
      "            0.1742, 0.3711, 0.3017, 0.9375, 0.1823, 0.2984, 0.4768, 0.1764,\n",
      "            0.1794, 0.3941, 0.2128, 0.1895, 0.3044, 0.2906, 0.3234, 0.1577,\n",
      "            0.3204, 0.7642, 0.4890, 0.2560, 0.1683, 0.8609, 0.1911, 0.2096,\n",
      "            0.2249, 0.4846, 0.9165, 0.2287, 0.1847, 0.2121, 0.2041, 0.1501,\n",
      "            0.1671, 0.4952, 0.1573, 0.2171, 0.1964, 0.2619, 0.2526, 0.9115,\n",
      "            0.4255, 0.4228, 0.9487, 0.3309, 0.2133, 0.3115, 0.3560, 0.8797],\n",
      "           device='cuda:0') TensorBase([8, 7, 7, 7, 8, 7, 8, 7, 4, 4, 7, 9, 4, 7, 8, 5, 3, 4, 7, 5, 4, 4, 7,\n",
      "            7, 3, 7, 8, 5, 7, 7, 2, 3, 0, 8, 8, 0, 7, 8, 3, 4, 8, 7, 8, 4, 0, 4,\n",
      "            2, 4, 3, 8, 4, 8, 7, 0, 7, 8, 5, 9, 8, 7, 8, 7, 8, 8],\n",
      "           device='cuda:0') tensor([ 8,  3,  0,  0,  8,  0,  8, 10,  4,  4, 10, 11,  0,  1,  8,  5,  2,  4,\n",
      "         7,  5,  4,  9,  3,  1,  2,  7,  1,  7, 11,  7,  6,  1,  0,  3,  9,  3,\n",
      "         3,  2,  4,  6,  9, 10,  8,  1,  0,  6,  6,  7,  3,  5,  6,  1,  7,  1,\n",
      "         2,  8,  6, 11,  3,  7,  2, 10,  1,  8], device='cuda:0')\n",
      "31 / 128 = Acc: 24.21875 %\n",
      "TensorBase([0.4534, 0.4444, 0.4217, 0.2463, 0.1488, 0.1894, 0.3646, 0.3316,\n",
      "            0.2205, 0.7338, 0.1570, 0.2218, 0.1499, 0.3359, 0.2692, 0.9392,\n",
      "            0.4554, 0.1976, 0.2913, 0.9105, 0.3219, 0.2107, 0.1794, 0.1668,\n",
      "            0.4487, 0.8218, 0.1994, 0.4209, 0.1861, 0.6491, 0.2981, 0.9359,\n",
      "            0.2292, 0.1936, 0.3539, 0.1592, 0.1631, 0.3777, 0.1775, 0.2432,\n",
      "            0.1828, 0.2093, 0.2575, 0.3251, 0.3857, 0.3733, 0.9623, 0.2127,\n",
      "            0.1996, 0.7880, 0.2107, 0.9483, 0.1572, 0.2724, 0.6408, 0.1659,\n",
      "            0.1955, 0.1961, 0.1835, 0.2969, 0.1601, 0.1817, 0.2411, 0.4848],\n",
      "           device='cuda:0') TensorBase([8, 8, 2, 5, 5, 0, 7, 0, 4, 8, 9, 8, 5, 7, 9, 8, 8, 0, 4, 8, 0, 8, 8,\n",
      "            7, 8, 8, 2, 8, 3, 8, 2, 8, 4, 3, 7, 3, 0, 4, 3, 2, 8, 8, 7, 9, 5, 4,\n",
      "            8, 4, 7, 8, 4, 8, 3, 0, 8, 7, 3, 8, 3, 0, 7, 0, 7, 7],\n",
      "           device='cuda:0') tensor([ 7,  6,  6,  3,  4,  0,  7,  9,  6,  5, 11,  6,  1, 10, 10,  5, 11,  0,\n",
      "         9,  8,  0,  1,  4,  7,  6,  5,  7,  6,  4, 11,  2,  5,  1,  1, 10,  2,\n",
      "        10,  4,  3,  2,  4,  2,  7, 11,  5,  4,  8,  4,  7,  5,  1,  3,  2,  0,\n",
      "         6, 10, 10,  2,  2,  1, 10,  0, 11,  0], device='cuda:0')\n",
      "49 / 192 = Acc: 25.520833333333332 %\n",
      "TensorBase([0.9147, 0.2715, 0.6675, 0.3482, 0.3288, 0.3153, 0.1827, 0.8217,\n",
      "            0.1684, 0.2730, 0.3251, 0.2195, 0.3569, 0.6609, 0.9445, 0.9547,\n",
      "            0.2171, 0.4771, 0.8487, 0.1718, 0.3195, 0.1789, 0.1672, 0.1790,\n",
      "            0.2337, 0.5869, 0.1936, 0.1742, 0.6384, 0.4041, 0.3267, 0.1540,\n",
      "            0.1959, 0.3776, 0.1681, 0.4784, 0.3710, 0.7380, 0.1183, 0.2955,\n",
      "            0.1824, 0.2098, 0.8168, 0.2012, 0.5733, 0.4646, 0.9346, 0.9221,\n",
      "            0.2532, 0.1957, 0.2902, 0.1883, 0.2340, 0.3391, 0.2252, 0.7762,\n",
      "            0.3043, 0.3074, 0.2801, 0.3673, 0.3166, 0.7939, 0.4441, 0.2005],\n",
      "           device='cuda:0') TensorBase([8, 0, 8, 2, 8, 2, 0, 8, 5, 9, 8, 4, 7, 8, 8, 8, 4, 5, 8, 4, 0, 3, 7,\n",
      "            0, 7, 8, 3, 3, 8, 7, 0, 3, 2, 9, 3, 7, 9, 8, 7, 0, 3, 3, 8, 4, 8, 8,\n",
      "            8, 8, 4, 7, 4, 0, 7, 7, 8, 8, 0, 0, 7, 9, 0, 8, 7, 4],\n",
      "           device='cuda:0') tensor([ 5,  7,  8,  2,  1,  6,  0,  5,  0, 10,  3,  6,  7,  1,  8,  8,  6,  3,\n",
      "        11,  1,  9,  4,  4,  3,  7,  2,  4,  7,  8,  7,  4,  4,  7, 11,  4, 10,\n",
      "        11,  3, 10, 11,  2, 10,  8,  4,  6,  6,  5,  5,  3,  7,  9,  1,  2,  7,\n",
      "         1,  7,  9, 11, 11, 10,  9,  8, 10,  5], device='cuda:0')\n",
      "63 / 256 = Acc: 24.609375 %\n",
      "TensorBase([0.3373, 0.2156, 0.1528, 0.4720, 0.1711, 0.4248, 0.2232, 0.1741,\n",
      "            0.4783, 0.1702, 0.7231, 0.1532, 0.1875, 0.2928, 0.4085, 0.3631,\n",
      "            0.2131, 0.1807, 0.3970, 0.1620, 0.1760, 0.3059, 0.2869, 0.2467,\n",
      "            0.1739, 0.2130, 0.3296, 0.3496, 0.1848, 0.9132, 0.2219, 0.7789,\n",
      "            0.1761, 0.2041, 0.4067, 0.1887, 0.5215, 0.6186, 0.2051, 0.6467,\n",
      "            0.1761, 0.2475, 0.2785, 0.8443, 0.1641, 0.1650, 0.3281, 0.1699,\n",
      "            0.9443, 0.3724, 0.1625, 0.8381, 0.1957, 0.2189, 0.7455, 0.9111,\n",
      "            0.4869, 0.5880, 0.1754, 0.1648, 0.9065, 0.1801, 0.3856, 0.1499],\n",
      "           device='cuda:0') TensorBase([7, 4, 7, 8, 3, 7, 4, 2, 7, 0, 8, 7, 8, 7, 7, 8, 0, 4, 8, 7, 2, 2, 7,\n",
      "            7, 3, 3, 7, 7, 3, 8, 8, 8, 3, 4, 7, 9, 8, 8, 7, 8, 3, 4, 9, 8, 0, 8,\n",
      "            7, 7, 8, 4, 7, 8, 5, 0, 8, 8, 7, 8, 3, 9, 8, 0, 7, 4],\n",
      "           device='cuda:0') tensor([10, 11, 10,  5,  4,  0,  4,  2, 10,  3,  9,  7,  9,  7,  7,  7,  4,  4,\n",
      "         6, 10,  6, 11,  7, 11,  2,  3,  6, 10,  2,  8,  1,  7,  7,  4, 11,  9,\n",
      "         4,  3, 11,  6,  3,  0,  9,  9, 10,  2, 11,  3,  5,  4,  1,  1, 11,  3,\n",
      "        11,  5,  3,  9,  3,  9,  8,  0, 10, 11], device='cuda:0')\n",
      "81 / 320 = Acc: 25.3125 %\n",
      "TensorBase([0.9229, 0.3341, 0.3296, 0.1662, 0.2706, 0.1668, 0.2243, 0.8812,\n",
      "            0.2247, 0.2386, 0.2995, 0.4730, 0.1741, 0.2017, 0.1820, 0.3513,\n",
      "            0.1714, 0.9115, 0.8918, 0.4491, 0.1798, 0.3370, 0.2539, 0.2635,\n",
      "            0.1524, 0.3022, 0.2080, 0.4793, 0.2023, 0.4631, 0.1663, 0.3284,\n",
      "            0.9602, 0.4502, 0.2286, 0.4230, 0.2967, 0.3572, 0.3097, 0.1768,\n",
      "            0.1600, 0.8633, 0.2110, 0.2116, 0.2098, 0.2376, 0.1908, 0.3721,\n",
      "            0.2031, 0.2745, 0.9153, 0.2311, 0.2654, 0.1705, 0.3995, 0.1573,\n",
      "            0.1689, 0.2289, 0.1550, 0.2296, 0.4806, 0.4730, 0.6725, 0.4634],\n",
      "           device='cuda:0') TensorBase([8, 7, 0, 7, 0, 3, 7, 8, 7, 9, 7, 7, 4, 3, 7, 5, 0, 5, 8, 7, 7, 0, 5,\n",
      "            7, 0, 4, 4, 7, 7, 8, 3, 0, 8, 7, 4, 8, 4, 7, 7, 3, 0, 8, 8, 4, 8, 8,\n",
      "            5, 4, 7, 7, 8, 7, 7, 3, 8, 7, 7, 4, 4, 4, 8, 8, 8, 7],\n",
      "           device='cuda:0') tensor([ 5, 10,  4, 10,  0,  1,  1,  8,  4,  9,  7,  0,  1,  2,  1,  8, 10,  5,\n",
      "         9,  3,  3,  9,  1,  0, 10,  4,  1, 10,  9,  8,  9,  0,  8, 11,  6, 11,\n",
      "         9,  7, 10,  2,  4,  8,  4,  4,  9,  2, 11,  4,  2,  7,  8,  2, 10,  7,\n",
      "         8, 10,  1,  4, 11,  1,  5,  6,  8,  3], device='cuda:0')\n",
      "99 / 384 = Acc: 25.78125 %\n",
      "TensorBase([0.6630, 0.1581, 0.3874, 0.1685, 0.1748, 0.3884, 0.8709, 0.2782,\n",
      "            0.9397, 0.2950, 0.2173, 0.2079, 0.3101, 0.3869, 0.3277, 0.4790,\n",
      "            0.3783, 0.8022, 0.1929, 0.2959, 0.2388, 0.6604, 0.1667, 0.3911,\n",
      "            0.1765, 0.2012, 0.2632, 0.8798, 0.1619, 0.3416, 0.2027, 0.4923,\n",
      "            0.8000, 0.8322, 0.9648, 0.4144, 0.2535, 0.1456, 0.4723, 0.8674,\n",
      "            0.1669, 0.2374, 0.2429, 0.3130, 0.2141, 0.1696, 0.1714, 0.6102,\n",
      "            0.3232, 0.2297, 0.2012, 0.2006, 0.6996, 0.2347, 0.2303, 0.3480,\n",
      "            0.1750, 0.9297, 0.1591, 0.2771, 0.7354, 0.8534, 0.9349, 0.7793],\n",
      "           device='cuda:0') TensorBase([8, 3, 2, 5, 3, 2, 8, 7, 8, 0, 4, 0, 0, 8, 7, 7, 8, 8, 0, 0, 8, 8, 7,\n",
      "            7, 3, 3, 0, 8, 7, 8, 8, 8, 8, 8, 8, 7, 7, 5, 7, 8, 7, 4, 2, 8, 4, 3,\n",
      "            3, 8, 7, 5, 7, 8, 8, 0, 5, 7, 3, 8, 7, 0, 8, 8, 8, 5],\n",
      "           device='cuda:0') tensor([11,  9,  6,  4,  3,  6,  9, 10,  5,  6,  4,  1,  0,  7,  2,  3, 11,  5,\n",
      "         0,  0,  1,  3,  3,  4,  2,  3,  0,  9, 10,  9,  1, 11,  8,  5,  8,  0,\n",
      "         7,  2,  0,  5,  3,  1,  7, 11,  6,  2,  2,  4,  6,  4, 11,  7,  5,  3,\n",
      "         3, 10,  2,  8,  3,  0,  7,  8,  5,  5], device='cuda:0')\n",
      "113 / 448 = Acc: 25.223214285714285 %\n",
      "TensorBase([0.3396, 0.3143, 0.2701, 0.2815, 0.1771, 0.3763, 0.1919, 0.7556,\n",
      "            0.1944, 0.2966, 0.9395, 0.4814, 0.2918, 0.1922, 0.1641, 0.3560,\n",
      "            0.1571, 0.3179, 0.1793, 0.2586, 0.7827, 0.3741, 0.3350, 0.6239,\n",
      "            0.2173, 0.2003, 0.2592, 0.1738, 0.2793, 0.2421, 0.2142, 0.1968,\n",
      "            0.5650, 0.2339, 0.9158, 0.8708, 0.2935, 0.9084, 0.1547, 0.2620,\n",
      "            0.9308, 0.3196, 0.2925, 0.2938, 0.1866, 0.1666, 0.1485, 0.3744,\n",
      "            0.2317, 0.2592, 0.9743, 0.2615, 0.1875, 0.2011, 0.5151, 0.2921,\n",
      "            0.3394, 0.3993, 0.9150, 0.7284, 0.2197, 0.8326, 0.3722, 0.1771],\n",
      "           device='cuda:0') TensorBase([7, 0, 7, 9, 3, 7, 7, 8, 3, 0, 8, 7, 0, 8, 4, 2, 7, 7, 9, 8, 8, 7, 7,\n",
      "            8, 8, 4, 7, 3, 0, 0, 4, 5, 8, 4, 8, 8, 4, 8, 7, 9, 8, 0, 7, 2, 4, 0,\n",
      "            3, 4, 8, 7, 8, 0, 4, 8, 8, 4, 7, 2, 8, 8, 5, 8, 4, 3],\n",
      "           device='cuda:0') tensor([ 4,  9, 10,  9,  2,  4,  7,  4,  3,  9,  8, 10,  6,  1, 11,  6,  4,  4,\n",
      "         9,  8,  3,  7, 10,  8,  4,  9,  7,  2,  0,  9,  4,  3,  3,  1,  9,  5,\n",
      "         9,  5, 10,  9,  5,  0, 11,  6,  4, 10,  3,  3, 11,  7,  8, 10, 10,  1,\n",
      "         3,  9,  7,  6,  5,  8,  6,  8,  3,  9], device='cuda:0')\n",
      "133 / 512 = Acc: 25.9765625 %\n",
      "TensorBase([0.2671, 0.3260, 0.1670, 0.1739, 0.3744, 0.1819, 0.1573, 0.9459,\n",
      "            0.9376, 0.3337, 0.3165, 0.4755, 0.2012, 0.1747, 0.1816, 0.8798,\n",
      "            0.3263, 0.2386, 0.9593, 0.4357, 0.3258, 0.2779, 0.1901, 0.1586,\n",
      "            0.9649, 0.7855, 0.3093, 0.3220, 0.6698, 0.9273, 0.4845, 0.1827,\n",
      "            0.5434, 0.2104, 0.3698, 0.3359, 0.1704, 0.2073, 0.5247, 0.3840,\n",
      "            0.1686, 0.3251, 0.1809, 0.1807, 0.3471, 0.2817, 0.3141, 0.2345,\n",
      "            0.9194, 0.1801, 0.1792, 0.8972, 0.9054, 0.9014, 0.5576, 0.1668,\n",
      "            0.2944, 0.2935, 0.9252, 0.1694, 0.9657, 0.1895, 0.3244, 0.1699],\n",
      "           device='cuda:0') TensorBase([0, 0, 7, 4, 8, 4, 7, 8, 8, 0, 0, 8, 4, 2, 3, 8, 0, 0, 8, 7, 8, 7, 3,\n",
      "            7, 8, 8, 0, 0, 8, 8, 7, 5, 8, 3, 9, 2, 7, 9, 8, 7, 3, 0, 7, 3, 5, 8,\n",
      "            0, 4, 8, 4, 5, 8, 8, 8, 5, 7, 5, 4, 8, 2, 8, 3, 0, 3],\n",
      "           device='cuda:0') tensor([ 7,  0,  3,  1,  9, 10, 10,  5,  5,  9,  0,  5,  5,  6,  4,  9,  4,  5,\n",
      "         8, 11,  6, 10,  4, 10,  8,  8,  9,  0, 11,  5, 10, 11,  6, 11, 11,  6,\n",
      "         7,  9,  5,  0,  2,  0,  2,  2, 11,  3,  0,  1,  8, 10,  4,  1,  5,  5,\n",
      "         5,  1, 10,  9,  5,  2,  8,  4,  0, 11], device='cuda:0')\n",
      "148 / 576 = Acc: 25.694444444444443 %\n",
      "TensorBase([0.9557, 0.1632, 0.3581, 0.4671, 0.3789, 0.2920, 0.2247, 0.5788,\n",
      "            0.2879, 0.1765, 0.8855, 0.1489, 0.2621, 0.3382, 0.8767, 0.6600,\n",
      "            0.1679, 0.7252, 0.2192, 0.4856, 0.3146, 0.7538, 0.3961, 0.4917,\n",
      "            0.2662, 0.4178, 0.1998, 0.3909, 0.2388, 0.2460, 0.1847, 0.1817,\n",
      "            0.2121, 0.8058, 0.1882, 0.3110, 0.1965, 0.3218, 0.2120],\n",
      "           device='cuda:0') TensorBase([8, 7, 9, 7, 7, 0, 3, 5, 0, 3, 8, 8, 7, 7, 8, 8, 3, 8, 0, 9, 7, 8, 7,\n",
      "            7, 5, 7, 4, 5, 3, 3, 1, 7, 3, 8, 4, 5, 7, 0, 3], device='cuda:0') tensor([ 8,  3, 11, 10,  0,  0,  7, 11,  9,  3,  8, 11, 11, 11,  8,  5, 10,  7,\n",
      "         0, 10, 11,  5,  7,  0,  9,  0,  6, 11,  1, 11,  6,  1,  2,  3,  5,  8,\n",
      "         7,  9,  9], device='cuda:0')\n",
      "156 / 615 = Acc: 25.365853658536587 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(77.92222222222227, 0.5, 'Ground Truth')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For Confusion Matrix\n",
    "predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "threshold = 0.65\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  n_correct = 0\n",
    "  n_samples = 0\n",
    "  softmax = nn.Softmax()\n",
    "  for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "    signals = signals.float()\n",
    "    signals = signals.to(device)\n",
    "    one_hot_labels = one_hot_labels.to(device)\n",
    "    outputs = model(signals)\n",
    "    for j, out in enumerate(outputs):\n",
    "      outputs[j] = softmax(out)\n",
    "    _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "    \"\"\"\n",
    "    # Opensetのためのthreshold-softmax\n",
    "    for idx in range(len(_)):\n",
    "      if _[idx] < threshold:\n",
    "        predicted[idx] = Unknown_label # 15, 20, 25\n",
    "    \"\"\"\n",
    "    print(_, predicted, one_hot_labels)\n",
    "    n_samples += one_hot_labels.size(0) # add batch_size\n",
    "    n_correct += (predicted == one_hot_labels).sum().item()\n",
    "    \n",
    "    predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "    one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "    predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "    one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(one_hot_labels_list, predicted_lists)\n",
    "sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues')\n",
    "plt.xlabel(\"Predicted Label\", fontsize=13)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Open set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "# X = dataset\n",
    "# y = labels\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0) # shuffle=Falseだとrandom_stateは何か数字を設定しても意味ないらしい\n",
    "\n",
    "mean_acc = 0\n",
    "\n",
    "dataset = MyDataset(data_series, labels_tensor, \"./data/\", transform=transforms.ToTensor())\n",
    "\n",
    "for Fold, (train_index, test_index) in enumerate(skf.split(data_series, labels_tensor)):\n",
    "    print(f\"Fold{Fold+1} Start!\")\n",
    "    # Prepare Open train Dataset\n",
    "    open_train_index = [i for i in train_index if i <= split_idx]\n",
    "    open_train_set = torch.utils.data.Subset(dataset, open_train_index)\n",
    "    open_test_set = torch.utils.data.Subset(dataset, test_index)\n",
    "    # Prepare Close train Dataset\n",
    "    # train_set = torch.utils.data.Subset(dataset, train_index)\n",
    "    # test_set = torch.utils.data.Subset(dataset, test_index) # openの場合も同じ\n",
    "\n",
    "    Unknown_label = close_num + 1\n",
    "\n",
    "    train_loader = DataLoader(dataset=open_train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=open_test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "    model = model.to(device)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    from fastprogress.fastprogress import master_bar, progress_bar\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    model.train()\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in mb:\n",
    "        for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "            signals = torch.tensor(signals)\n",
    "            signals = signals.float()\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # print(signals.size())\n",
    "            outputs = model(signals)\n",
    "            outputs = outputs.to(device)\n",
    "            # print(outputs)\n",
    "            loss = triple_joint_loss(outputs, labels, alpha) # will check the shapes of outputs and labels\n",
    "            # test_loss = triple_joint_loss(signals, one_hot_labels, alpha) # from test_loader?\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_centloss.zero_grad()\n",
    "            loss.backward()\n",
    "            for param in center_loss.parameters():\n",
    "                param.grad.data *= (1./alpha) # 98.98%を出したときはこれを書いていなかった→追加しても問題なし．\n",
    "            optimizer.step()\n",
    "            optimizer_centloss.step()\n",
    "        mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "\n",
    "    # For Confusion Matrix\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.999]\n",
    "    model.eval()\n",
    "    for threshold in thresholds:\n",
    "      predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "      one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "      with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        softmax = nn.Softmax()\n",
    "        for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "          signals = torch.tensor(signals)\n",
    "          signals = signals.float()\n",
    "          signals = signals.to(device)\n",
    "          one_hot_labels = one_hot_labels.to(device)\n",
    "          # print(len(one_hot_labels))\n",
    "          outputs = model(signals)\n",
    "          # if i == 1:\n",
    "          \n",
    "            # print(outputs)\n",
    "          for j, out in enumerate(outputs):\n",
    "            outputs[j] = softmax(out)\n",
    "\n",
    "          _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "          \n",
    "          for idx in range(len(_)):\n",
    "            if _[idx] < threshold:\n",
    "              predicted[idx] = Unknown_label # 15, 20, 25\n",
    "          # print(_, predicted, one_hot_labels)\n",
    "\n",
    "          n_samples += one_hot_labels.size(0) # add batch_size\n",
    "          n_correct += (predicted == one_hot_labels).sum().item()\n",
    "          \n",
    "          predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "          one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "          predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "          one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "          \n",
    "          acc = 100.0 * n_correct / n_samples\n",
    "          # print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
    "        with open(\"cross_val_result_close.txt\", \"a\") as f:\n",
    "          f.write(f\"Fold{Fold+1}, Threshold{threshold}\\n\")\n",
    "          f.write(classification_report(one_hot_labels_list, predicted_lists, digits=4) + \"\\n\")\n",
    "\n",
    "\n",
    "        cm = confusion_matrix(one_hot_labels_list, predicted_lists)\n",
    "        sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues')\n",
    "        plt.xlabel(\"Predicted Label\", fontsize=13)\n",
    "        plt.ylabel(\"Ground Truth\", fontsize=13)\n",
    "        fig_name = \"cross_val_Fold{}_threshold{}.png\".format(Fold, threshold)\n",
    "        plt.savefig(\"./figure/cross_val_open/\" + fig_name)\n",
    "        plt.close()\n",
    "      \n",
    "      if threshold == 0.7:\n",
    "        mean_acc += acc\n",
    "print(mean_acc / 10.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Close-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    4.08878<p>Finished Epoch: 02, Training Loss:    3.54280<p>Finished Epoch: 03, Training Loss:    3.06923<p>Finished Epoch: 04, Training Loss:    2.61717<p>Finished Epoch: 05, Training Loss:    2.83085<p>Finished Epoch: 06, Training Loss:    2.65355<p>Finished Epoch: 07, Training Loss:    3.17012<p>Finished Epoch: 08, Training Loss:    3.31383<p>Finished Epoch: 09, Training Loss:    2.19917<p>Finished Epoch: 10, Training Loss:    2.41243<p>Finished Epoch: 11, Training Loss:    3.20799<p>Finished Epoch: 12, Training Loss:    2.69954<p>Finished Epoch: 13, Training Loss:    2.46071<p>Finished Epoch: 14, Training Loss:    2.35814<p>Finished Epoch: 15, Training Loss:    3.32858<p>Finished Epoch: 16, Training Loss:    2.62238<p>Finished Epoch: 17, Training Loss:    2.42638<p>Finished Epoch: 18, Training Loss:    3.78107<p>Finished Epoch: 19, Training Loss:    2.90015<p>Finished Epoch: 20, Training Loss:    2.38313<p>Finished Epoch: 21, Training Loss:    1.96274<p>Finished Epoch: 22, Training Loss:    2.30468<p>Finished Epoch: 23, Training Loss:    2.43199<p>Finished Epoch: 24, Training Loss:    2.06429<p>Finished Epoch: 25, Training Loss:    2.37968<p>Finished Epoch: 26, Training Loss:    2.86968<p>Finished Epoch: 27, Training Loss:    4.10585<p>Finished Epoch: 28, Training Loss:    2.85029<p>Finished Epoch: 29, Training Loss:    2.53330<p>Finished Epoch: 30, Training Loss:    2.47498<p>Finished Epoch: 31, Training Loss:    2.72215<p>Finished Epoch: 32, Training Loss:    2.35849<p>Finished Epoch: 33, Training Loss:    2.28938<p>Finished Epoch: 34, Training Loss:    1.90321<p>Finished Epoch: 35, Training Loss:    2.66024<p>Finished Epoch: 36, Training Loss:    2.33788<p>Finished Epoch: 37, Training Loss:    2.75204<p>Finished Epoch: 38, Training Loss:    2.66768<p>Finished Epoch: 39, Training Loss:    2.90004<p>Finished Epoch: 40, Training Loss:    2.08865<p>Finished Epoch: 41, Training Loss:    2.56979<p>Finished Epoch: 42, Training Loss:    2.28056<p>Finished Epoch: 43, Training Loss:    2.20451<p>Finished Epoch: 44, Training Loss:    1.74325<p>Finished Epoch: 45, Training Loss:    2.32918<p>Finished Epoch: 46, Training Loss:    2.11646<p>Finished Epoch: 47, Training Loss:    2.42304<p>Finished Epoch: 48, Training Loss:    3.25637<p>Finished Epoch: 49, Training Loss:    2.10698<p>Finished Epoch: 50, Training Loss:    1.97459<p>Finished Epoch: 51, Training Loss:    5.13607<p>Finished Epoch: 52, Training Loss:    2.24768<p>Finished Epoch: 53, Training Loss:    1.90621<p>Finished Epoch: 54, Training Loss:    1.90315<p>Finished Epoch: 55, Training Loss:    2.29192<p>Finished Epoch: 56, Training Loss:    2.68592<p>Finished Epoch: 57, Training Loss:    2.21051<p>Finished Epoch: 58, Training Loss:    2.47251<p>Finished Epoch: 59, Training Loss:    1.84428<p>Finished Epoch: 60, Training Loss:    1.75423<p>Finished Epoch: 61, Training Loss:    4.22863<p>Finished Epoch: 62, Training Loss:    3.27991<p>Finished Epoch: 63, Training Loss:    2.25853<p>Finished Epoch: 64, Training Loss:    1.99578<p>Finished Epoch: 65, Training Loss:    2.92770<p>Finished Epoch: 66, Training Loss:    3.22520<p>Finished Epoch: 67, Training Loss:    1.78921<p>Finished Epoch: 68, Training Loss:    2.75212<p>Finished Epoch: 69, Training Loss:    2.33043<p>Finished Epoch: 70, Training Loss:    1.77545<p>Finished Epoch: 71, Training Loss:    7.82208<p>Finished Epoch: 72, Training Loss:    2.58595<p>Finished Epoch: 73, Training Loss:    1.94256<p>Finished Epoch: 74, Training Loss:    2.63765<p>Finished Epoch: 75, Training Loss:    2.10829<p>Finished Epoch: 76, Training Loss:    1.78946<p>Finished Epoch: 77, Training Loss:    2.61097<p>Finished Epoch: 78, Training Loss:    4.92118<p>Finished Epoch: 79, Training Loss:    2.43259<p>Finished Epoch: 80, Training Loss:    2.07273<p>Finished Epoch: 81, Training Loss:    4.34130<p>Finished Epoch: 82, Training Loss:    2.26867<p>Finished Epoch: 83, Training Loss:    2.24906<p>Finished Epoch: 84, Training Loss:    2.02818<p>Finished Epoch: 85, Training Loss:    2.72915<p>Finished Epoch: 86, Training Loss:    2.86057<p>Finished Epoch: 87, Training Loss:    1.77318<p>Finished Epoch: 88, Training Loss:    2.81791<p>Finished Epoch: 89, Training Loss:    2.52518<p>Finished Epoch: 90, Training Loss:    1.95595<p>Finished Epoch: 91, Training Loss:    2.83416<p>Finished Epoch: 92, Training Loss:    4.98526<p>Finished Epoch: 93, Training Loss:    1.96234<p>Finished Epoch: 94, Training Loss:    2.19534<p>Finished Epoch: 95, Training Loss:    1.93469<p>Finished Epoch: 96, Training Loss:    2.79002<p>Finished Epoch: 97, Training Loss:    1.92961<p>Finished Epoch: 98, Training Loss:    2.34113<p>Finished Epoch: 99, Training Loss:    3.50304<p>Finished Epoch: 100, Training Loss:    2.02485"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/center_loss.py:45: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
      "  distmat.addmm_(1, -2, x, self.centers.t())\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.35999<p>Finished Epoch: 02, Training Loss:    3.30790<p>Finished Epoch: 03, Training Loss:    2.32217<p>Finished Epoch: 04, Training Loss:    2.47197<p>Finished Epoch: 05, Training Loss:    2.46101<p>Finished Epoch: 06, Training Loss:    3.07283<p>Finished Epoch: 07, Training Loss:    2.62805<p>Finished Epoch: 08, Training Loss:    2.68871<p>Finished Epoch: 09, Training Loss:    3.01430<p>Finished Epoch: 10, Training Loss:    2.64681<p>Finished Epoch: 11, Training Loss:    3.22599<p>Finished Epoch: 12, Training Loss:    2.92444<p>Finished Epoch: 13, Training Loss:    2.14229<p>Finished Epoch: 14, Training Loss:    3.46264<p>Finished Epoch: 15, Training Loss:    3.52142<p>Finished Epoch: 16, Training Loss:    2.08051<p>Finished Epoch: 17, Training Loss:    2.73952<p>Finished Epoch: 18, Training Loss:    3.90361<p>Finished Epoch: 19, Training Loss:    2.20509<p>Finished Epoch: 20, Training Loss:    2.07977<p>Finished Epoch: 21, Training Loss:    2.32001<p>Finished Epoch: 22, Training Loss:    3.21287<p>Finished Epoch: 23, Training Loss:    3.13409<p>Finished Epoch: 24, Training Loss:    2.50059<p>Finished Epoch: 25, Training Loss:    2.83537<p>Finished Epoch: 26, Training Loss:    3.94211<p>Finished Epoch: 27, Training Loss:    2.15740<p>Finished Epoch: 28, Training Loss:    2.10151<p>Finished Epoch: 29, Training Loss:    2.32447<p>Finished Epoch: 30, Training Loss:    2.30454<p>Finished Epoch: 31, Training Loss:    3.13282<p>Finished Epoch: 32, Training Loss:    2.12270<p>Finished Epoch: 33, Training Loss:    2.18477<p>Finished Epoch: 34, Training Loss:    2.61309<p>Finished Epoch: 35, Training Loss:    2.06463<p>Finished Epoch: 36, Training Loss:    2.18999<p>Finished Epoch: 37, Training Loss:    2.17241<p>Finished Epoch: 38, Training Loss:    2.02407<p>Finished Epoch: 39, Training Loss:    2.61399<p>Finished Epoch: 40, Training Loss:    3.98354<p>Finished Epoch: 41, Training Loss:    2.91739<p>Finished Epoch: 42, Training Loss:    4.28672<p>Finished Epoch: 43, Training Loss:    1.94507<p>Finished Epoch: 44, Training Loss:    2.38377<p>Finished Epoch: 45, Training Loss:    4.89613<p>Finished Epoch: 46, Training Loss:    1.73787<p>Finished Epoch: 47, Training Loss:    2.38885<p>Finished Epoch: 48, Training Loss:    3.12549<p>Finished Epoch: 49, Training Loss:    2.67085<p>Finished Epoch: 50, Training Loss:    2.26109<p>Finished Epoch: 51, Training Loss:    2.36643<p>Finished Epoch: 52, Training Loss:    2.43124<p>Finished Epoch: 53, Training Loss:    1.99208<p>Finished Epoch: 54, Training Loss:    1.78843<p>Finished Epoch: 55, Training Loss:    2.68185<p>Finished Epoch: 56, Training Loss:    1.97641<p>Finished Epoch: 57, Training Loss:    2.12756<p>Finished Epoch: 58, Training Loss:    2.41304<p>Finished Epoch: 59, Training Loss:    1.96494<p>Finished Epoch: 60, Training Loss:    1.73474<p>Finished Epoch: 61, Training Loss:    2.04915<p>Finished Epoch: 62, Training Loss:    2.30534<p>Finished Epoch: 63, Training Loss:    2.05253<p>Finished Epoch: 64, Training Loss:    2.32328<p>Finished Epoch: 65, Training Loss:    3.51399<p>Finished Epoch: 66, Training Loss:    2.01760<p>Finished Epoch: 67, Training Loss:    2.42875<p>Finished Epoch: 68, Training Loss:    2.93845<p>Finished Epoch: 69, Training Loss:    2.93601<p>Finished Epoch: 70, Training Loss:    2.02083<p>Finished Epoch: 71, Training Loss:    2.80653<p>Finished Epoch: 72, Training Loss:    2.00710<p>Finished Epoch: 73, Training Loss:    2.61473<p>Finished Epoch: 74, Training Loss:    2.06175<p>Finished Epoch: 75, Training Loss:    2.42625<p>Finished Epoch: 76, Training Loss:    1.98739<p>Finished Epoch: 77, Training Loss:    2.52740<p>Finished Epoch: 78, Training Loss:    2.16501<p>Finished Epoch: 79, Training Loss:    1.97247<p>Finished Epoch: 80, Training Loss:    2.62475<p>Finished Epoch: 81, Training Loss:    2.67786<p>Finished Epoch: 82, Training Loss:    2.84680<p>Finished Epoch: 83, Training Loss:    3.10994<p>Finished Epoch: 84, Training Loss:    2.02941<p>Finished Epoch: 85, Training Loss:    2.11310<p>Finished Epoch: 86, Training Loss:    2.02001<p>Finished Epoch: 87, Training Loss:    2.51908<p>Finished Epoch: 88, Training Loss:    1.71629<p>Finished Epoch: 89, Training Loss:    3.56272<p>Finished Epoch: 90, Training Loss:    2.97567<p>Finished Epoch: 91, Training Loss:    1.76174<p>Finished Epoch: 92, Training Loss:    2.95605<p>Finished Epoch: 93, Training Loss:    2.92941<p>Finished Epoch: 94, Training Loss:    1.66982<p>Finished Epoch: 95, Training Loss:    3.03786<p>Finished Epoch: 96, Training Loss:    2.56139<p>Finished Epoch: 97, Training Loss:    2.32879<p>Finished Epoch: 98, Training Loss:    2.14818<p>Finished Epoch: 99, Training Loss:    4.88285<p>Finished Epoch: 100, Training Loss:    2.15071"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.25869<p>Finished Epoch: 02, Training Loss:    2.84468<p>Finished Epoch: 03, Training Loss:    3.03310<p>Finished Epoch: 04, Training Loss:    3.28779<p>Finished Epoch: 05, Training Loss:    2.86791<p>Finished Epoch: 06, Training Loss:    3.22767<p>Finished Epoch: 07, Training Loss:    2.78621<p>Finished Epoch: 08, Training Loss:    2.57082<p>Finished Epoch: 09, Training Loss:    2.40527<p>Finished Epoch: 10, Training Loss:    3.53529<p>Finished Epoch: 11, Training Loss:    2.56673<p>Finished Epoch: 12, Training Loss:    2.62528<p>Finished Epoch: 13, Training Loss:    2.07846<p>Finished Epoch: 14, Training Loss:    2.49928<p>Finished Epoch: 15, Training Loss:    1.96520<p>Finished Epoch: 16, Training Loss:    3.48981<p>Finished Epoch: 17, Training Loss:    3.73120<p>Finished Epoch: 18, Training Loss:    2.21086<p>Finished Epoch: 19, Training Loss:    2.55928<p>Finished Epoch: 20, Training Loss:    1.91110<p>Finished Epoch: 21, Training Loss:    2.27438<p>Finished Epoch: 22, Training Loss:    2.46328<p>Finished Epoch: 23, Training Loss:    2.34427<p>Finished Epoch: 24, Training Loss:    2.50106<p>Finished Epoch: 25, Training Loss:    2.28369<p>Finished Epoch: 26, Training Loss:    1.94842<p>Finished Epoch: 27, Training Loss:    2.09358<p>Finished Epoch: 28, Training Loss:    2.10880<p>Finished Epoch: 29, Training Loss:    1.95305<p>Finished Epoch: 30, Training Loss:    1.94864<p>Finished Epoch: 31, Training Loss:    2.23099<p>Finished Epoch: 32, Training Loss:    2.91082<p>Finished Epoch: 33, Training Loss:    1.90208<p>Finished Epoch: 34, Training Loss:    3.26683<p>Finished Epoch: 35, Training Loss:    2.05456<p>Finished Epoch: 36, Training Loss:    4.11229<p>Finished Epoch: 37, Training Loss:    2.20681<p>Finished Epoch: 38, Training Loss:    3.09833<p>Finished Epoch: 39, Training Loss:    2.96915<p>Finished Epoch: 40, Training Loss:    2.12150<p>Finished Epoch: 41, Training Loss:    3.15160<p>Finished Epoch: 42, Training Loss:    3.17786<p>Finished Epoch: 43, Training Loss:    2.02282<p>Finished Epoch: 44, Training Loss:    3.08195<p>Finished Epoch: 45, Training Loss:    2.41944<p>Finished Epoch: 46, Training Loss:    1.83081<p>Finished Epoch: 47, Training Loss:    2.11421<p>Finished Epoch: 48, Training Loss:    1.92342<p>Finished Epoch: 49, Training Loss:    1.65204<p>Finished Epoch: 50, Training Loss:    1.97292<p>Finished Epoch: 51, Training Loss:    2.57987<p>Finished Epoch: 52, Training Loss:    1.92257<p>Finished Epoch: 53, Training Loss:    2.69249<p>Finished Epoch: 54, Training Loss:    2.55825<p>Finished Epoch: 55, Training Loss:    1.95988<p>Finished Epoch: 56, Training Loss:    2.10801<p>Finished Epoch: 57, Training Loss:    2.27561<p>Finished Epoch: 58, Training Loss:    2.48242<p>Finished Epoch: 59, Training Loss:    1.92075<p>Finished Epoch: 60, Training Loss:    1.99302<p>Finished Epoch: 61, Training Loss:    2.58539<p>Finished Epoch: 62, Training Loss:    2.29236<p>Finished Epoch: 63, Training Loss:    4.25217<p>Finished Epoch: 64, Training Loss:    2.69270<p>Finished Epoch: 65, Training Loss:    2.72571<p>Finished Epoch: 66, Training Loss:    3.74254<p>Finished Epoch: 67, Training Loss:    1.81648<p>Finished Epoch: 68, Training Loss:    3.04587<p>Finished Epoch: 69, Training Loss:    1.75425<p>Finished Epoch: 70, Training Loss:    3.23333<p>Finished Epoch: 71, Training Loss:    2.19906<p>Finished Epoch: 72, Training Loss:    1.89293<p>Finished Epoch: 73, Training Loss:    2.06900<p>Finished Epoch: 74, Training Loss:    2.32925<p>Finished Epoch: 75, Training Loss:    4.03026<p>Finished Epoch: 76, Training Loss:    1.82625<p>Finished Epoch: 77, Training Loss:    2.27624<p>Finished Epoch: 78, Training Loss:    1.70512<p>Finished Epoch: 79, Training Loss:    2.55450<p>Finished Epoch: 80, Training Loss:    2.42019<p>Finished Epoch: 81, Training Loss:    1.81269<p>Finished Epoch: 82, Training Loss:    2.06973<p>Finished Epoch: 83, Training Loss:    2.50566<p>Finished Epoch: 84, Training Loss:    2.19869<p>Finished Epoch: 85, Training Loss:    3.25237<p>Finished Epoch: 86, Training Loss:    2.23098<p>Finished Epoch: 87, Training Loss:    1.95993<p>Finished Epoch: 88, Training Loss:    2.29057<p>Finished Epoch: 89, Training Loss:    3.16673<p>Finished Epoch: 90, Training Loss:    2.88490<p>Finished Epoch: 91, Training Loss:    2.45436<p>Finished Epoch: 92, Training Loss:    2.12836<p>Finished Epoch: 93, Training Loss:    1.77808<p>Finished Epoch: 94, Training Loss:    3.66401<p>Finished Epoch: 95, Training Loss:    7.75087<p>Finished Epoch: 96, Training Loss:    2.39020<p>Finished Epoch: 97, Training Loss:    1.74106<p>Finished Epoch: 98, Training Loss:    3.04477<p>Finished Epoch: 99, Training Loss:    1.89267<p>Finished Epoch: 100, Training Loss:    2.61499"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.26839<p>Finished Epoch: 02, Training Loss:    2.52532<p>Finished Epoch: 03, Training Loss:    4.66085<p>Finished Epoch: 04, Training Loss:    2.74452<p>Finished Epoch: 05, Training Loss:    2.70501<p>Finished Epoch: 06, Training Loss:    3.04418<p>Finished Epoch: 07, Training Loss:    2.27617<p>Finished Epoch: 08, Training Loss:    2.95230<p>Finished Epoch: 09, Training Loss:    2.41523<p>Finished Epoch: 10, Training Loss:    2.03934<p>Finished Epoch: 11, Training Loss:    2.86051<p>Finished Epoch: 12, Training Loss:    3.43744<p>Finished Epoch: 13, Training Loss:    2.23157<p>Finished Epoch: 14, Training Loss:    2.12268<p>Finished Epoch: 15, Training Loss:    2.28053<p>Finished Epoch: 16, Training Loss:    3.70051<p>Finished Epoch: 17, Training Loss:    2.51686<p>Finished Epoch: 18, Training Loss:    3.08126<p>Finished Epoch: 19, Training Loss:    2.49637<p>Finished Epoch: 20, Training Loss:    2.10004<p>Finished Epoch: 21, Training Loss:    2.48910<p>Finished Epoch: 22, Training Loss:    2.51415<p>Finished Epoch: 23, Training Loss:    2.39900<p>Finished Epoch: 24, Training Loss:    2.25714<p>Finished Epoch: 25, Training Loss:    2.98823<p>Finished Epoch: 26, Training Loss:    2.85555<p>Finished Epoch: 27, Training Loss:    2.72405<p>Finished Epoch: 28, Training Loss:    2.82991<p>Finished Epoch: 29, Training Loss:    2.97093<p>Finished Epoch: 30, Training Loss:    1.94449<p>Finished Epoch: 31, Training Loss:    2.67140<p>Finished Epoch: 32, Training Loss:    5.91051<p>Finished Epoch: 33, Training Loss:    1.88285<p>Finished Epoch: 34, Training Loss:    1.78125<p>Finished Epoch: 35, Training Loss:    3.11518<p>Finished Epoch: 36, Training Loss:    3.25080<p>Finished Epoch: 37, Training Loss:    4.17293<p>Finished Epoch: 38, Training Loss:    2.83774<p>Finished Epoch: 39, Training Loss:    2.17035<p>Finished Epoch: 40, Training Loss:    2.73792<p>Finished Epoch: 41, Training Loss:    3.03469<p>Finished Epoch: 42, Training Loss:    2.66980<p>Finished Epoch: 43, Training Loss:    2.64689<p>Finished Epoch: 44, Training Loss:    2.00864<p>Finished Epoch: 45, Training Loss:    2.13438<p>Finished Epoch: 46, Training Loss:    1.98704<p>Finished Epoch: 47, Training Loss:    2.22683<p>Finished Epoch: 48, Training Loss:    1.79692<p>Finished Epoch: 49, Training Loss:    2.67477<p>Finished Epoch: 50, Training Loss:    2.55525<p>Finished Epoch: 51, Training Loss:    2.29616<p>Finished Epoch: 52, Training Loss:    2.95242<p>Finished Epoch: 53, Training Loss:    2.36248<p>Finished Epoch: 54, Training Loss:    2.23720<p>Finished Epoch: 55, Training Loss:    2.55341<p>Finished Epoch: 56, Training Loss:    4.36846<p>Finished Epoch: 57, Training Loss:    2.32241<p>Finished Epoch: 58, Training Loss:    2.50179<p>Finished Epoch: 59, Training Loss:    3.40939<p>Finished Epoch: 60, Training Loss:    2.26526<p>Finished Epoch: 61, Training Loss:    2.46869<p>Finished Epoch: 62, Training Loss:    4.11536<p>Finished Epoch: 63, Training Loss:    3.38388<p>Finished Epoch: 64, Training Loss:    2.17461<p>Finished Epoch: 65, Training Loss:    2.05098<p>Finished Epoch: 66, Training Loss:    2.62458<p>Finished Epoch: 67, Training Loss:    1.84273<p>Finished Epoch: 68, Training Loss:    2.32166<p>Finished Epoch: 69, Training Loss:    2.29952<p>Finished Epoch: 70, Training Loss:    1.99119<p>Finished Epoch: 71, Training Loss:    3.11591<p>Finished Epoch: 72, Training Loss:    2.11493<p>Finished Epoch: 73, Training Loss:    2.32806<p>Finished Epoch: 74, Training Loss:    2.01103<p>Finished Epoch: 75, Training Loss:    1.89792<p>Finished Epoch: 76, Training Loss:    1.84651<p>Finished Epoch: 77, Training Loss:    2.07659<p>Finished Epoch: 78, Training Loss:    2.05379<p>Finished Epoch: 79, Training Loss:    2.14549<p>Finished Epoch: 80, Training Loss:    2.20940<p>Finished Epoch: 81, Training Loss:    1.87178<p>Finished Epoch: 82, Training Loss:    1.67901<p>Finished Epoch: 83, Training Loss:    3.04139<p>Finished Epoch: 84, Training Loss:    2.01698<p>Finished Epoch: 85, Training Loss:    1.94626<p>Finished Epoch: 86, Training Loss:    2.54581<p>Finished Epoch: 87, Training Loss:    2.69053<p>Finished Epoch: 88, Training Loss:    1.84092<p>Finished Epoch: 89, Training Loss:    1.97338<p>Finished Epoch: 90, Training Loss:    2.11065<p>Finished Epoch: 91, Training Loss:    2.35717<p>Finished Epoch: 92, Training Loss:    4.68791<p>Finished Epoch: 93, Training Loss:    1.94481<p>Finished Epoch: 94, Training Loss:    2.26592<p>Finished Epoch: 95, Training Loss:    2.14686<p>Finished Epoch: 96, Training Loss:    2.65270<p>Finished Epoch: 97, Training Loss:    3.10657<p>Finished Epoch: 98, Training Loss:    2.23126<p>Finished Epoch: 99, Training Loss:    3.00843<p>Finished Epoch: 100, Training Loss:    2.12075"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.13083<p>Finished Epoch: 02, Training Loss:    2.67814<p>Finished Epoch: 03, Training Loss:    2.39348<p>Finished Epoch: 04, Training Loss:    2.44943<p>Finished Epoch: 05, Training Loss:    2.53352<p>Finished Epoch: 06, Training Loss:    3.12570<p>Finished Epoch: 07, Training Loss:    3.42833<p>Finished Epoch: 08, Training Loss:    2.72332<p>Finished Epoch: 09, Training Loss:    2.58080<p>Finished Epoch: 10, Training Loss:    3.36077<p>Finished Epoch: 11, Training Loss:    2.38684<p>Finished Epoch: 12, Training Loss:    2.72162<p>Finished Epoch: 13, Training Loss:    3.72438<p>Finished Epoch: 14, Training Loss:    2.63329<p>Finished Epoch: 15, Training Loss:    2.63645<p>Finished Epoch: 16, Training Loss:    2.68223<p>Finished Epoch: 17, Training Loss:    2.61259<p>Finished Epoch: 18, Training Loss:    2.54423<p>Finished Epoch: 19, Training Loss:    2.18910<p>Finished Epoch: 20, Training Loss:    2.60970<p>Finished Epoch: 21, Training Loss:    2.26998<p>Finished Epoch: 22, Training Loss:    2.49649<p>Finished Epoch: 23, Training Loss:    2.32434<p>Finished Epoch: 24, Training Loss:    2.26140<p>Finished Epoch: 25, Training Loss:    1.89373<p>Finished Epoch: 26, Training Loss:    4.86155<p>Finished Epoch: 27, Training Loss:    2.93059<p>Finished Epoch: 28, Training Loss:    2.25583<p>Finished Epoch: 29, Training Loss:    2.10819<p>Finished Epoch: 30, Training Loss:    2.31013<p>Finished Epoch: 31, Training Loss:    2.98184<p>Finished Epoch: 32, Training Loss:    2.20559<p>Finished Epoch: 33, Training Loss:    1.85752<p>Finished Epoch: 34, Training Loss:    2.26488<p>Finished Epoch: 35, Training Loss:    2.43390<p>Finished Epoch: 36, Training Loss:    3.79635<p>Finished Epoch: 37, Training Loss:    2.70113<p>Finished Epoch: 38, Training Loss:    1.93172<p>Finished Epoch: 39, Training Loss:    2.89259<p>Finished Epoch: 40, Training Loss:    1.95120<p>Finished Epoch: 41, Training Loss:    2.27454<p>Finished Epoch: 42, Training Loss:    2.15257<p>Finished Epoch: 43, Training Loss:    3.52789<p>Finished Epoch: 44, Training Loss:    2.56233<p>Finished Epoch: 45, Training Loss:    2.21312<p>Finished Epoch: 46, Training Loss:    2.77422<p>Finished Epoch: 47, Training Loss:    1.81956<p>Finished Epoch: 48, Training Loss:    3.06419<p>Finished Epoch: 49, Training Loss:    2.00627<p>Finished Epoch: 50, Training Loss:    1.84907<p>Finished Epoch: 51, Training Loss:    2.15904<p>Finished Epoch: 52, Training Loss:    2.29577<p>Finished Epoch: 53, Training Loss:    2.26872<p>Finished Epoch: 54, Training Loss:    1.88590<p>Finished Epoch: 55, Training Loss:    3.72275<p>Finished Epoch: 56, Training Loss:    2.03248<p>Finished Epoch: 57, Training Loss:    2.49683<p>Finished Epoch: 58, Training Loss:    2.42396<p>Finished Epoch: 59, Training Loss:    1.72867<p>Finished Epoch: 60, Training Loss:    1.92291<p>Finished Epoch: 61, Training Loss:    2.00326<p>Finished Epoch: 62, Training Loss:    2.29319<p>Finished Epoch: 63, Training Loss:    2.32021<p>Finished Epoch: 64, Training Loss:    2.64378<p>Finished Epoch: 65, Training Loss:    2.63133<p>Finished Epoch: 66, Training Loss:    3.30332<p>Finished Epoch: 67, Training Loss:    3.06789<p>Finished Epoch: 68, Training Loss:    1.73330<p>Finished Epoch: 69, Training Loss:    2.32116<p>Finished Epoch: 70, Training Loss:    2.01950<p>Finished Epoch: 71, Training Loss:    2.29425<p>Finished Epoch: 72, Training Loss:    2.49476<p>Finished Epoch: 73, Training Loss:    2.66815<p>Finished Epoch: 74, Training Loss:    3.26900<p>Finished Epoch: 75, Training Loss:    2.34429<p>Finished Epoch: 76, Training Loss:    2.16252<p>Finished Epoch: 77, Training Loss:    3.08526<p>Finished Epoch: 78, Training Loss:    1.96085<p>Finished Epoch: 79, Training Loss:    2.17036<p>Finished Epoch: 80, Training Loss:    1.81793<p>Finished Epoch: 81, Training Loss:    2.41419<p>Finished Epoch: 82, Training Loss:    1.89736<p>Finished Epoch: 83, Training Loss:    2.34043<p>Finished Epoch: 84, Training Loss:    5.05396<p>Finished Epoch: 85, Training Loss:    2.06029<p>Finished Epoch: 86, Training Loss:    2.13362<p>Finished Epoch: 87, Training Loss:    1.91589<p>Finished Epoch: 88, Training Loss:    2.09063<p>Finished Epoch: 89, Training Loss:    2.17761<p>Finished Epoch: 90, Training Loss:    3.51624<p>Finished Epoch: 91, Training Loss:    1.80913<p>Finished Epoch: 92, Training Loss:    3.57883<p>Finished Epoch: 93, Training Loss:    4.20121<p>Finished Epoch: 94, Training Loss:    2.14249<p>Finished Epoch: 95, Training Loss:    2.24183<p>Finished Epoch: 96, Training Loss:    1.73051<p>Finished Epoch: 97, Training Loss:    1.97274<p>Finished Epoch: 98, Training Loss:    2.88578<p>Finished Epoch: 99, Training Loss:    2.26552<p>Finished Epoch: 100, Training Loss:    1.98298"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold6 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.56169<p>Finished Epoch: 02, Training Loss:    6.30705<p>Finished Epoch: 03, Training Loss:    2.95402<p>Finished Epoch: 04, Training Loss:    2.96778<p>Finished Epoch: 05, Training Loss:    2.81963<p>Finished Epoch: 06, Training Loss:    2.29289<p>Finished Epoch: 07, Training Loss:    2.30910<p>Finished Epoch: 08, Training Loss:    2.53496<p>Finished Epoch: 09, Training Loss:    2.46143<p>Finished Epoch: 10, Training Loss:    2.39386<p>Finished Epoch: 11, Training Loss:    2.68134<p>Finished Epoch: 12, Training Loss:    2.10488<p>Finished Epoch: 13, Training Loss:    2.93936<p>Finished Epoch: 14, Training Loss:    4.00922<p>Finished Epoch: 15, Training Loss:    3.19767<p>Finished Epoch: 16, Training Loss:    2.67500<p>Finished Epoch: 17, Training Loss:    2.45553<p>Finished Epoch: 18, Training Loss:    2.11724<p>Finished Epoch: 19, Training Loss:    2.07973<p>Finished Epoch: 20, Training Loss:    1.96779<p>Finished Epoch: 21, Training Loss:    2.27469<p>Finished Epoch: 22, Training Loss:    2.24186<p>Finished Epoch: 23, Training Loss:    2.16410<p>Finished Epoch: 24, Training Loss:    2.96250<p>Finished Epoch: 25, Training Loss:    2.70635<p>Finished Epoch: 26, Training Loss:    1.93950<p>Finished Epoch: 27, Training Loss:    2.03036<p>Finished Epoch: 28, Training Loss:    2.54455<p>Finished Epoch: 29, Training Loss:    2.08094<p>Finished Epoch: 30, Training Loss:    2.12441<p>Finished Epoch: 31, Training Loss:    5.91429<p>Finished Epoch: 32, Training Loss:    4.23522<p>Finished Epoch: 33, Training Loss:    2.69200<p>Finished Epoch: 34, Training Loss:    5.50852<p>Finished Epoch: 35, Training Loss:    2.04785<p>Finished Epoch: 36, Training Loss:    2.22836<p>Finished Epoch: 37, Training Loss:    2.16785<p>Finished Epoch: 38, Training Loss:    1.90109<p>Finished Epoch: 39, Training Loss:    1.87247<p>Finished Epoch: 40, Training Loss:    3.73409<p>Finished Epoch: 41, Training Loss:    4.48663<p>Finished Epoch: 42, Training Loss:    2.74897<p>Finished Epoch: 43, Training Loss:    2.43037<p>Finished Epoch: 44, Training Loss:    3.24187<p>Finished Epoch: 45, Training Loss:    2.13498<p>Finished Epoch: 46, Training Loss:    2.03360<p>Finished Epoch: 47, Training Loss:    3.04366<p>Finished Epoch: 48, Training Loss:    4.83846<p>Finished Epoch: 49, Training Loss:    2.08070<p>Finished Epoch: 50, Training Loss:    2.31943<p>Finished Epoch: 51, Training Loss:    2.76963<p>Finished Epoch: 52, Training Loss:    2.22618<p>Finished Epoch: 53, Training Loss:    3.37595<p>Finished Epoch: 54, Training Loss:    2.39456<p>Finished Epoch: 55, Training Loss:    1.63987<p>Finished Epoch: 56, Training Loss:    2.70031<p>Finished Epoch: 57, Training Loss:    2.24350<p>Finished Epoch: 58, Training Loss:    2.04779<p>Finished Epoch: 59, Training Loss:    2.49973<p>Finished Epoch: 60, Training Loss:    2.30833<p>Finished Epoch: 61, Training Loss:    1.95488<p>Finished Epoch: 62, Training Loss:    2.31449<p>Finished Epoch: 63, Training Loss:    1.96234<p>Finished Epoch: 64, Training Loss:    2.00881<p>Finished Epoch: 65, Training Loss:    2.02464<p>Finished Epoch: 66, Training Loss:    2.06258<p>Finished Epoch: 67, Training Loss:    2.24637<p>Finished Epoch: 68, Training Loss:    2.33261<p>Finished Epoch: 69, Training Loss:    2.80348<p>Finished Epoch: 70, Training Loss:    2.43582<p>Finished Epoch: 71, Training Loss:    2.51152<p>Finished Epoch: 72, Training Loss:    2.25891<p>Finished Epoch: 73, Training Loss:    2.82600<p>Finished Epoch: 74, Training Loss:    2.53305<p>Finished Epoch: 75, Training Loss:    1.82742<p>Finished Epoch: 76, Training Loss:    2.28732<p>Finished Epoch: 77, Training Loss:    2.08436<p>Finished Epoch: 78, Training Loss:    2.13516<p>Finished Epoch: 79, Training Loss:    2.32338<p>Finished Epoch: 80, Training Loss:    1.90214<p>Finished Epoch: 81, Training Loss:    2.34282<p>Finished Epoch: 82, Training Loss:    3.40288<p>Finished Epoch: 83, Training Loss:    2.01927<p>Finished Epoch: 84, Training Loss:    2.48650<p>Finished Epoch: 85, Training Loss:    1.99454<p>Finished Epoch: 86, Training Loss:    1.60746<p>Finished Epoch: 87, Training Loss:    1.95761<p>Finished Epoch: 88, Training Loss:    2.32467<p>Finished Epoch: 89, Training Loss:    4.69972<p>Finished Epoch: 90, Training Loss:    3.20261<p>Finished Epoch: 91, Training Loss:    2.09889<p>Finished Epoch: 92, Training Loss:    2.72731<p>Finished Epoch: 93, Training Loss:    2.96016<p>Finished Epoch: 94, Training Loss:    1.89413<p>Finished Epoch: 95, Training Loss:    2.56775<p>Finished Epoch: 96, Training Loss:    3.84862<p>Finished Epoch: 97, Training Loss:    1.81154<p>Finished Epoch: 98, Training Loss:    2.07320<p>Finished Epoch: 99, Training Loss:    2.26660<p>Finished Epoch: 100, Training Loss:    1.86976"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold7 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.89036<p>Finished Epoch: 02, Training Loss:    4.39806<p>Finished Epoch: 03, Training Loss:    2.30939<p>Finished Epoch: 04, Training Loss:    4.24928<p>Finished Epoch: 05, Training Loss:    2.93196<p>Finished Epoch: 06, Training Loss:    2.76906<p>Finished Epoch: 07, Training Loss:    3.51511<p>Finished Epoch: 08, Training Loss:    2.42070<p>Finished Epoch: 09, Training Loss:    3.34930<p>Finished Epoch: 10, Training Loss:    1.99914<p>Finished Epoch: 11, Training Loss:    2.91259<p>Finished Epoch: 12, Training Loss:    2.53449<p>Finished Epoch: 13, Training Loss:    3.43382<p>Finished Epoch: 14, Training Loss:    2.86723<p>Finished Epoch: 15, Training Loss:    2.15220<p>Finished Epoch: 16, Training Loss:    2.06820<p>Finished Epoch: 17, Training Loss:    2.61283<p>Finished Epoch: 18, Training Loss:    3.04335<p>Finished Epoch: 19, Training Loss:    1.97427<p>Finished Epoch: 20, Training Loss:    1.98293<p>Finished Epoch: 21, Training Loss:    1.96410<p>Finished Epoch: 22, Training Loss:    2.38427<p>Finished Epoch: 23, Training Loss:    2.12930<p>Finished Epoch: 24, Training Loss:    2.21641<p>Finished Epoch: 25, Training Loss:    2.11366<p>Finished Epoch: 26, Training Loss:    2.06789<p>Finished Epoch: 27, Training Loss:    2.64728<p>Finished Epoch: 28, Training Loss:    2.30794<p>Finished Epoch: 29, Training Loss:    2.46011<p>Finished Epoch: 30, Training Loss:    2.94118<p>Finished Epoch: 31, Training Loss:    2.83645<p>Finished Epoch: 32, Training Loss:    2.54720<p>Finished Epoch: 33, Training Loss:    2.64727<p>Finished Epoch: 34, Training Loss:    1.81141<p>Finished Epoch: 35, Training Loss:    2.32280<p>Finished Epoch: 36, Training Loss:    2.45648<p>Finished Epoch: 37, Training Loss:    2.47562<p>Finished Epoch: 38, Training Loss:    2.31620<p>Finished Epoch: 39, Training Loss:    3.20819<p>Finished Epoch: 40, Training Loss:    2.06046<p>Finished Epoch: 41, Training Loss:    1.71978<p>Finished Epoch: 42, Training Loss:    2.53705<p>Finished Epoch: 43, Training Loss:    2.11992<p>Finished Epoch: 44, Training Loss:    2.14113<p>Finished Epoch: 45, Training Loss:    2.20312<p>Finished Epoch: 46, Training Loss:    2.40123<p>Finished Epoch: 47, Training Loss:    1.83706<p>Finished Epoch: 48, Training Loss:    2.47897<p>Finished Epoch: 49, Training Loss:    2.22549<p>Finished Epoch: 50, Training Loss:    2.45798<p>Finished Epoch: 51, Training Loss:    2.94585<p>Finished Epoch: 52, Training Loss:    2.18904<p>Finished Epoch: 53, Training Loss:    2.42373<p>Finished Epoch: 54, Training Loss:    2.14762<p>Finished Epoch: 55, Training Loss:    2.55643<p>Finished Epoch: 56, Training Loss:    2.16243<p>Finished Epoch: 57, Training Loss:    1.93500<p>Finished Epoch: 58, Training Loss:    2.15037<p>Finished Epoch: 59, Training Loss:    2.18094<p>Finished Epoch: 60, Training Loss:    2.24086<p>Finished Epoch: 61, Training Loss:    1.89952<p>Finished Epoch: 62, Training Loss:    2.11941<p>Finished Epoch: 63, Training Loss:    2.32733<p>Finished Epoch: 64, Training Loss:    3.00764<p>Finished Epoch: 65, Training Loss:    1.91557<p>Finished Epoch: 66, Training Loss:    2.19191<p>Finished Epoch: 67, Training Loss:    2.40504<p>Finished Epoch: 68, Training Loss:    2.20025<p>Finished Epoch: 69, Training Loss:    1.67457<p>Finished Epoch: 70, Training Loss:    2.61267<p>Finished Epoch: 71, Training Loss:    2.38770<p>Finished Epoch: 72, Training Loss:    1.98684<p>Finished Epoch: 73, Training Loss:    1.88866<p>Finished Epoch: 74, Training Loss:    2.10263<p>Finished Epoch: 75, Training Loss:    1.86689<p>Finished Epoch: 76, Training Loss:    2.21766<p>Finished Epoch: 77, Training Loss:    2.79127<p>Finished Epoch: 78, Training Loss:    2.00013<p>Finished Epoch: 79, Training Loss:    3.47066<p>Finished Epoch: 80, Training Loss:    2.07114<p>Finished Epoch: 81, Training Loss:    1.97039<p>Finished Epoch: 82, Training Loss:    1.98764<p>Finished Epoch: 83, Training Loss:    1.89718<p>Finished Epoch: 84, Training Loss:    1.74374<p>Finished Epoch: 85, Training Loss:    2.47710<p>Finished Epoch: 86, Training Loss:    2.11795<p>Finished Epoch: 87, Training Loss:    1.71562<p>Finished Epoch: 88, Training Loss:    2.11196<p>Finished Epoch: 89, Training Loss:    2.04280<p>Finished Epoch: 90, Training Loss:    3.06921<p>Finished Epoch: 91, Training Loss:    2.40910<p>Finished Epoch: 92, Training Loss:    2.44263<p>Finished Epoch: 93, Training Loss:    1.86215<p>Finished Epoch: 94, Training Loss:    2.68885<p>Finished Epoch: 95, Training Loss:    4.10315<p>Finished Epoch: 96, Training Loss:    2.36772<p>Finished Epoch: 97, Training Loss:    2.41231<p>Finished Epoch: 98, Training Loss:    1.82357<p>Finished Epoch: 99, Training Loss:    1.71096<p>Finished Epoch: 100, Training Loss:    2.05481"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold8 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.00823<p>Finished Epoch: 02, Training Loss:    3.07604<p>Finished Epoch: 03, Training Loss:    3.19076<p>Finished Epoch: 04, Training Loss:    3.07667<p>Finished Epoch: 05, Training Loss:    2.64543<p>Finished Epoch: 06, Training Loss:    2.88756<p>Finished Epoch: 07, Training Loss:    2.25006<p>Finished Epoch: 08, Training Loss:    3.08047<p>Finished Epoch: 09, Training Loss:    1.97826<p>Finished Epoch: 10, Training Loss:    3.62012<p>Finished Epoch: 11, Training Loss:    2.27536<p>Finished Epoch: 12, Training Loss:    2.39178<p>Finished Epoch: 13, Training Loss:    4.35768<p>Finished Epoch: 14, Training Loss:    2.62031<p>Finished Epoch: 15, Training Loss:    2.00908<p>Finished Epoch: 16, Training Loss:    2.52130<p>Finished Epoch: 17, Training Loss:    2.53462<p>Finished Epoch: 18, Training Loss:    2.41852<p>Finished Epoch: 19, Training Loss:    3.46521<p>Finished Epoch: 20, Training Loss:    2.66770<p>Finished Epoch: 21, Training Loss:    1.87591<p>Finished Epoch: 22, Training Loss:    2.08379<p>Finished Epoch: 23, Training Loss:    2.67286<p>Finished Epoch: 24, Training Loss:    4.79162<p>Finished Epoch: 25, Training Loss:    2.27469<p>Finished Epoch: 26, Training Loss:    2.59365<p>Finished Epoch: 27, Training Loss:    2.16247<p>Finished Epoch: 28, Training Loss:    2.55263<p>Finished Epoch: 29, Training Loss:    2.31297<p>Finished Epoch: 30, Training Loss:    2.41204<p>Finished Epoch: 31, Training Loss:    1.86726<p>Finished Epoch: 32, Training Loss:    1.86567<p>Finished Epoch: 33, Training Loss:    2.10415<p>Finished Epoch: 34, Training Loss:    2.46344<p>Finished Epoch: 35, Training Loss:    2.00910<p>Finished Epoch: 36, Training Loss:    5.46649<p>Finished Epoch: 37, Training Loss:    2.36269<p>Finished Epoch: 38, Training Loss:    1.88378<p>Finished Epoch: 39, Training Loss:    2.17324<p>Finished Epoch: 40, Training Loss:    1.93050<p>Finished Epoch: 41, Training Loss:    2.04000<p>Finished Epoch: 42, Training Loss:    1.99551<p>Finished Epoch: 43, Training Loss:    2.62438<p>Finished Epoch: 44, Training Loss:    2.31661<p>Finished Epoch: 45, Training Loss:    2.42237<p>Finished Epoch: 46, Training Loss:    2.08283<p>Finished Epoch: 47, Training Loss:    2.73285<p>Finished Epoch: 48, Training Loss:    2.30503<p>Finished Epoch: 49, Training Loss:    1.94856<p>Finished Epoch: 50, Training Loss:    1.99169<p>Finished Epoch: 51, Training Loss:    2.02391<p>Finished Epoch: 52, Training Loss:    3.09117<p>Finished Epoch: 53, Training Loss:    2.38735<p>Finished Epoch: 54, Training Loss:    2.34546<p>Finished Epoch: 55, Training Loss:    2.35993<p>Finished Epoch: 56, Training Loss:    2.16528<p>Finished Epoch: 57, Training Loss:    3.47327<p>Finished Epoch: 58, Training Loss:    1.84669<p>Finished Epoch: 59, Training Loss:    4.88329<p>Finished Epoch: 60, Training Loss:    1.75310<p>Finished Epoch: 61, Training Loss:    2.08036<p>Finished Epoch: 62, Training Loss:    2.39887<p>Finished Epoch: 63, Training Loss:    1.84969<p>Finished Epoch: 64, Training Loss:    3.04373<p>Finished Epoch: 65, Training Loss:    2.84109<p>Finished Epoch: 66, Training Loss:    3.52007<p>Finished Epoch: 67, Training Loss:    3.06203<p>Finished Epoch: 68, Training Loss:    2.93693<p>Finished Epoch: 69, Training Loss:    2.04950<p>Finished Epoch: 70, Training Loss:    3.34534<p>Finished Epoch: 71, Training Loss:    2.66601<p>Finished Epoch: 72, Training Loss:    2.46520<p>Finished Epoch: 73, Training Loss:    1.97718<p>Finished Epoch: 74, Training Loss:    1.95076<p>Finished Epoch: 75, Training Loss:    3.16256<p>Finished Epoch: 76, Training Loss:    2.20784<p>Finished Epoch: 77, Training Loss:    2.87499<p>Finished Epoch: 78, Training Loss:    1.94632<p>Finished Epoch: 79, Training Loss:    2.91915<p>Finished Epoch: 80, Training Loss:    3.17142<p>Finished Epoch: 81, Training Loss:    4.21355<p>Finished Epoch: 82, Training Loss:    2.89488<p>Finished Epoch: 83, Training Loss:    2.02659<p>Finished Epoch: 84, Training Loss:    2.07397<p>Finished Epoch: 85, Training Loss:    2.10183<p>Finished Epoch: 86, Training Loss:    3.19542<p>Finished Epoch: 87, Training Loss:    2.30997<p>Finished Epoch: 88, Training Loss:    2.18371<p>Finished Epoch: 89, Training Loss:    2.05732<p>Finished Epoch: 90, Training Loss:    3.41737<p>Finished Epoch: 91, Training Loss:    2.12431<p>Finished Epoch: 92, Training Loss:    1.89190<p>Finished Epoch: 93, Training Loss:    1.77101<p>Finished Epoch: 94, Training Loss:    2.21776<p>Finished Epoch: 95, Training Loss:    5.03328<p>Finished Epoch: 96, Training Loss:    1.76107<p>Finished Epoch: 97, Training Loss:    2.43333<p>Finished Epoch: 98, Training Loss:    2.20084<p>Finished Epoch: 99, Training Loss:    2.95178<p>Finished Epoch: 100, Training Loss:    2.37851"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold9 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    4.24030<p>Finished Epoch: 02, Training Loss:    3.03262<p>Finished Epoch: 03, Training Loss:    2.90961<p>Finished Epoch: 04, Training Loss:    2.82350<p>Finished Epoch: 05, Training Loss:    2.11450<p>Finished Epoch: 06, Training Loss:    2.39474<p>Finished Epoch: 07, Training Loss:    2.66720<p>Finished Epoch: 08, Training Loss:    3.95616<p>Finished Epoch: 09, Training Loss:    2.29522<p>Finished Epoch: 10, Training Loss:    2.09488<p>Finished Epoch: 11, Training Loss:    2.58513<p>Finished Epoch: 12, Training Loss:    2.34235<p>Finished Epoch: 13, Training Loss:    2.27820<p>Finished Epoch: 14, Training Loss:    2.48628<p>Finished Epoch: 15, Training Loss:    3.03721<p>Finished Epoch: 16, Training Loss:    2.45939<p>Finished Epoch: 17, Training Loss:    3.27746<p>Finished Epoch: 18, Training Loss:    1.91097<p>Finished Epoch: 19, Training Loss:    1.94460<p>Finished Epoch: 20, Training Loss:    3.78682<p>Finished Epoch: 21, Training Loss:    2.26040<p>Finished Epoch: 22, Training Loss:    2.47227<p>Finished Epoch: 23, Training Loss:    2.29795<p>Finished Epoch: 24, Training Loss:    2.07775<p>Finished Epoch: 25, Training Loss:    3.10348<p>Finished Epoch: 26, Training Loss:    2.35326<p>Finished Epoch: 27, Training Loss:    3.10924<p>Finished Epoch: 28, Training Loss:    2.28895<p>Finished Epoch: 29, Training Loss:    2.45137<p>Finished Epoch: 30, Training Loss:    1.86595<p>Finished Epoch: 31, Training Loss:    1.70733<p>Finished Epoch: 32, Training Loss:    2.01601<p>Finished Epoch: 33, Training Loss:    2.47144<p>Finished Epoch: 34, Training Loss:    3.29083<p>Finished Epoch: 35, Training Loss:    2.51843<p>Finished Epoch: 36, Training Loss:    2.50653<p>Finished Epoch: 37, Training Loss:    2.22658<p>Finished Epoch: 38, Training Loss:    3.10333<p>Finished Epoch: 39, Training Loss:    6.97531<p>Finished Epoch: 40, Training Loss:    2.16535<p>Finished Epoch: 41, Training Loss:    5.05239<p>Finished Epoch: 42, Training Loss:    2.09459<p>Finished Epoch: 43, Training Loss:    3.75377<p>Finished Epoch: 44, Training Loss:    2.08741<p>Finished Epoch: 45, Training Loss:    2.76228<p>Finished Epoch: 46, Training Loss:    3.03156<p>Finished Epoch: 47, Training Loss:    2.04642<p>Finished Epoch: 48, Training Loss:    2.50260<p>Finished Epoch: 49, Training Loss:    2.40967<p>Finished Epoch: 50, Training Loss:    2.96881<p>Finished Epoch: 51, Training Loss:    5.81117<p>Finished Epoch: 52, Training Loss:    2.10923<p>Finished Epoch: 53, Training Loss:    2.03227<p>Finished Epoch: 54, Training Loss:    4.16077<p>Finished Epoch: 55, Training Loss:    3.41017<p>Finished Epoch: 56, Training Loss:    2.00943<p>Finished Epoch: 57, Training Loss:    1.92833<p>Finished Epoch: 58, Training Loss:    2.39975<p>Finished Epoch: 59, Training Loss:    2.09894<p>Finished Epoch: 60, Training Loss:    1.82669<p>Finished Epoch: 61, Training Loss:    2.07564<p>Finished Epoch: 62, Training Loss:    2.21659<p>Finished Epoch: 63, Training Loss:    2.01839<p>Finished Epoch: 64, Training Loss:    2.63226<p>Finished Epoch: 65, Training Loss:    2.43871<p>Finished Epoch: 66, Training Loss:    2.32307<p>Finished Epoch: 67, Training Loss:    1.80407<p>Finished Epoch: 68, Training Loss:    1.71059<p>Finished Epoch: 69, Training Loss:    2.49050<p>Finished Epoch: 70, Training Loss:    2.30219<p>Finished Epoch: 71, Training Loss:    2.04713<p>Finished Epoch: 72, Training Loss:    2.51263<p>Finished Epoch: 73, Training Loss:    2.63388<p>Finished Epoch: 74, Training Loss:    2.32507<p>Finished Epoch: 75, Training Loss:    4.27560<p>Finished Epoch: 76, Training Loss:    1.84022<p>Finished Epoch: 77, Training Loss:    2.88416<p>Finished Epoch: 78, Training Loss:    3.27687<p>Finished Epoch: 79, Training Loss:    2.51366<p>Finished Epoch: 80, Training Loss:    1.98646<p>Finished Epoch: 81, Training Loss:    2.61194<p>Finished Epoch: 82, Training Loss:    2.11970<p>Finished Epoch: 83, Training Loss:    2.52721<p>Finished Epoch: 84, Training Loss:    2.19889<p>Finished Epoch: 85, Training Loss:    4.26824<p>Finished Epoch: 86, Training Loss:    2.20230<p>Finished Epoch: 87, Training Loss:    1.68786<p>Finished Epoch: 88, Training Loss:    2.27278<p>Finished Epoch: 89, Training Loss:    2.22852<p>Finished Epoch: 90, Training Loss:    1.88352<p>Finished Epoch: 91, Training Loss:    2.65009<p>Finished Epoch: 92, Training Loss:    2.18402<p>Finished Epoch: 93, Training Loss:    2.07809<p>Finished Epoch: 94, Training Loss:    1.92901<p>Finished Epoch: 95, Training Loss:    2.10377<p>Finished Epoch: 96, Training Loss:    2.72556<p>Finished Epoch: 97, Training Loss:    2.17371<p>Finished Epoch: 98, Training Loss:    1.95230<p>Finished Epoch: 99, Training Loss:    3.07189<p>Finished Epoch: 100, Training Loss:    1.80103"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold10 Start!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finished Epoch: 01, Training Loss:    3.76487<p>Finished Epoch: 02, Training Loss:    2.87415<p>Finished Epoch: 03, Training Loss:    2.91087<p>Finished Epoch: 04, Training Loss:    3.19506<p>Finished Epoch: 05, Training Loss:    2.88219<p>Finished Epoch: 06, Training Loss:    2.54357<p>Finished Epoch: 07, Training Loss:    2.65990<p>Finished Epoch: 08, Training Loss:    3.01060<p>Finished Epoch: 09, Training Loss:    3.13872<p>Finished Epoch: 10, Training Loss:    2.40867<p>Finished Epoch: 11, Training Loss:    2.77259<p>Finished Epoch: 12, Training Loss:    3.04868<p>Finished Epoch: 13, Training Loss:    2.89663<p>Finished Epoch: 14, Training Loss:    2.50424<p>Finished Epoch: 15, Training Loss:    1.95699<p>Finished Epoch: 16, Training Loss:    2.24986<p>Finished Epoch: 17, Training Loss:    2.51768<p>Finished Epoch: 18, Training Loss:    2.17632<p>Finished Epoch: 19, Training Loss:    3.15474<p>Finished Epoch: 20, Training Loss:    2.38508<p>Finished Epoch: 21, Training Loss:    2.17777<p>Finished Epoch: 22, Training Loss:    3.78004<p>Finished Epoch: 23, Training Loss:    3.28151<p>Finished Epoch: 24, Training Loss:    2.70358<p>Finished Epoch: 25, Training Loss:    2.17260<p>Finished Epoch: 26, Training Loss:    3.36780<p>Finished Epoch: 27, Training Loss:    2.26318<p>Finished Epoch: 28, Training Loss:    2.20749<p>Finished Epoch: 29, Training Loss:    2.31583<p>Finished Epoch: 30, Training Loss:    2.04824<p>Finished Epoch: 31, Training Loss:    2.20876<p>Finished Epoch: 32, Training Loss:    2.21904<p>Finished Epoch: 33, Training Loss:    2.70619<p>Finished Epoch: 34, Training Loss:    3.38617<p>Finished Epoch: 35, Training Loss:    2.58563<p>Finished Epoch: 36, Training Loss:    3.21013<p>Finished Epoch: 37, Training Loss:    3.12135<p>Finished Epoch: 38, Training Loss:    2.29237<p>Finished Epoch: 39, Training Loss:    2.20865<p>Finished Epoch: 40, Training Loss:    2.31555<p>Finished Epoch: 41, Training Loss:    2.36680<p>Finished Epoch: 42, Training Loss:    2.78277<p>Finished Epoch: 43, Training Loss:    2.05670<p>Finished Epoch: 44, Training Loss:    2.42847<p>Finished Epoch: 45, Training Loss:    3.74534<p>Finished Epoch: 46, Training Loss:    2.70166<p>Finished Epoch: 47, Training Loss:    2.12446<p>Finished Epoch: 48, Training Loss:    2.58774<p>Finished Epoch: 49, Training Loss:    2.47685<p>Finished Epoch: 50, Training Loss:    2.20577<p>Finished Epoch: 51, Training Loss:    2.92302<p>Finished Epoch: 52, Training Loss:    2.02292<p>Finished Epoch: 53, Training Loss:    2.84097<p>Finished Epoch: 54, Training Loss:    2.39466<p>Finished Epoch: 55, Training Loss:    2.02562<p>Finished Epoch: 56, Training Loss:    2.23755<p>Finished Epoch: 57, Training Loss:    2.25950<p>Finished Epoch: 58, Training Loss:    2.70300<p>Finished Epoch: 59, Training Loss:    2.73456<p>Finished Epoch: 60, Training Loss:    2.18622<p>Finished Epoch: 61, Training Loss:    2.49952<p>Finished Epoch: 62, Training Loss:    2.26532<p>Finished Epoch: 63, Training Loss:    2.01544<p>Finished Epoch: 64, Training Loss:    2.23394<p>Finished Epoch: 65, Training Loss:    1.93119<p>Finished Epoch: 66, Training Loss:    2.15471<p>Finished Epoch: 67, Training Loss:    2.06279<p>Finished Epoch: 68, Training Loss:    1.97491<p>Finished Epoch: 69, Training Loss:    2.03334<p>Finished Epoch: 70, Training Loss:    2.18807<p>Finished Epoch: 71, Training Loss:    1.72658<p>Finished Epoch: 72, Training Loss:    1.96504<p>Finished Epoch: 73, Training Loss:    2.44662<p>Finished Epoch: 74, Training Loss:    2.54766<p>Finished Epoch: 75, Training Loss:    2.15953<p>Finished Epoch: 76, Training Loss:    2.23509<p>Finished Epoch: 77, Training Loss:    7.69920<p>Finished Epoch: 78, Training Loss:    2.04008<p>Finished Epoch: 79, Training Loss:    1.93328<p>Finished Epoch: 80, Training Loss:    2.37117<p>Finished Epoch: 81, Training Loss:    3.25485<p>Finished Epoch: 82, Training Loss:    2.17500<p>Finished Epoch: 83, Training Loss:    3.48491<p>Finished Epoch: 84, Training Loss:    1.97069<p>Finished Epoch: 85, Training Loss:    2.24668<p>Finished Epoch: 86, Training Loss:    1.98327<p>Finished Epoch: 87, Training Loss:    2.75736<p>Finished Epoch: 88, Training Loss:    2.51047<p>Finished Epoch: 89, Training Loss:    2.34293<p>Finished Epoch: 90, Training Loss:    2.50114<p>Finished Epoch: 91, Training Loss:    2.19691<p>Finished Epoch: 92, Training Loss:    1.82505<p>Finished Epoch: 93, Training Loss:    2.93825<p>Finished Epoch: 94, Training Loss:    2.24734<p>Finished Epoch: 95, Training Loss:    1.59274<p>Finished Epoch: 96, Training Loss:    1.96773<p>Finished Epoch: 97, Training Loss:    2.57483<p>Finished Epoch: 98, Training Loss:    2.03530<p>Finished Epoch: 99, Training Loss:    1.97140<p>Finished Epoch: 100, Training Loss:    1.87606"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28570/2790633555.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_28570/3433469541.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_28570/2790633555.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.31079994923644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "# X = dataset\n",
    "# y = labels\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0) # shuffle=Falseだとrandom_stateは何か数字を設定しても意味ないらしい\n",
    "\n",
    "mean_acc = 0\n",
    "\n",
    "dataset = HCU_Dataset(data_tensor_list, labels_tensor)\n",
    "\n",
    "for Fold, (train_index, test_index) in enumerate(skf.split(data_tensor_list, labels_tensor)):\n",
    "    print(f\"Fold{Fold+1} Start!\")\n",
    "    # Prepare Open train Dataset\n",
    "    # open_train_index = [i for i in train_index if i <= split_idx]\n",
    "    # open_train_set = torch.utils.data.Subset(dataset, open_train_index)\n",
    "    # open_test_set = torch.utils.data.Subset(dataset, test_index)\n",
    "    # Prepare Close train Dataset\n",
    "    train_set = torch.utils.data.Subset(dataset, train_index)\n",
    "    test_set = torch.utils.data.Subset(dataset, test_index) # openの場合も同じ\n",
    "\n",
    "    # Unknown_label = close_num + 1\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "    model = model.to(device)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    from fastprogress.fastprogress import master_bar, progress_bar\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    model.train()\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in mb:\n",
    "        for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "            signals = torch.tensor(signals)\n",
    "            signals = signals.float()\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # print(signals.size())\n",
    "            outputs = model(signals)\n",
    "            outputs = outputs.to(device)\n",
    "            # print(outputs)\n",
    "            loss = triple_joint_loss(outputs, labels, alpha) # will check the shapes of outputs and labels\n",
    "            # test_loss = triple_joint_loss(signals, one_hot_labels, alpha) # from test_loader?\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_centloss.zero_grad()\n",
    "            loss.backward()\n",
    "            for param in center_loss.parameters():\n",
    "                param.grad.data *= (1./alpha) # 98.98%を出したときはこれを書いていなかった→追加しても問題なし．\n",
    "            optimizer.step()\n",
    "            optimizer_centloss.step()\n",
    "        mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "\n",
    "    # For Confusion Matrix\n",
    "    # thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.999]\n",
    "    model.eval()\n",
    "    # for threshold in thresholds:\n",
    "    predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "    one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "    with torch.no_grad():\n",
    "      n_correct = 0\n",
    "      n_samples = 0\n",
    "      softmax = nn.Softmax()\n",
    "      for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "        signals = torch.tensor(signals)\n",
    "        signals = signals.float()\n",
    "        signals = signals.to(device)\n",
    "        one_hot_labels = one_hot_labels.to(device)\n",
    "        # print(len(one_hot_labels))\n",
    "        outputs = model(signals)\n",
    "        # if i == 1:\n",
    "        \n",
    "          # print(outputs)\n",
    "        for j, out in enumerate(outputs):\n",
    "          outputs[j] = softmax(out)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "        \"\"\"\"\"\"\n",
    "        # for idx in range(len(_)):\n",
    "          # if _[idx] < threshold:\n",
    "            # predicted[idx] = Unknown_label # 15, 20, 25\n",
    "        \"\"\"\"\"\"\n",
    "        # print(_, predicted, one_hot_labels)\n",
    "\n",
    "        n_samples += one_hot_labels.size(0) # add batch_size\n",
    "        n_correct += (predicted == one_hot_labels).sum().item()\n",
    "        \n",
    "        predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "        one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "        predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "        one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "        \n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        # print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
    "      with open(\"cross_val_result_HCU_close.txt\", \"a\") as f:\n",
    "        f.write(f\"Fold{Fold+1}\\n\")\n",
    "        f.write(classification_report(one_hot_labels_list, predicted_lists, digits=4) + \"\\n\")\n",
    "\n",
    "\n",
    "      cm = confusion_matrix(one_hot_labels_list, predicted_lists)\n",
    "      sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues')\n",
    "      plt.xlabel(\"Predicted Label\", fontsize=13)\n",
    "      plt.ylabel(\"Ground Truth\", fontsize=13)\n",
    "      fig_name = \"cross_val_Fold{}_close.png\".format(Fold)\n",
    "      plt.savefig(\"./figure/HCU_cross_val_close/\" + fig_name)\n",
    "      plt.close()\n",
    "    \n",
    "    # if threshold == 0.7:\n",
    "    mean_acc += acc\n",
    "print(mean_acc / 10.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3f59b86193daf02ac44c2d7d891a49d755eb44400e9ea36eaea4c9328767f1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
