{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from tsai.imports import *\n",
    "from tsai.models.layers import *\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import signal\n",
    "from PyEMD import EMD\n",
    "from PyEMD import EEMD\n",
    "import pywt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 12\n",
    "close_num = 5 # 5, 7, 9, 11 注意（close numを使ってるとこと整合性とれてるか）\n",
    "batch_size = 64\n",
    "learning_rate = 0.00001\n",
    "num_epochs = 300\n",
    "sequence_len = 250 * 5 # sampling_rate * second　matlabで250Hzにresampleされているはず\n",
    "overlap = int(sequence_len * 0.3)\n",
    "alpha = 0.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### マルチレベルの要素に対してMADを適用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "def universal_wavelet(data):\n",
    "    coeffs = pywt.wavedec(data,'db8',level=6)\n",
    "    coeffs_flat = []\n",
    "    # counter = 0\n",
    "\n",
    "    for i in range(len(coeffs)):\n",
    "        flat = coeffs[i].flatten()\n",
    "        N_samples = len(flat)\n",
    "        mad = median_abs_deviation(flat, axis=None)\n",
    "        hat_sigma = mad / 0.6745 # estimate of standard deviation\n",
    "        thre_universal = hat_sigma * np.sqrt(2 * np.log(N_samples))\n",
    "    # have calculated threshold value so far\n",
    "\n",
    "    # need to shrink coeffs while looping lists\n",
    "    for i in range(len(coeffs)):\n",
    "        for j in range(len(coeffs[i])):\n",
    "            for k in range(len(coeffs[i][j])):\n",
    "                coeff = coeffs[i][j][k]\n",
    "                if np.abs(coeff) > thre_universal:\n",
    "                    coeffs[i][j][k] = np.sign(coeff) * (np.abs(coeff) - thre_universal)\n",
    "                else:\n",
    "                    coeffs[i][j][k] = 0\n",
    "    \n",
    "    rec = pywt.waverec(coeffs, 'db8')\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(end_idx, sequence_len, overlap, data_list):\n",
    "    \"\"\"\n",
    "    データのセグメンテーションを行う\n",
    "    segmentation(len(data_np_unfil_norm), sequence_len, overlap, data_list)\n",
    "    \"\"\"\n",
    "    seg_list = []\n",
    "\n",
    "    for data in data_list:\n",
    "        n = 0\n",
    "        n_stop = sequence_len\n",
    "        data_segs = []\n",
    "        while n_stop < end_idx:\n",
    "            n_start = 0 + ((sequence_len - 1) - (overlap - 1)) * n\n",
    "            n_stop = n_start + sequence_len\n",
    "            seg = data[n_start:n_stop].copy()\n",
    "            if len(seg) == sequence_len:\n",
    "                data_segs.append([seg])\n",
    "            n += 1\n",
    "        seg_list.append(data_segs)\n",
    "    return seg_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sampling rate 250Hz 5sで1250 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "data_list = []\n",
    "seg_list = []\n",
    "\n",
    "for i in range(1, 12 + 1):\n",
    "    scaler = StandardScaler()\n",
    "    file_path = \"./data/Keio Hospital/BPF_distance%02d.csv\" % i\n",
    "    csv = pd.read_csv(file_path)\n",
    "    csv = csv.to_numpy()\n",
    "    csv = scaler.fit_transform(csv)\n",
    "    csv = universal_wavelet(csv) # waveletを用いない場合はコメントアウト\n",
    "    scaler = MinMaxScaler()\n",
    "    csv = scaler.fit_transform(csv)\n",
    "\n",
    "    data_list.append(csv[:, 1]) # waveletを用いない場合はコメントアウト\n",
    "    # data_list.append(csv) # waveletを用いる場合はコメントアウト\n",
    "seg_list = segmentation(len(csv), sequence_len, overlap, data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 1, 1250)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_re = np.reshape(seg_list, (3072, 1, 1250))\n",
    "seg_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(seg_list)):\n",
    "    for j in range(len(seg_list[i])):\n",
    "        if i <= close_num:\n",
    "            labels.append(i)\n",
    "        else:\n",
    "            labels.append(close_num + 1) # for open set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 1, 1250)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3072, 1, 1250]), torch.Size([3072]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = []\n",
    "# for i in range(len(seg_list)): # waveletありのとき\n",
    "    # data_set.extend(seg_list[i])　\n",
    "for i in range(len(seg_re)): # waveletなしのとき\n",
    "    data_set.append(seg_re[i])\n",
    "\n",
    "data_tensor_list = torch.tensor(data_set)\n",
    "labels_tensor = torch.tensor(labels)\n",
    "data_tensor_list.shape, labels_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 6, 6, 6])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(Module):\n",
    "    def __init__(self, ni, nf, ks=40, bottleneck=True):\n",
    "        ks = [ks // (2**i) for i in range(3)]\n",
    "        ks = [k if k % 2 != 0 else k - 1 for k in ks]  # ensure odd ks\n",
    "        bottleneck = bottleneck if ni > 1 else False\n",
    "        self.bottleneck = Conv1d(ni, nf, 1, bias=False) if bottleneck else noop\n",
    "        self.convs = nn.ModuleList([Conv1d(nf if bottleneck else ni, nf, k, bias=False) for k in ks])\n",
    "        self.maxconvpool = nn.Sequential(*[nn.MaxPool1d(3, stride=1, padding=1), Conv1d(ni, nf, 1, bias=False)])\n",
    "        self.concat = Concat()\n",
    "        self.bn = BN1d(nf * 4)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x\n",
    "        x = self.bottleneck(input_tensor)\n",
    "        x = self.concat([l(x) for l in self.convs] + [self.maxconvpool(input_tensor)])\n",
    "        return self.act(self.bn(x))\n",
    "\n",
    "\n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionBlock(Module):\n",
    "    def __init__(self, ni, nf=32, residual=True, depth=6, **kwargs):\n",
    "        self.residual, self.depth = residual, depth\n",
    "        self.inception, self.shortcut = nn.ModuleList(), nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            self.inception.append(InceptionModule(ni if d == 0 else nf * 4, nf, **kwargs))\n",
    "            if self.residual and d % 3 == 2: \n",
    "                n_in, n_out = ni if d == 2 else nf * 4, nf * 4\n",
    "                self.shortcut.append(BN1d(n_in) if n_in == n_out else ConvBlock(n_in, n_out, 1, act=None))\n",
    "        self.add = Add()\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inception[d](x)\n",
    "            if self.residual and d % 3 == 2: res = x = self.act(self.add(x, self.shortcut[d//3](res)))\n",
    "        return x\n",
    "\n",
    "    \n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionTime(Module):\n",
    "    def __init__(self, c_in, c_out, seq_len=None, nf=32, nb_filters=None, **kwargs):\n",
    "        nf = ifnone(nf, nb_filters) # for compatibility\n",
    "        self.inceptionblock = InceptionBlock(c_in, nf, **kwargs) # c_in is input channel num of conv1d\n",
    "        self.gap = GAP1d(1)\n",
    "        self.fc = nn.Linear(nf * 4, c_out) # c_out is 1d output size \n",
    "        self.fc_tsne = nn.Linear(c_out, 2)\n",
    "        self.two_vecs_train = [] # list is faster in appending\n",
    "        self.two_vecs_test = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inceptionblock(x)\n",
    "        x = self.gap(x)\n",
    "        # if self.training:\n",
    "        #     self.two_vecs_train.append(two_dimensional_vec.tolist()) # あとでネストしたものをまとめてtensorかndarrayに変換するため\n",
    "        # else:\n",
    "        #     self.two_vecs_test.append(two_dimensional_vec.tolist())\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def feature_save_train(self, x):\n",
    "        x = self.fc_tsne(x)\n",
    "        self.two_vecs_train.append(x)\n",
    "    \n",
    "    def feature_save_test(self, x):\n",
    "        x = self.fc_tsne(x)\n",
    "        self.two_vecs_test.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCU_Dataset(Dataset):\n",
    "    def __init__(self, dataset, labels) -> None:\n",
    "        # super().__init__()\n",
    "        self.radar_heartbeat = dataset\n",
    "        self.labels = labels\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "          idx = idx.tolist()        \n",
    "        return self.radar_heartbeat[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.radar_heartbeat)\n",
    "\n",
    "\n",
    "dataset = HCU_Dataset(data_tensor_list, labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import log\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def softmax_loss(outputs, labels):\n",
    "    loss = 0\n",
    "    batch_size = len(labels)\n",
    "    logsoftmax_out = log(softmax(outputs))\n",
    "    for idx in range(batch_size):\n",
    "        loss += 1.0 - logsoftmax_out[idx][labels[idx]]\n",
    "    \n",
    "    return loss / batch_size\n",
    "\n",
    "\n",
    "from center_loss import CenterLoss\n",
    "center_loss = CenterLoss(num_classes=close_num + 1, feat_dim=close_num + 1, use_gpu=True) # 入出力が同じだと一見変な感じがするが，交差エントロピーと違ってcenterlossを使うと最初から決めていれば，モデルの出力サイズを必ずしもクラス数に一致させる必要がないからfeat_dimを任意に設定できる．\n",
    "optimizer_centloss = torch.optim.SGD(center_loss.parameters(), lr=0.05)\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type='cosface', eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 32.0 if not s else s\n",
    "            self.m = 0.2 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.fc.to(device)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        # logを引き算に変えて計算\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L)\n",
    "\n",
    "cos_loss = AngularPenaltySMLoss(close_num + 1, close_num + 1, loss_type=\"cosface\") # center_lossと同じ理由でin_featuresはクラス数でよい．\n",
    "\n",
    "\n",
    "def triple_joint_loss(output, label, alpha):\n",
    "    # alpha: hyper parameter\n",
    "    output_only_truth = []\n",
    "    for idx, x in enumerate(output):\n",
    "        # x = x[labels[idx]] グローバル変数でlabelsが効いていただけで本来はlabelが意図していた書き方\n",
    "        x = x[label[idx]]\n",
    "        x = torch.tensor(x).to(device)\n",
    "        output_only_truth.append([x])\n",
    "    output_only_truth = torch.tensor(output_only_truth)\n",
    "    output_only_truth = output_only_truth.float()\n",
    "    output_only_truth = output_only_truth.to(device)\n",
    "    # print(output.is_cuda, output_only_truth.is_cuda, label.is_cuda)\n",
    "\n",
    "    return softmax_loss(output, label) + alpha * center_loss(output, label)\n",
    "    # return softmax_loss(output, label) + alpha * center_loss(output, label) + cos_loss(output, label)\n",
    "    # return cos_loss(output_only_truth, label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Open set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_832/3355372790.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_832/3263101318.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_832/3355372790.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.846567113668094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "# X = dataset\n",
    "# y = labels\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0) # shuffle=Falseだとrandom_stateは何か数字を設定しても意味ないらしい\n",
    "num_epochs = 150\n",
    "mean_acc = 0\n",
    "split_idx = 1535 # 5\n",
    "# split_idx = 2047 # 7\n",
    "# split_idx = 2559 # 9\n",
    "\n",
    "dataset = HCU_Dataset(data_tensor_list, labels_tensor)\n",
    "\n",
    "for Fold, (train_index, test_index) in enumerate(skf.split(data_tensor_list, labels_tensor)):\n",
    "    print(f\"Fold{Fold+1} Start!\")\n",
    "    # Prepare Open train Dataset\n",
    "    open_train_index = [i for i in train_index if i <= split_idx]\n",
    "    open_train_set = torch.utils.data.Subset(dataset, open_train_index)\n",
    "    open_test_set = torch.utils.data.Subset(dataset, test_index)\n",
    "    # Prepare Close train Dataset\n",
    "    # train_set = torch.utils.data.Subset(dataset, train_index)\n",
    "    # test_set = torch.utils.data.Subset(dataset, test_index) # openの場合も同じ\n",
    "\n",
    "    Unknown_label = close_num + 1\n",
    "\n",
    "    train_loader = DataLoader(dataset=open_train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=open_test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    from fastprogress.fastprogress import master_bar, progress_bar\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    model.train()\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in mb:\n",
    "        for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "            signals = torch.tensor(signals)\n",
    "            signals = signals.float()\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # print(signals.size())\n",
    "            outputs = model(signals)\n",
    "            outputs = outputs.to(device)\n",
    "            # print(outputs)\n",
    "            loss = triple_joint_loss(outputs, labels, alpha) # will check the shapes of outputs and labels\n",
    "            # loss = criterion(outputs, labels)\n",
    "            # test_loss = triple_joint_loss(signals, one_hot_labels, alpha) # from test_loader?\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_centloss.zero_grad()\n",
    "            loss.backward()\n",
    "            for param in center_loss.parameters():\n",
    "                param.grad.data *= (1./alpha) # 98.98%を出したときはこれを書いていなかった→追加しても問題なし．\n",
    "            optimizer.step()\n",
    "            optimizer_centloss.step()\n",
    "        mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "\n",
    "    # For Confusion Matrix\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    model.eval()\n",
    "    for threshold in thresholds:\n",
    "      predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "      one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "      with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        softmax = nn.Softmax()\n",
    "        for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "          signals = torch.tensor(signals)\n",
    "          signals = signals.float()\n",
    "          signals = signals.to(device)\n",
    "          one_hot_labels = one_hot_labels.to(device)\n",
    "          # print(len(one_hot_labels))\n",
    "          outputs = model(signals)\n",
    "          # if i == 1:\n",
    "          \n",
    "            # print(outputs)\n",
    "          for j, out in enumerate(outputs):\n",
    "            outputs[j] = softmax(out)\n",
    "\n",
    "          _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "          \n",
    "          for idx in range(len(_)):\n",
    "            if _[idx] < threshold:\n",
    "              predicted[idx] = Unknown_label # 15, 20, 25\n",
    "          # print(_, predicted, one_hot_labels)\n",
    "\n",
    "          n_samples += one_hot_labels.size(0) # add batch_size\n",
    "          n_correct += (predicted == one_hot_labels).sum().item()\n",
    "          \n",
    "          predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "          one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "          predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "          one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "          \n",
    "          acc = 100.0 * n_correct / n_samples\n",
    "          # print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
    "        with open(\"./results/new/cross_val_result_HCU_BPF_unival_open_level6.txt\", \"a\") as f:\n",
    "          f.write(f\"Fold{Fold+1}, Threshold{threshold}\\n\")\n",
    "          f.write(classification_report(one_hot_labels_list, predicted_lists, digits=4) + \"\\n\")\n",
    "\n",
    "\n",
    "        cm = confusion_matrix(one_hot_labels_list, predicted_lists)\n",
    "        sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues')\n",
    "        plt.xlabel(\"Predicted Label\", fontsize=13)\n",
    "        plt.ylabel(\"Ground Truth\", fontsize=13)\n",
    "        fig_name = \"cross_val_Fold{}_threshold{}.png\".format(Fold, threshold)\n",
    "        # plt.savefig(\"./figure/HCU_cross_val_BPF_uniwav_open6-6_level6/\" + fig_name)\n",
    "        plt.close()\n",
    "      \n",
    "      if threshold == 0.7:\n",
    "        mean_acc += acc\n",
    "print(mean_acc / 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 12), dtype=float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.empty((0, 12))\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation for Close-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "# X = dataset\n",
    "# y = labels\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0) # shuffle=Falseだとrandom_stateは何か数字を設定しても意味ないらしい\n",
    "\n",
    "mean_acc = 0\n",
    "\n",
    "dataset = HCU_Dataset(data_tensor_list, labels_tensor)\n",
    "\n",
    "for Fold, (train_index, test_index) in enumerate(skf.split(data_tensor_list, labels_tensor)):\n",
    "    print(f\"Fold{Fold+1} Start!\")\n",
    "    # Prepare Open train Dataset\n",
    "    # open_train_index = [i for i in train_index if i <= split_idx]\n",
    "    # open_train_set = torch.utils.data.Subset(dataset, open_train_index)\n",
    "    # open_test_set = torch.utils.data.Subset(dataset, test_index)\n",
    "    # Prepare Close train Dataset\n",
    "    train_set = torch.utils.data.Subset(dataset, train_index)\n",
    "    test_set = torch.utils.data.Subset(dataset, test_index) # openの場合も同じ\n",
    "\n",
    "    # Unknown_label = close_num + 1\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "    model = model.to(device)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    from fastprogress.fastprogress import master_bar, progress_bar\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    model.train()\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in mb:\n",
    "        for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "            signals = torch.tensor(signals)\n",
    "            signals = signals.float()\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # print(signals.size())\n",
    "            outputs = model(signals)\n",
    "            outputs = outputs.to(device)\n",
    "            # print(outputs)\n",
    "            loss = triple_joint_loss(outputs, labels, alpha) # will check the shapes of outputs and labels\n",
    "            # test_loss = triple_joint_loss(signals, one_hot_labels, alpha) # from test_loader?\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_centloss.zero_grad()\n",
    "            loss.backward()\n",
    "            for param in center_loss.parameters():\n",
    "                param.grad.data *= (1./alpha) # 98.98%を出したときはこれを書いていなかった→追加しても問題なし．\n",
    "            optimizer.step()\n",
    "            optimizer_centloss.step()\n",
    "        mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "\n",
    "    # For Confusion Matrix\n",
    "    # thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 0.999]\n",
    "    model.eval()\n",
    "    # for threshold in thresholds:\n",
    "    predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "    one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "    with torch.no_grad():\n",
    "      n_correct = 0\n",
    "      n_samples = 0\n",
    "      softmax = nn.Softmax()\n",
    "      for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "        signals = torch.tensor(signals)\n",
    "        signals = signals.float()\n",
    "        signals = signals.to(device)\n",
    "        one_hot_labels = one_hot_labels.to(device)\n",
    "        # print(len(one_hot_labels))\n",
    "        outputs = model(signals)\n",
    "        # if i == 1:\n",
    "        \n",
    "          # print(outputs)\n",
    "        for j, out in enumerate(outputs):\n",
    "          outputs[j] = softmax(out)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "        \"\"\"\"\"\"\n",
    "        # for idx in range(len(_)):\n",
    "          # if _[idx] < threshold:\n",
    "            # predicted[idx] = Unknown_label # 15, 20, 25\n",
    "        \"\"\"\"\"\"\n",
    "        # print(_, predicted, one_hot_labels)\n",
    "\n",
    "        n_samples += one_hot_labels.size(0) # add batch_size\n",
    "        n_correct += (predicted == one_hot_labels).sum().item()\n",
    "        \n",
    "        predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "        one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "        predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "        one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "        \n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        # print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
    "      with open(\"cross_val_result_HCU_BPF_unival_close_level6.txt\", \"a\") as f:\n",
    "        f.write(f\"Fold{Fold+1}\\n\")\n",
    "        f.write(classification_report(one_hot_labels_list, predicted_lists, digits=4) + \"\\n\")\n",
    "\n",
    "\n",
    "      cm = confusion_matrix(one_hot_labels_list, predicted_lists)\n",
    "      sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues')\n",
    "      plt.xlabel(\"Predicted Label\", fontsize=13)\n",
    "      plt.ylabel(\"Ground Truth\", fontsize=13)\n",
    "      fig_name = \"cross_val_Fold{}_close.png\".format(Fold)\n",
    "      plt.savefig(\"./figure/HCU_cross_val_BPF_uniwav_close_level6/\" + fig_name)\n",
    "      plt.close()\n",
    "    \n",
    "    # if threshold == 0.7:\n",
    "    mean_acc += acc\n",
    "print(mean_acc / 10.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tSNE definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# from sklearn.decomposition import PCA\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "def _show_2D_XXX(cls, many_dim_vector, target, title, figsize, labels):\n",
    "    many_dim_vector_reduced = cls(n_components=2, random_state=0).fit_transform(many_dim_vector)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    # levels = MaxNLocator(nbins=10).tick_values(0,10)-.0001\n",
    "    # cmap = plt.get_cmap('jet')\n",
    "    # norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
    "    # color_list = [\"#E60012\", \"#F39800\", \"#FFF100\", \"#8FC31F\",\"#009944\", \"#009E96\", \"#00A0E9\", \"#0068B7\", \"#1D2088\", \"#920783\", \"#E4007F\", \"#E5004F\"]\n",
    "    # cmap = ListedColormap(sns.color_palette(color_list, 12))\n",
    "    label = [str(i) for i in range(num_class)]\n",
    "    cax = ax.scatter(many_dim_vector_reduced[:, 0], many_dim_vector_reduced[:, 1], label=label, c=target, cmap='jet')\n",
    "    ax.set_title(title)\n",
    "    # cbar = fig.colorbar(cax, ticks=sorted(list(set(target))))\n",
    "    legend1 = ax.legend(*cax.legend_elements(num=6), loc=\"best\", title=\"Class\")\n",
    "    ax.add_artist(legend1)\n",
    "    if labels is not None:\n",
    "        cbar.ax.set_yticklabels(labels)\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def show_2D_tSNE(many_dim_vector, target, title='Feature Map Visualization', figsize=(8, 6), labels=None):\n",
    "    return _show_2D_XXX(TSNE, many_dim_vector, target, title, figsize, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_711/601606646.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_711/3263101318.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/center_loss.py:45: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
      "  distmat.addmm_(1, -2, x, self.centers.t())\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "\n",
    "mean_acc = 0\n",
    "num_epochs = 100\n",
    "\n",
    "dataset = HCU_Dataset(data_tensor_list, labels_tensor)\n",
    "close_train_size = int(0.90 * len(dataset)) # 10 cross validationと合わせる\n",
    "close_test_size = len(dataset) - close_train_size\n",
    "close_train_set, close_test_set = torch.utils.data.random_split(dataset, [close_train_size, close_test_size])\n",
    "\n",
    "# Unknown_label = close_num + 1\n",
    "\n",
    "train_loader = DataLoader(dataset=close_train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=close_test_set, batch_size=batch_size, shuffle=True) # to calculate validation loss randomly\n",
    "\n",
    "model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "mb = master_bar(range(num_epochs))\n",
    "\n",
    "# Prepare the List\n",
    "all_train_features = []\n",
    "all_train_labels = []\n",
    "all_test_features = []\n",
    "all_test_labels = []\n",
    "training_epoch_loss = []\n",
    "validation_epoch_loss = []\n",
    "\n",
    "#****************************Train*************************************\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in mb:\n",
    "    model.train()\n",
    "    training_step_loss = []\n",
    "    for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "        signals = torch.tensor(signals)\n",
    "        signals = signals.float()\n",
    "        signals = signals.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(signals)\n",
    "        outputs = outputs.to(device)\n",
    "        loss = triple_joint_loss(outputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_centloss.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in center_loss.parameters():\n",
    "            param.grad.data *= (1./alpha)\n",
    "        optimizer.step()\n",
    "        optimizer_centloss.step()\n",
    "        training_step_loss.append(loss.item())\n",
    "    mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "    training_epoch_loss.append(np.array(training_step_loss).mean())\n",
    "\n",
    "\n",
    "#*******************************Test***********************************\n",
    "    # model.eval()\n",
    "    # # for threshold in thresholds:\n",
    "    # predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "    # one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "    # with torch.no_grad():\n",
    "    #     softmax = nn.Softmax()\n",
    "    #     for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "    #         validation_step_loss = []\n",
    "    #         signals = torch.tensor(signals)\n",
    "    #         signals = signals.float()\n",
    "    #         signals = signals.to(device)\n",
    "    #         one_hot_labels = one_hot_labels.to(device)\n",
    "    #         outputs = model(signals)\n",
    "    #         validation_loss = triple_joint_loss(outputs, one_hot_labels, alpha)\n",
    "    #         validation_step_loss.append(validation_loss.item())\n",
    "    #         show_2D_tSNE(outputs, one_hot_labels)\n",
    "    #     validation_epoch_loss.append(np.array(validation_step_loss).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_train_size = int(0.90 * len(dataset)) # 10 cross validationと合わせる\n",
    "close_test_size = len(dataset) - close_train_size\n",
    "close_train_set, close_test_set = torch.utils.data.random_split(dataset, [close_train_size, close_test_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_832/651523020.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 800x600 with 1 Axes>,\n",
       " <AxesSubplot: title={'center': 'Feature Map Visualization'}>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAIQCAYAAABT6Kz3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVcElEQVR4nO3dd3hUVf7H8c9k0tsECEkooRi6IAgoSwdFqgVEXGSFoCioWFgQFF0BC+KiYgFEXP1RRMQK7rJKEWkuTZEivUiHhCCQQCCkzP39ETMypDAJM5mb5P16nnlgzj33nu/kInw8994zFsMwDAEAAABe5uPtAgAAAACJYAoAAACTIJgCAADAFAimAAAAMAWCKQAAAEyBYAoAAABTIJgCAADAFAimAAAAMAWCKQAAAEyBYAoApcTBgwdlsVg0c+ZM09Uxbtw4WSyWYq/FW+MCKBqCKVDGzJw5UxaLJc/Xs88+65Ex16xZo3Hjxuns2bMeOf61uPzn8eOPP+babhiGYmNjZbFYdPvttxdrbZMmTZLFYtH333+fb59//etfslgs+ve//12MlZnLhQsXNG7cOK1YscLbpQC4RgRToIx66aWX9PHHHzu9+vbt65Gx1qxZoxdffNGUwTRHYGCg5s6dm6t95cqVOnr0qAICAoq9pr59+8rHxyfPunLMnTtXFSpUULdu3VS9enVdvHhR/fv3L8YqXfOPf/xDFy9e9MixL1y4oBdffDHPYOrJcQG4n6+3CwDgHd26dVPz5s29XcY1SU1NVUhIiFuO1b17d33xxRd699135ev751+Nc+fOVbNmzXTq1Cm3jFMYlStXVseOHfX1119r2rRpucLxsWPHtGrVKg0ePFh+fn6SsgO2Gfn6+jr9XEv7uACKhhlTAHn67rvv1LZtW4WEhCgsLEw9evTQ9u3bnfps3bpVAwcO1HXXXafAwEDFxMTowQcf1O+//+7oM27cOI0cOVKSVLNmTcdl84MHDxZ4T6TFYtG4ceOcjmOxWLRjxw7169dP5cqVU5s2bRzb58yZo2bNmikoKEjly5dX3759deTIEZc/73333afff/9dS5cudbSlp6fryy+/VL9+/fLc54033lCrVq1UoUIFBQUFqVmzZvryyy/z/CyPP/64PvnkE9WtW1eBgYFq1qyZVq1addW67r//fiUnJ+u///1vrm3z5s2T3W7X3/72N0l539uZkJCgBx54QFWrVlVAQIAqVaqku+66SwcPHnSq7/KfdY4aNWpo4MCBjvenT5/W008/rUaNGik0NFTh4eHq1q2btmzZctXPceW9ngMHDsz3lpKcWtLT0zVmzBg1a9ZMNptNISEhatu2rZYvX+44zsGDB1WxYkVJ0osvvpjrGHndY5qZmamXX35ZcXFxCggIUI0aNfTcc8/p0qVLuT7/7bffrh9//FE333yzAgMDdd1112n27NlX/bwAioZgCpRRycnJOnXqlNMrx8cff6wePXooNDRU//znP/XCCy9ox44datOmjVOgWbp0qX777Tc98MADmjx5svr27at58+ape/fuMgxDknT33XfrvvvukyS99dZbjtsGcsJEYfXp00cXLlzQq6++qocffliSNH78eA0YMEC1a9fWpEmTNGzYMC1btkzt2rVz+faBGjVqqGXLlvr0008dbd99952Sk5PzvcXhnXfe0Y033qiXXnpJr776qnx9fdWnT588Q+TKlSs1bNgw3X///XrppZf0+++/q2vXrtq2bVuBdd1999353mYwd+5cVa9eXa1bt853/969e2v+/Pl64IEH9N577+nJJ5/UuXPndPjw4QLHzctvv/2mBQsW6Pbbb9ekSZM0cuRI/frrr2rfvr2OHz9eqGMNGTIk160kOQE7KipKkpSSkqIPP/xQHTp00D//+U+NGzdOSUlJ6tKlizZv3ixJqlixoqZNmyZJ6tWrl+NYd999d75jP/TQQxozZoyaNm2qt956S+3bt9eECRPyPM/79u3TPffco9tuu01vvvmmypUrp4EDB+b6nzQAbmIAKFNmzJhhSMrzZRiGce7cOSMiIsJ4+OGHnfZLSEgwbDabU/uFCxdyHf/TTz81JBmrVq1ytL3++uuGJOPAgQNOfQ8cOGBIMmbMmJHrOJKMsWPHOt6PHTvWkGTcd999Tv0OHjxoWK1WY/z48U7tv/76q+Hr65urPb+fx08//WRMmTLFCAsLc3yuPn36GB07djQMwzCqV69u9OjRw2nfKz9/enq60bBhQ+OWW27J9VkkGT///LOj7dChQ0ZgYKDRq1evAuvLqSMwMNBITk52tO3atcuQZIwePdrRduXP88yZM4Yk4/XXXy/w+Ff+rHNUr17diI+Pd7xPS0szsrKynPocOHDACAgIMF566aV86zCMP89ffvbu3WvYbDbjtttuMzIzMw3DMIzMzEzj0qVLTv3OnDljREdHGw8++KCjLSkpKd/PcOW4mzdvNiQZDz30kFO/p59+2pBk/PDDD06f/8o/yydPnjQCAgKMESNG5PtZABQdM6ZAGTV16lQtXbrU6SVlz4KePXtW9913n9NsqtVqVYsWLZwuowYFBTl+n5aWplOnTukvf/mLJOmXX37xSN2PPPKI0/uvv/5adrtd9957r1O9MTExql27tlO9V3Pvvffq4sWLWrhwoc6dO6eFCxfmexlfcv78Z86cUXJystq2bZvnZ2/ZsqWaNWvmeF+tWjXdddddWrx4sbKysgqs6/7771daWpq+/vprR1vODGrOLGN+9fn7+2vFihU6c+ZMgWO4IiAgQD4+2f9sZGVl6ffff1doaKjq1q17Tec7NTVVvXr1Urly5fTpp5/KarVKkqxWq/z9/SVJdrtdp0+fVmZmppo3b17k8b799ltJ0vDhw53aR4wYIUm5ZrsbNGigtm3bOt5XrFhRdevW1W+//Vak8QEUjDvCgTLq5ptvzvPhp71790qSbrnlljz3Cw8Pd/z+9OnTevHFFzVv3jydPHnSqV9ycrIbq/1TzZo1nd7v3btXhmGodu3aefbPeSjIFRUrVlSnTp00d+5cXbhwQVlZWbrnnnvy7b9w4UK98sor2rx5s9P9iXmtm5lXfXXq1NGFCxeUlJSkmJiYfMfp1q2bypcvr7lz5zru+fz000/VuHFjXX/99fnuFxAQoH/+858aMWKEoqOj9Ze//EW33367BgwYUOB4+bHb7XrnnXf03nvv6cCBA06BukKFCoU+Xo6HH35Y+/fv15o1a3IdZ9asWXrzzTe1a9cuZWRkONqv/HPgqkOHDsnHx0e1atVyao+JiVFERIQOHTrk1F6tWrVcxyhXrpxbgj6A3AimAJzY7XZJ2feZ5hVeLn/C+d5779WaNWs0cuRINWnSRKGhobLb7eratavjOAXJb+HzgmYQL5+lzKnXYrHou+++c8y0XS40NPSqdVyuX79+evjhh5WQkKBu3bopIiIiz36rV6/WnXfeqXbt2um9995TpUqV5OfnpxkzZhS4vFNR+Pn56d5779W//vUvJSYm6vDhw9q7d68mTpx41X2HDRumO+64QwsWLNDixYv1wgsvaMKECfrhhx904403Frjvlefh1Vdf1QsvvKAHH3xQL7/8ssqXLy8fHx8NGzbMpfOdl3feeUeffvqp5syZoyZNmjhtmzNnjgYOHKiePXtq5MiRioqKktVq1YQJE7R///4ijZfD1UX38/ozJclxDzUA9yKYAnASFxcnKfsBlE6dOuXb78yZM1q2bJlefPFFjRkzxtGeM+N6ufxCQLly5SQp1wNKV85aXa1ewzBUs2ZN1alTx+X98tOrVy8NGTJE69at02effZZvv6+++kqBgYFavHix0zJOM2bMyLN/Xj+XPXv2KDg42KUHwf72t7/p/fff12effaYDBw7IYrE4Hiq7mri4OI0YMUIjRozQ3r171aRJE7355puaM2eOpOzzcOU5SE9P14kTJ5zavvzyS3Xs2FEfffSRU/vZs2cVGRnpUi2XW716tZ5++mkNGzYsz1sSvvzyS1133XX6+uuvnf4MjR071qlfYb7ZqXr16rLb7dq7d6/q16/vaE9MTNTZs2dVvXr1Qn8OAO7DPaYAnHTp0kXh4eF69dVXnS6d5khKSpL050zSlTNHb7/9dq59ctYavTL8hIeHKzIyMteySe+9957L9d59992yWq168cUXc9ViGIbT0lWuCA0N1bRp0zRu3Djdcccd+fazWq2yWCxOs4oHDx7UggUL8uy/du1ap/sijxw5om+++UadO3fOd1bucq1bt1aNGjU0Z84cffbZZ2rfvr2qVq1a4D4XLlxQWlqaU1tcXJzCwsKcbj2Ii4vLdQ4++OCDXDOmVqs118/4iy++0LFjx65a/5VOnDihe++9V23atNHrr7+eZ5+8/oytX79ea9eudeoXHBwsKfefr7x0795dUu4/p5MmTZIk9ejRw6X6AXgGM6YAnISHh2vatGnq37+/mjZtqr59+6pixYo6fPiw/vvf/6p169aaMmWKwsPD1a5dO02cOFEZGRmqUqWKlixZogMHDuQ6Zs5DP88//7z69u0rPz8/3XHHHQoJCdFDDz2k1157TQ899JCaN2+uVatWac+ePS7XGxcXp1deeUWjR4/WwYMH1bNnT4WFhenAgQOaP3++Bg8erKeffrpQP4P4+Pir9unRo4cmTZqkrl27ql+/fjp58qSmTp2qWrVqaevWrbn6N2zYUF26dNGTTz6pgIAAR/h+8cUXXarJYrGoX79+evXVVyVlf3PX1ezZs0e33nqr7r33XjVo0EC+vr6aP3++EhMTnZZGeuihh/TII4+od+/euu2227RlyxYtXrw41yzo7bffrpdeekkPPPCAWrVqpV9//VWffPKJrrvuOpc+w+WefPJJJSUladSoUZo3b57TthtuuEE33HCDbr/9dn399dfq1auXevTooQMHDuj9999XgwYNdP78eUf/oKAgNWjQQJ999pnq1Kmj8uXLq2HDhmrYsGGucRs3bqz4+Hh98MEHOnv2rNq3b68NGzZo1qxZ6tmzpzp27FjozwLAjby3IAAAb7h8eaSCLF++3OjSpYths9mMwMBAIy4uzhg4cKDTkkdHjx41evXqZURERBg2m83o06ePcfz48TyX7nn55ZeNKlWqGD4+Pk5LR124cMEYNGiQYbPZjLCwMOPee+81Tp48me9yUUlJSXnW+9VXXxlt2rQxQkJCjJCQEKNevXrG0KFDjd27d7vl55HXclEfffSRUbt2bSMgIMCoV6+eMWPGjDyXRZJkDB061JgzZ46j/4033mgsX768wDGvtH37dkOSERAQYJw5cybX9iuXaTp16pQxdOhQo169ekZISIhhs9mMFi1aGJ9//rnTfllZWcYzzzxjREZGGsHBwUaXLl2Mffv25blc1IgRI4xKlSoZQUFBRuvWrY21a9ca7du3N9q3b59vHYaRe9mm9u3b57tsWc55t9vtxquvvmpUr17d8TNbuHChER8fb1SvXt3pM6xZs8Zo1qyZ4e/v73SMvM5HRkaG8eKLLxo1a9Y0/Pz8jNjYWGP06NFGWlqaU7+8znlO7Zd/XgDuYzEM7uAGAE+yWCwaOnSopkyZ4u1SAMDUuMcUAAAApkAwBQAAgCkQTAEAAGAKPJUPAB7GrfwA4BpmTAEAAGAKBFMAAACYQom/lG+323X8+HGFhYUV6mvpAAAAUDwMw9C5c+dUuXJl+fjkPy9a4oPp8ePHFRsb6+0yAAAAcBVHjhwp8OuUS3wwDQsLk5T9QcPDw71cDQAAAK6UkpKi2NhYR27LT4kPpjmX78PDwwmmAAAAJna12y55+AkAAACmQDAFAACAKRBMAQAAYAol/h5TAAAAs0tPT9fFixe9XYbHBAUFyd/f/5qPQzAFAADwELvdrn379unixYuler11wzAUFBSkWrVqFbhO6dUQTAEAADxk3759unTpkipVqqSQkJBSGU4Nw1BqaqoSExO1b98+1alTp8jHIpgCAAB4QM7l+0qVKikqKsrb5XhUSEiIJOnEiRNKT08v8mV9Hn4CAADwgJzL9zmhrbTLmRG+lntpCaYAAAAeVBov3+fFHZ+TYAoAAABTIJgCAACUQBaLRXPmzPF2GW5FMAUAADChI0eOaODAgapatar8/f0VExOjW265Rf/+97+9XZrH8FQ+AACAyezevVtt27ZVeHi4xo8fr6ZNmyo9PV3/+c9/9NRTT+nOO+/0dokewYwpALjoVKb09u/SkwnS0BPSR2ekrWmSYXi7MgClzeDBg2WxWPTLL78oPj5ejRo1UrNmzTRu3Dj99NNPee7z2GOPqUaNGgoMDFTVqlU1bNgwXbp0ybF93bp1atGihUJCQhQaGqrrr79eq1evliTt2bNHt9xyi8LDwx0L5X/xxRfF8lkvx4wpABQgy5BmnZXGJklHM/PuU89PmhQjdQsr1tIAlFInT57U6tWr9eyzzyo8PDzX9sjIyDz3Cw0N1YcffqjY2Fj98ssveuKJJxQWFqaXX35ZktS/f381bNhQ06dPl6+vr3766Sf5+flJkoYMGaKMjAx9//33CgsL05YtWxQWVvx/qRFMASAfmYbU56i04FzB/XZlSN2PSPOrSj1z/xsCAIWyc+dOGYah+vXrF2q/iRMnOn5ft25d7dq1S1999ZUjmJ44cUJPPfWUmjRpIklq2LCho/+xY8d055136uabb5akQo/tLlzKB4B8TD0tfXOVUHq5Xkel5xOlVLvnagJQ+tntRftL5KOPPlLTpk0VGRmp4OBgvfbaazp+/Lhj+5AhQzRs2DC1atVKzz33nHbs2OHY9uijj+rtt99W06ZN9fe//13r16+/5s9RFARTAMiDYUhv/C4V9vbRV3+Xqu2RkvO57A8AV3P99dfLYrFo586dLu+zbNkyDRkyRJ07d9b8+fO1YcMGPfnkk8rIyHD0efPNN7Vp0yZ17dpVq1atUpMmTfTxxx9Lkv7+979r9+7duu+++7R9+3a1adNG48ePd/tnuxqCKQDkYV96/veUXs1pu9TmoFvLAVCGREVFqU2bNvroo4+UkpKSa/upU6dyta1evVqVKlXSa6+9prZt26phw4Y6fPhwrn6NGjXSmDFj9OOPP6pLly6aOXOmY1tcXJxGjhypJUuWaMiQIZo1a5ZbP5crCKYAypRMQ1qRKn2VIv18Mf8n6t87c23jbEuXEjOu3g8A8jJ9+nTZ7XY1bdpUs2bN0rZt27Rp0yaNHz/ecR/o5erUqaMTJ07oww8/1I4dOzR+/HgtXrzYsT01NVXx8fH69ttvtWfPHi1dulRbtmxR3bp1JUmDBg3S119/rV27dul///ufVq9erdq1axfb583Bw08AyoyPz0rPnJROXDYT2sBfmlZJahfi3Hf22Wsf7/0z0tioaz8OgLKnfv36+vnnnzVmzBg999xzSkpKUrly5dSoUSNNmTIlV/9+/fpp9erVGjlypNLT09WxY0eNGDHC8UCU1WrV6dOnNWjQIP3++++KiIhQ9+7d9cYbb0iSsrKyNGzYMCUmJiokJEQdOnTQtGnTivUzS5LFMEr2CnwpKSmy2WxKTk7Oc0kFAJCy1xx96ETudh9JVklzK0sfJ0vr06SLdinFDX8zPlZOmlrp2o8DoGRKTk7WoUOHVKtWLQUHB3u7HI+7cOGC9u3bp+rVq8tmszltczWvMWMKoNS7YJeGJ+a9zf7Hq8/xvLdfi0ir+48JAKUZ95gCKPX+c05K8cISTvX9i39MACjJCKYASr3jmd75y65RoBcGBYASjGAKoNSL9s2+XF+cavlJ1xNMAaBQCKYASr07w6QQS/GO+Vj54h0PAEoDgimAUi/UR5oQXXzjWSQ9GFF84wFAaUEwBVAmPFFeei9GKlcMf+vdHy7ZeCIfAAqN5aIAlBmPls+eyfw+VTqVJdXwk7ZfkoYmuG+MOD/p/6q473gAUJYQTAGUKQE+Uo+wP9+3D5EMSU8nSmmFWFQ/QtLZy977Shpgk6ZXlnyL+X5WACgtCKYAyryh5aWHy0nfnZN+S5eq+0t1/KWnEqSVF6SsP/pV9JF6h0vDKkh1A6R96dKWNCnQIrULlsK4fA8A14RgCgCS/C3SXVd8S96yGtK5LCkhUypnlSKv+Buzln/2CwA8KTMzS0uW7NfRo+dUtWqYOneOk6+v5/9P+LXXXtPkyZN16tQp1a1bV5MnT1b79u09OibBFAAKEGZlJhSA98yevUWjRi1VYmKqoy06OkQTJ96mAQMae2zcjz76SGPGjNEbb7yhNm3a6PXXX9cdd9yhnTt3qkoVz91Iz1P5AAAAJjR79hbFxy9wCqWSlJiYqvj4BZo9e4vHxn7nnXd033336cknn1TTpk01Z84cBQYGaurUqR4bUyKYAgAAmE5mZpZGjVpaYJ9Ro5YqMzOrwD5FkZaWph07dui2225ztFmtVrVt21YbNmxw+3iXI5gCAACYzJIl+3PNlF4pMTFVS5bsd/vYCQkJysrKUqVKlZzao6KidPLkSbePdzmCKQAAgMkcPXrOrf1KCoIpAACAyVStGnb1ToXoVxgxMTGyWq06ceKEU/vJkycVFRXl9vEuRzAFAAAwmc6d4xQdHVJgn+joEHXuHOf2sQMDA9WgQQN9//33jrasrCz9+OOPuvnmm90+3uUIpgAAACbj62vVxIm3Fdhn4sTbPLae6VNPPaVPP/1UU6ZM0aZNm9S/f39dvHhRjz32mEfGy8E6pgAAACaUs06pN9YxHTRokE6ePKlXX31Vp06dUr169fTNN9+oatWqHhtTkiyGYRTi26HNJyUlRTabTcnJyQoPD7/6DgAAAMUgOTlZhw4dUq1atRQcHFzk43jrm58K68KFC9q3b5+qV68um83mtM3VvMaMKQAAgIn5+lrVvXsdb5dRLLjHFAAAAKZAMAUAAIApEEwBAABgCgRTAAAAmALBFAAAAKZAMAUAAIApEEwBAABgCgRTAAAAmALBFAAAAKZAMAUAADCxzEzp21XSB59n/5qZ6fkxFy1apFtuuUVRUVGyWCyaM2eO5wcVwRQAAMC0Zn8jVe0o9XhEGjIu+9eqHbPbPen8+fNq1KiR3nzzTc8OdAXfYh0NAAAALpn9jRQ/Ond74u9/tg+4yzNj33PPPbrnnnuyxxgwwDOD5IEZUwAAAJPJzJRGvVFwn1FvFs9l/eJEMAUAADCZJWuyZ0YLkngqu19pQjAFAAAwmaMJ7u1XUhBMAQAATKZqjHv7lRQEUwAAAJPp3EqKrlBwn+jI7H6lCcEUAADAZHx9pYlPF9xn4ojsfp6QnJystWvXau3atZKk3377TWvXrtXevXs9M+AfCKYAAAAmNOAuadaE3DOn0ZHZ7Z5aKkqS/ve//6lVq1Zq1Sp7Snbs2LFq1aqVRo/OY/0qN2IdUwAAAJMacJfUr0f20/dHE7LvKe3cynMzpTm6d+8uwzA8O0geCKYAAAAm5usrdW/n7SqKB5fyAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKXg0mE6YMEE33XSTwsLCFBUVpZ49e2r37t1OfdLS0jR06FBVqFBBoaGh6t27txITEz1ZFgAAAEzIo8F05cqVGjp0qNatW6elS5cqIyNDnTt3VmpqqqPP3//+d/3nP//RF198oZUrV+r48eO6++67PVkWAAAATMijy0UtWrTI6f3MmTMVFRWljRs3ql27dkpOTtZHH32kuXPn6pZbbpEkzZgxQ/Xr19e6dev0l7/8xZPlAQAAwESK9R7T5ORkSVL58uUlSRs3blRGRoY6derk6FOvXj1Vq1bN8RVYV7p06ZJSUlKcXgAAACj5ii2Y2u12DRs2TK1bt1bDhg0lSQkJCfL391dERIRT3+joaCUkJOR5nAkTJshmszlesbGxni4dAAAAxaDYgunQoUO1bds2zZs375qOM3r0aCUnJzteR44ccVOFAAAA5pNpl749J31wOvvXTLvnx3zuuefUsGFDhYSEqHz58rrtttu0detWj49bLMH08ccf18KFC7V8+XJVrVrV0R4TE6P09HSdPXvWqX9iYqJiYmLyPFZAQIDCw8OdXgAAAKXR7LNS1b1SjyPSkITsX6vuzW73pNWrV2vIkCFatWqVvv32W2VkZKhr164ev4XSow8/GYahJ554QvPnz9eKFStUs2ZNp+3NmjWTn5+fli1bpt69e0uSdu/ercOHD6tly5aeLA0AAMDUZp+V4o/nbk/M+rN9QIRnxl69erXT+7lz56pKlSpas2aNunbt6plB5eFgOnToUM2dO1fffPONwsLCHPeN2mw2BQUFyWazadCgQRo+fLjKly+v8PBwPfHEE2rZsiVP5AMAgDIr0y6Nusqy7qMSpX7hkm8xXP8+c+aMJCkyMtKj43g0mE6bNk2S1KFDB6f2GTNmaODAgZKkt956Sz4+Purdu7cuXbqkLl266L333vNkWQAAAKa2JDV7ZrQgiVnZ/bqHebaWrKwsPf7442ratKmaN2/u0bE8fin/agIDAzV16lRNnTrVk6UAAACUGEcz3NvvWsTHx2vPnj25Lu97gkeDKQAAAAqvqp97+xVVfHy8vv/+e61YsULXXXedZwdTMS+wDwAAgKvrHCJFWwvuE23N7ucJdrtd8fHx+u677/T999+rXr16nhnoCgRTAAAAk/H1kSZGF9xnYrTnHnyKj4/X119/rVmzZslms+nIkSM6cuSIUlNTPTPgHwimAAAAJjQgQppVOffMabQ1u91TS0VJ0pw5c3T+/Hl1795d1apVc7z+7//+z3ODintMAQAATGtARPaSUEtSsx90quqXffne00tEufIAuycQTAEAAEzM18fzS0KZBZfyAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAABPLUpb2aLd+1k/ao93KUpbHx5w4caLq1Kmj0NBQhYaGqkmTJvryyy89Pi5fSQoAAGBSm7VJi7VIqTrvaAtRqLqoq5roRo+NGxsbq/Hjx6t+/foyDEP/+te/dN9996lmzZpq1qyZx8YlmAIAAJjQZm3S18o9S5mq8452T4XT++67z+n9u+++q1mzZmn16tUeDaZcygcAADCZLGVpsRYV2GeJFhXLZf3MzEx9+OGHunjxotq1a+fRsZgxBQAAMJn92ud0+T4v53Ve+7VPdVTXIzVs2LBBHTp0UHp6uoKCgvTJJ5+oadOmHhkrB8EUAADAZFKU4tZ+RXHDDTfop59+0pkzZzRv3jwNHjxYcXFxHg2nBFMAAACTCVe4W/sVRWBgoK6//npJUps2bfTLL7/ojTfe0Ny5cz02JveYAgAAmEycailEoQX2CVWo4lSrmCqS7Ha70tPTPToGwRQAAMBkrLKqi7oW2Kezusoqq0fGf/zxx7Vo0SLt3r1bGzZs0OOPP64NGzbo/vvv98h4ObiUDwAAYEI5S0FduY5pqELV2cPrmCYlJWnQoEFKSkpSaGio6tWrp6+//lo9e/b02JgSwRQAAMC0muhGNdIN2q99SlGKwhWuONXy2Expjs8++8yjx88PwRQAAMDErLJ6bEkos+EeUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKbCOKQAAcIuTO3Zo8bBhOnvokHysVgVFRiqmcWN1ePFFBZcv7+3yUAIQTAEAwDU5sGKF5nTpInt6eq5tR1av1k9Tpijy+uv16Nat8vHhYi3yx58OAABQZOumTNHsjh3zDKWXO7V9uyaEhsqelVVMlZUi9kwp7Vsp9YPsX+2ZxTr8c889J4vFokGDBnl8LIIpAAAokpTjx7X4iSdc7p958aLerVPHgxWVQhdmS0lVpTM9pJQh2b8mVc1uLwarVq3SrFmzVKeYzhvBFAAAFMmcrl0LvU/yb79px5dfeqCaUujCbCk5XrInOrfbE7PbPRxOk5OTNWDAAL333nuy2WweHSsHwRQAABRJ0q+/Fmm/b596ys2VlEL2TOncqIL7nBvl0cv6Dz74oDp16qS77rrLY2NciYefAABAoZ05eLDI+6YeP+6+Qkqr9CW5Z0qvZE/M7hfY3e3Df/jhh/r111+1efNmtx+7IARTAABQaIlbtni7hNIt66h7+xXC/v379cwzz+jbb79VcHCw249fEIIpAAAotODISG+XULpZq7q3XyGsXbtWp0+fVuvWrR1tWVlZ+vnnnzVr1iylpaXJ19czEZJgCgAACsWemalVr7xS5P2DK1Z0YzWllH9nySe64Mv5PtHZ/dzs9ttv108//eTUNnDgQNWuXVvPP/+8x0KpRDAFAACF9Ounn2r/okVF3r/ft9+6sZpSysdXCpuY/fR9fsImZvdzs4iICDVv3typLTg4WOXLl8/V7m48lQ8AAArl52nTZCniNzhV79BBVTwcbkqN4AGSbVb2zOjlfKKz24MHeKcuD2LGFAAAuOR8YqJ+mjpVx9avl2G3F3r/Rv376+7ZxbMwfKkRPEAK7Jf99H3W0ex7Sv07e2SmtCAbNmwolnEIpgAA4KqSdu7UzHbtdPHMmUKH0qqtWqnP558rvEoVD1VXyvn4emRJKDMimAIAgAIZhqHP7747O5S6+F331dq0UedJk1S5eXNZLBYPV4jSgmAKAAAKdHDFCp3atculvj6+vrJVr677Fy+WXzGvgYmSj4efAABAgY6uXSuL1epS3+jGjRW/fDmhFEXCjCkAACiQq6H0rpkz1XjAAC7do8iYMQUAAAWKu+22q95bGlyxohr160coxTUhmAIAgAJVatpU1dq2lU9+3/hjsajliBGy+vkVb2EodQimAADgqvp8/rnK164tSY7F9XOCauMBA9R65Eiv1YbSg3tMAQDAVYXGxGjIpk3a/vnn+vWTT3Tx9GlVqF1bTQcPVvV27biED7cgmAIAAJf4BgSocf/+aty/v7dLQSnFpXwAAAAzy8yUNnwrfftB9q+ZmR4fcsSIEbJYLE6vmjVrenxcZkwBAADM6vvZ0oejpLOJf7ZFREsPTZQ6DfDo0LVq1dIPP/zgeO+b38NvbkQwBQAAMKPvZ0tvxOduP5v4Z7sHw6nValVsbKzHjp8XLuUDAACYTWZm9kxpQT4a5dHL+ocOHVJUVJSqVq2qu+66S3v37vXYWDmYMQUAADCbX5Y4X77Py5nE7H43d3f78C1btlTDhg3VoEEDHTt2TC+//LLat2+vHTt2KCIiwu3j5SCYAgAAmM2po+7tV0j33HOP0/t27dqpZs2amjlzpoYNG+aRMSUu5QMAAJhPZFX39rtGkZGRql69uvbt2+fRcQimAAAAZtO0c/bT9wUpF53drxgkJyfryJEjqlSpkkfHIZgCAACYja9v9pJQBRk0MbufBwwZMkTfffeddu/ere+//17du3eXj4+PHnjgAY+Ml4N7TAEAAMwoZymoK9cxLRedHUo9uFTUsWPHFB8fr7Nnz6pcuXK66aab9L///U+VK1f22JgSwRQAAMC8Og2QOvTLfvr+1NHse0qbdvbYTGmOhQsXevT4+fHopfxVq1bpjjvuUOXKlWWxWLRgwQKn7YZhaMyYMapUqZKCgoLUqVOnYlkjCwAAoMTw9c1eEqr74Oxfi+EbmLzFo8E0NTVVjRs31tSpU/PcPnHiRL377rt6//33tX79eoWEhKhLly5KS0vzZFkAAAAwIY9G7m7duqlbt255bjMMQ2+//bb+8Y9/6K677pIkzZ49W9HR0VqwYIH69u3rydIAAABgMl57Kv/AgQNKSEhQp06dHG02m00tWrTQ2rVr893v0qVLSklJcXoBAACg5PNaME1ISJAkRUc7r9EVHR3t2JaXCRMmyGazOV6xsbEerRMAAADFo8StYzp69GglJyc7XkeOHPF2SQAAAHADrwXTmJgYSVJiYqJTe2JiomNbXgICAhQeHu70AgAAQMnntWBas2ZNxcTEaNmyZY62lJQUrV+/Xi1btvRWWQAAAPASjz6Vf/78ee3bt8/x/sCBA9q8ebPKly+vatWqadiwYXrllVdUu3Zt1axZUy+88IIqV66snj17erIsAAAAmJBHZ0x//vln3XjjjbrxxhslScOHD9eNN96oMWPGSJJGjRqlJ554QoMHD9ZNN92k8+fPa9GiRQoMDPRkWQAAALiKAwcOqGfPnoqIiFBgYKDq1Kmj1atXe3RMj86YdujQQYZh5LvdYrHopZde0ksvveTJMgAAAEqsrMxM7V+yROeOHlVY1aqK69xZVg9/+1NSUpLatGmjli1b6ptvvlF0dLR27typChUqeHTc0vudVgAAACXcltmztXTUKKVe9rB4SHS0bps4UY0HDPDYuOPGjVOlSpX05ZdfOtrq1avnsfFylLjlogAAAMqCLbNna0F8vFMolaTUxEQtiI/XltmzPTb2okWL1KRJE3Xr1k3ly5dX/fr1NWnSJI+Nl4NgCgCASaQlJ2v95Mn6ql8/zR8wQFs/+USZly55uyx4QVZmppaOGlVgn6WjRikrM9Mj4x89elQff/yx4uLitHDhQj300EN67rnnNGXKFI+Ml4NL+QAAmMD6d9/V4uHDZWRlOdq2fvyxvh81SvcvXqyohg29WB2K2/4lS3LNlF4pNTFR+5csUZ3u3d0+vt1uV8OGDR1BtFWrVtq2bZs+/PBDPf74424fLwczpgAAeNnat9/WoqeecgqlOc6dOKHZt96qSykp1zxO0s6d+mbQIL1VrZreqlZNX99/v46uX3/Nx4X7nTt61K39CqtixYqqU6eOU1v9+vV1/Phxj4yXg2AKAIAXXTh1SktHjMi/g2Eo9eRJbfn442saZ/mYMXrv+uu1+f/+TylHjijlyBH9OneuPvrLX7S2GO4dROGEVa3q1n6F1bx5c+3fv9+pbc+ePapSpYpHxstBMAUAwIs2zZghw26/ar/dCxYUeYy1b7+tVS+/LF25hOMf75eMGKFDHl6fEoUT17mzQqKjC+wTEh2tuM6dPTL+008/rc2bN2v06NHavn27pk+frk8++URDhgzxyHg5CKYAAHhRwi+/uNQvPTW1SMdPS07WkuHDC+5ksWj9u+8W6fjwDKuvr26bOLHAPrdNnOix9UzbtWunOXPm6KuvvlLTpk31z3/+U+PHj9cjjzzikfFy8PATAABeZPX3d6lfpWbNCn3s9NRUTbvhhtwzpVcyDB1cvrzQx4dn5axT6o11TCWpb9++6tu3r0fHuBLBFAAAL6p9++0urUfZvAgzVV/166eUw4dd63y18AqvaDxggBr261fs3/zkLaXzUwEAUELU69lTETVr6uzBg/mGw2aPPKKo669XwpYt+vn995Xwyy/yDQpSXNeuavjXvyqiRg1ZLBanfRK3btWef//b5TpqdOhwDZ8CnmT19fXIklBmRDAFAMCLrH5+GvD995p1yy1KPnQo13a/0FDt+fe/9faiRUo+eNBp26GVK/XD6NEKrVRJ7ceMUbPBg2XxyX585Ifnny9UHa2uspg7UBx4+AkAAC8rd911enz3bt09d64a9u2r6MaNHdsyzp/XuePHc4XSy50/cUL/ffRR/XvQIBmGIcMwdGTNGpfHr9e7t6q2aHEtHwFwC4IpAAAm4BsQoIZ9+6pR//5K3LKlSMfYPHOm9n77rTJSU3Xx9GmX9rFYrbr388+LNB7gbgRTAAC8zDAMbZk9W1Pr1dOnPXpc07E2TJ4si9Xqcv/a3bs7Lv/DM4wy8mCZOz4nfxIBAPCypaNGaUF8vH7fs+eaj3V840b5BQWpyl/+4lL/q62ViaILCgqSYRhKLeIatCVNamqqDMNQUFBQkY/Bw08AAHjRkbVrtfaNN9x2PN8/1kVtPXKkPu/du8C+nd98U5H16rltbDjz9/dXUFCQEv9YgzQkJCTX6gmlQU74TkxMVFBQkPxdXJs3LwRTAAC86Odp0+Tj6yt7ZqZbjlf/nnuyf737bnV8+WUtf+EFWXx8nL721MffXz2mTlXThx5yy5jIX61atbRv3z6dOHGiVIbSHDkzpbVq1bqm41iMEn7jQ0pKimw2m5KTkxUeHu7tcgAAKJT3GzdW4tatbjmWj6+vnjp4UOFVqjjaEjZv1s/Tpyth0yb5Bgerfs+eajJwoAL4N7NYpaen6+LFi94uw2OuNlPqal5jxhQAAC/yDwuTLJZr/uYli4+P/rpggVMolaSYJk10+7Rp13RsXDt/f/9rusRdVvDwEwAAXtSgT5/C7WCxKKBcOfn88ZWUVn9/1b79dj118KDqFPBEv2EY+vjjTYqOfl1hYePVr9+Xysqy59sf8AYu5QMA4EVpycmaUreuLpw6JSMrq8C+tmrV9Oi2bQoIC5NhGMpKT5fV3/+q9y6+/PJKjRmzIs9trVtX1Y8/Dipq+YBLXM1rzJgCAOBFgTab4pcvV3jVqpKy7xPVFUHTGhioliNGOEKpJFksFvkGBFw1lA4fvijfUCpJ//vfUd1yy4xr+xCAmzBjCgCACdgzM7X7P//RgWXLZNjtqtamjaq1bSvDbldYpUqyFuH+xDNnLqp8edfWKbXbx5Tqp8bhXTz8BABACeLj66v6vXqpfq9ebjvmk09+53Lff/zje40ff5vbxgaKgkv5AACUUt9/f8Dlvl98sdODlQCuIZgCAFBKFebKfM2a5TxXCOAigikAAKVUz551Xe7773/f58FKANcQTAEAKKXefLOLS/18fKSAAB47gfcRTAEA8IDziYn6efp0/W/iRO2cP19ZGRnFXkNQkJ/GjGl31X6ZmWOKoRrg6vjfIwAA3MiemaklTz+tn6ZOlT0rSxYfHxlZWQquWFF3zZhR4LczuduOHUmaOvWnfLffeWdtffNNv2KrB7gaZkwBAHCjb4cO1fp33pE9M1MyDMe3OV1IStK8u+7SwZUri6UOwzB0992f6ezZtDy3W60WxcVVKJZaAFcRTAEAcJOEzZu18YMP8t1u2O1a/sILxVLL8uUHtXv378rKyvt7dLKyDH3wwUalpqYXSz2AKwimAABcgwunTunUnj3aMHWqPmzZsuDOhqHDq1fr3PHjHq9r/fqj8rnKv/KpqRnateuUx2sBXMU9pgAAFNLJ7du1dtIk/bZkiVKOHi30/hdPn1ZY5coeqOxPR46kyG6/ej9fX+aoYB4EUwAAriJp1y5tmDxZx3/+WWf279fF338v+sEsFoVVqeK+4vLxyy8nrtqnfPkgNWhQ0eO1AK4imAIAkIdLKSmaecstSti40a3HrdS0qYLKefZblk6fvqj1649dtV/TpjHy87N6tBagMJi/BwDgCktHjdJrNpvbQ6kk3dC/v9uPeaXk5LyfxL+cj49FDRpEebwWoDCYMQUAlHn2rCytnTRJW2bN0um9e5WV7rkn1WNbtfLYsXPExIQqMNBXaWmZBfarVcuzM7dAYRFMAQBl2tF16zSna1ddSk72+FhWf39Vbt68wD5Z6em6cOqU/ENDFRAeXqRxgoL89Nde1+m7T1crUBeVoBilK9Cpj6+vj/72txuKdHzAUwimAIAy69SuXZrZvr1HZ0gv1/yxx2SxWPLcdvH0aa165RX98uGHSj93TpJ0XefOav/CC6rWpo3LY2Smp2t8YKBqGIYe+6PNkJSkivpY9+u8xSbDkN5+u4vKlw+6xk8EuJfFMIy8V94tIVJSUmSz2ZScnKzwIv6fJQCgbFowcKC2zJ4tFcM/hdXatdPA5ctlyWNx0ZRjx/RBs2ZKPXnSqRaLNfvBpHu//FL1evbMvV/KJR08eFahof6qWTNCMgy9ZM37YSZDkl0++jp6pMZO7q8+fa53x8cCXOJqXiOYAgDKJMNu1/igILfOllp8fBRUoYLk46O006dl2O0qHxen1qNHq8mAAXmG0t/37tX0pk2Vcf78VY8ti0UVr79eTZ59RR8ssWvu3F+Vnp79laeNGkWp868jFabUfI9hSLJIGluy/+lHCeRqXuNSPgCgTMpMS3NLKLVYrarYoIGaPvywbnzgAfmHhrpew6VLmn3rrVcNpVJ2kJak37bu1+h+P+i8xaYs48/bAk7/+kuBoVTKDqWSdPbwYUVUq+ZynUBxIZgCAMok36AgBVWoUOTF8uv27KlmgwerWps2CggLK9Ixdn71lVKOHCnUPivVXikKk2E436vaXD85ZkSv5ui6dQRTmBLBFABQJlksFjV/5BGtnjBBLn13pyS/kBB1nzZNje+/P9+HmApjz8KFslitMrKyXOqfIV9tVhMZyn0faWWdcCmUSlLMjTcWokqg+BBMAQBlVqunn9aOL77Q73v35vkAlMVqVfNHH1Vc586q3aOHfPK4R/RaZKWnOy7RuyJVIcqQf57bMuTn8oxpZO3aLo8JFCe++QkAUGYFRkTowTVr1GTgQPn4+Tnaffz9VbtHDz118KC6T56sunfc4fZQKmXPXBZm5jVAl/LdtlP1XTpGRK1aLo8HFDeeygcAQFLa2bP6fc8e+QYGKqphwzyfoHe38wkJeqtaNdkzMlzeZ7b664BqyrhibilYqXpckxWotPxnnSwWjS3EDC3gLq7mNWZMAQBQ9uxplZtvVvQNNxRLKJWk0JgY9Zw5UxYfH1l8Xbu7roNW/PE753mlCwrRxxqgdAXkuV9Y1aqEUpgewRQAAC9q1K+fHvjxR9W9887s2wksFkU1aqQ7/vUv1bnzzlz9q+mI+mqewoKy/wn38/OR1Zp9O0D7vrep9+wZCqtSRRarVRZfX1WoV0+D1q3T8EI+/Q94A5fyAQAwCcMwJMNwmrHd/vnnWjFunM789pt8rFZVvvlmdZk0SeXqN9L8+Tu1c+cphYb6q1eveqpdu4IXqwfyxzc/AQAAwBS4xxQAAAAlCsEUAAAApkAwBQAAgCkQTAEAAGAKBFMAAACYAsEUAAAApkAwBQAAgCkQTAEAAGAKBFMAAACYAsEUAAAApkAwBQAAgCkQTAEAAGAKvt4uAADgZVlnpAszpYytkn99KWioZA3xdlUAyiCCKQCUVRcWSMkDJJ37s+2SpHPPSJaqUuQWybe8l4oDUBZxKR8Ayhq7XUpoICX3klMovZxxVEqqIJ26u1hLA1C2mSKYTp06VTVq1FBgYKBatGihDRs2eLskACi9TlaRjJ2u9c2YL528wbP1AMAfvB5MP/vsMw0fPlxjx47VL7/8osaNG6tLly46efKkt0sDgNIneZxkJBRun6xfpYv/9kg5AHA5i2EYhjcLaNGihW666SZNmTJFkmS32xUbG6snnnhCzz777FX3T0lJkc1mU3JyssLDwz1dLgCUbCd8JWUVfj9LpBST5PZyAJQNruY1r86Ypqena+PGjerUqZOjzcfHR506ddLatWvz3OfSpUtKSUlxegEAXGAYKlIolSTjtFtLAYC8eDWYnjp1SllZWYqOjnZqj46OVkJC3peaJkyYIJvN5njFxsYWR6kAUPIZl65lZ7eVAQD58fo9poU1evRoJScnO15HjhzxdkkAUDL4BF7DzqFuKwMA8uPVdUwjIyNltVqVmJjo1J6YmKiYmJg89wkICFBAQEBxlAcApZBNUnLhd/Nr7/ZKAOBKXp0x9ff3V7NmzbRs2TJHm91u17Jly9SyZUsvVgYApVTErKLtZ5vu3joAIA9e/+an4cOHKz4+Xs2bN9fNN9+st99+W6mpqXrggQe8XRoAlD5Bd0kpTSX7L67vY6ko+VX2XE0A8AevB9O//vWvSkpK0pgxY5SQkKAmTZpo0aJFuR6IMoOsLOmJV6SN26WRD0r3dPV2RQBQBBU3SImRks660DlAiuRefgDFw+vrmF6r4ljH1DCkoCbSpYzc2wL9pddHSn27S5HlPDI8ALifYZd+7yRlLM+ng48U+IgUMUWyWIq1NAClj6t5jWDqAksD1/rdWF9a+J5U2XyTvQCQv7QlUvr/JPlLAa0lv+aSD0/hA3AfV/Oa1y/lm93rH7ned9NOqXY36cBSKaqC52oCALcK7Jz9AgAvI5hexag3C9f/Qpr04D+khdOy32dkSAuWSf9dJaVnSM0aSAN7SRUi3F4qAABAical/Ktw9TL+5aw+0vmN0rFE6baHpANHJV9r9r2qhiH5+UmfTJR6M0EBAADKAFfzWon75qeSIMsuHTou3fqgdOREdltmVna73cieOf3rcOnnba4f0zAMZV66pBL+/xEAAAD54lL+VdSuLu09VPj9lq/PDqd5MQzJ4iO9OUP6NI9bBbLS07Vv8WIl7dql3xYv1vGNG3Xp7FmnPharVc0efVTd331XFp6YBQAApQCX8q8iPV0KaFK4fepdJ91QR/pyiWS3598v0F+6uNm5bdtnn+m/jz6qtDNnXBrLLzRUQ3fskC02tnBFAgAAFBMu5buJv78057XC7fPuaOliWsGhVMq+pH/5/xbsnD9fX/Xt63IolaSM8+f1bq1a2rd4MZf5AQBAiUYwdcHf7pSMHVIFW8H9rD7SRy9Lt7WWGtfLfp8fH4t0fe0/16027HYtGTGiSPXZ09P1SdeuerdWLSVu3VqkYwAAAHgb95gWwqm1f/4+I0P6ZKE071spI1PqcLP09ANSUGD29ofvkV79IP9j2Q3pyfv/fH/sp5909sCBa6rv7G+/6f3GjWWxWnXjoEHqMmmS/ENCrumYAAAAxYV7TD3og8+lIeMkq1XKyspus1gkGVLPTtIXb2Vvk6Q9Cxfq0zvucOv4wZGRemz7doVERbn1uAAAAIXBPaYmMPhe6fuPpFtb/HnJvnZ1afI/nEOpJIV74OGlC6dOaVJsrPYtWuT2YwMAALgbM6bFJDMzey3TwIC8txuGoelNmnjkHlGL1aqH1q1T5ebN3X5sAACAq2HG1GR8ffMPpZJksVjUbcoUj4xtGIZWT5jgkWMDAAC4C8HURKq3bav4FSvcf2C7XbsXLFDmpUvuPzYAAICbEExNpkb79urw0ktuP65htyvz4kW3HxcAAMBdCKYm1P6FF9Sof3+3HjOoQgUFmPgeXAAAAIKpSd09e7Ye3rhRIdHR13wsi9Wq5o8+KosPpxsAAJgXC+ybWOWmTfV0QoKyMjJ0YNkyndi0SfuXLlXGuXPyDQ5WkwcfVKO+fXVq1y59ce+9Or1nT65jWKxWVaxfX61HjvTCJwAAAHAdy0WVIju+/FIrX3pJJ3/9VZLkFxKiGwcNUseXXlKg7SrfpwoAAOAhruY1gmkpYxiGUo4eVebFiwqPjZVfUJC3SwIAAGWcq3mNS/mljMVikc0D3yIFAADgaTwNAwAAAFMgmAIAAMAUCKYAAAAwBYIpAAAATIFgCgAAAFMgmAKAyWUpS3bZvV0GAHgcy0UBgAkd11HN0cc6r/OOtiAF6W7do7qq58XKAMBzCKYAYCKpStV0vaezOptr20Vd1Cf6WB3UUbeoU/EXBwAexqV8ADCJZJ3VP/VqnqH0ciu0/Kp9AKAkIpgCgElM0hsu9/2XpnuwEgDwDoIpAJjAYR2WIcPl/ueUoixlebAiACh+BFMAMIHPNa/Q+/ym/R6oBAC8h2AKACaQpouF3uecznmgEgDwHoIpAJhAhCIKvU9VVXV/IQDgRQRTADCBgXqw0PtEKdoDlQCA9xBMAcAEQhWmUIW63L+WanmwGgDwDoIpAJjE03pG/gq4aj8/+WmAHiiGigCgeBFMAcAkfOSjf2iM2ql9vn2qqbpe0LjiKwoAihFfSQoAJtNJndVJnbVD27RZm2SRj25WC8Vx+R5AKUcwBQCTaqCGaqCG3i4DAIoNl/IBAABgCgRTAAAAmALBFAAAAKZAMAUAAIApEEwBAABgCgRTAAAAmALBFAAAAKZAMAUAAIApEEwBAABgCgRTAAAAmALBFAAAAKZAMAUAAIApEEwBAABgCgRTAAAAmALBFAAAAKZAMAUAAIApEEwBAABgCgRTAAAAmALBFAAAAKZAMAUAAIApEEwBAABgCgRTAAAAmALBFAAAAKZAMAUAAIApEEwBAABgCgRTAAAAmILHgun48ePVqlUrBQcHKyIiIs8+hw8fVo8ePRQcHKyoqCiNHDlSmZmZnioJAAAAJubrqQOnp6erT58+atmypT766KNc27OystSjRw/FxMRozZo1OnHihAYMGCA/Pz+9+uqrnioLAAAAJmUxDMPw5AAzZ87UsGHDdPbsWaf27777TrfffruOHz+u6OhoSdL777+vZ555RklJSfL393fp+CkpKbLZbEpOTlZ4eLi7ywcAAMA1cjWvee0e07Vr16pRo0aOUCpJXbp0UUpKirZv357vfpcuXVJKSorTCwAAACWf14JpQkKCUyiV5HifkJCQ734TJkyQzWZzvGJjYz1aJwAAAIpHoYLps88+K4vFUuBr165dnqpVkjR69GglJyc7XkeOHPHoeAAAACgehXr4acSIERo4cGCBfa677jqXjhUTE6MNGzY4tSUmJjq25ScgIEABAQEujQEAAICSo1DBtGLFiqpYsaJbBm7ZsqXGjx+vkydPKioqSpK0dOlShYeHq0GDBm4ZAwAAACWHx5aLOnz4sE6fPq3Dhw8rKytLmzdvliTVqlVLoaGh6ty5sxo0aKD+/ftr4sSJSkhI0D/+8Q8NHTqUGVEAAIAyyGPLRQ0cOFCzZs3K1b58+XJ16NBBknTo0CE9+uijWrFihUJCQhQfH6/XXntNvr6u52WWiwIAADA3V/Oax9cx9TSCKQAAgLmZfh1TAAAA4HIEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDAFAACAKfh6uwAAAAB4UNpFaeF70oVkqe29Us2G3q4oXwRTAACA0iYjQ3r7IemHOZJh/7N97svZv9oipQGvSD2GeKe+fHApHwAAoDTZukq6w19aNts5lF4u+ZQ0+RHpbpt04Xzx1lcAgikAAEBpcXiHNKq96/0vpEh/jZIMw3M1FQLBFAAAoDQwDOnRxoXfL+OiNLy1++spAoIpAABAafDxWCkrs2j77lwrHd3r3nqKgGAKAABQGnz91rXt/0pv99RxDQimAAAApUHaNT7EdGSXe+q4BgRTAAAA5P8EfzEimAIAAECyVfR2BQRTAACAUiEg5Nr2HzTRPXVcA4IpAABAaXB9m6LvGxQm3Xq/+2opIoIpAABAadBtcNH3/b99ksXivlqKiGAKAABQGrS8Q/L1L/x+z30mlYtyfz1FQDAFAAAoDXz9CnefqMUiPf+l1O5ez9VUSL7eLgAAAABu0vNJKfWs9MlLuZd/CgiWLD6SLVJ6eJLUppdXSiyIxTAMw9tFXIuUlBTZbDYlJycrPDzc2+UAAAB43+8npB/mSElHpIgo6Za/STE1vVaOq3mNGVMAAIDSpkIlqc9Ib1dRaNxjCgAAAFMgmAIAAMAUCKYAAAAwBYIpAAAATIFgCgAAAFMgmAIAAMAUCKYAAAAwBYIpAAAATIFgCgAAAFMgmAIAAMAUPBZMDx48qEGDBqlmzZoKCgpSXFycxo4dq/T0dKd+W7duVdu2bRUYGKjY2FhNnDjRUyUBAADAxHw9deBdu3bJbrdr+vTpqlWrlrZt26aHH35YqampeuONNyRJKSkp6ty5szp16qT3339fv/76qx588EFFRERo8ODBnioNAAAAJmQxDMMorsFef/11TZs2Tb/99pskadq0aXr++eeVkJAgf39/SdKzzz6rBQsWaNeuXS4dMyUlRTabTcnJyQoPD/dY7QAAACgaV/Nasd5jmpycrPLlyzver127Vu3atXOEUknq0qWLdu/erTNnzuR5jEuXLiklJcXpBQAAgJKv2ILpvn37NHnyZA0ZMsTRlpCQoOjoaKd+Oe8TEhLyPM6ECRNks9kcr9jYWM8VDQAAgGJT6GD67LPPymKxFPi68jL8sWPH1LVrV/Xp00cPP/zwNRU8evRoJScnO15Hjhy5puMBAADAHAr98NOIESM0cODAAvtcd911jt8fP35cHTt2VKtWrfTBBx849YuJiVFiYqJTW877mJiYPI8dEBCggICAwpYNAAAAkyt0MK1YsaIqVqzoUt9jx46pY8eOatasmWbMmCEfH+cJ2pYtW+r5559XRkaG/Pz8JElLly5V3bp1Va5cucKWBgAAgBLMY/eYHjt2TB06dFC1atX0xhtvKCkpSQkJCU73jvbr10/+/v4aNGiQtm/frs8++0zvvPOOhg8f7qmyAAAAYFIeW8d06dKl2rdvn/bt26eqVas6bctZocpms2nJkiUaOnSomjVrpsjISI0ZM4Y1TAEAAMqgYl3H1BNYxxQAAMDcTLmOKQAAAJAfgikAAABMgWAKAAAAUyCYAgAAwBQIpgAAADAFgikAAABMgWAKAAAAUyCYAgAAwBQIpgAAADAFgikAAABMgWAKAAAAUyCYAgAAFAe7XTIMb1dhagRTAAAAT8lIlxa8Kw2qK3W3SncGSRPuk/b+4u3KTIlgCgAA4AkZ6dKYHtL0YdLxvX+0XZJ+/FIa1kJav9Cr5ZkRwRQAAMAT5r8lbf4h+/L95ZfwszIle5Y0oa904Zz36jMhgikAAIC72e3SN+9Khj3v7YYhpV2Qln9SvHWZHMEUAADA3c6dln4/XnAfq1Xau7F46ikhCKYAAADu5hfg3n5lBMEUAADA3YLDpAatJZ8ColZWptTijuKrqQQgmAIAAHjCX0dn32uaF6uvVKOh1PS24q3J5AimAAAAntCih/TYZMniI/lYs9tyfq1cS3r5u4JnVMsgX28XAAAAUGrd+Xj25fpFH8o4tF2pyee0LzlQx3xiFPXFv9Xob39ToM3m7SpNw2IYJfu7sVJSUmSz2ZScnKzw8HBvlwMAAJBLalKSPr3zTh1bt04+vr6SxSJ7ZqZ8g4LUa9YsNbjnHm+X6FGu5jVmTAEAADwg5dgxnT14UIE2mxY88IASNm+WJNkzMx19Mi9c0Bd9+qjblCkKjY6WrVo1Vb7pJlksFi9V7V0EUwAAgGtkGIYOrVqlI2vW6OLp0zq6dq2OrFnj/I1PBfju8ced3gdHRWnwzz/LFhvriXJNi2AKAABwDU7t2qXPe/dW0o4d2Q8z5fckfiFcOHlSb1erpooNG2rIxo2y+vu7oVLz41EwAACAIjqfmKgZ7drp1O7d2Q1uCKWXS9q2Te/WqeN0+b80I5gCAAAU0c/Tpuni6dMysrI8NkbKoUPaPGuWx45vJgRTAACAItoye7ZHQ2mO70eP9vgYZkAwBQAAKKK0M2eKZZyLSUnFMo63EUwBAACKqFxcHN/e5Eb8JAEAAIqo+SOPuP2Bp7KMYAoAAFBEjQcMULW2bWXJb9bUYpEsFvn4+io4OrroA5WRWVnWMQUAACgiq7+/7l+8WMtfeEEbp09X+vnzkqSgChUU17mzom+4QUHly6ter15KTUrStOuvL9I4NTt2dGfZpmUxDBe/ksCkXP3uVQAAAE/KuHBBSTt3ysdqVcXrr5fVzy9Xn1kdO+rgihWFO7DFomeSkxUYFuaeQr3A1bxWNuaFAQAAPMwvOFiVmzVTTJMmeYZSSRrwww+qWMhZ08f37CnRobQwCKYAAADFxGKx6LFt29Ts0Uev2tcaGKinDh5UhVq1iqEyc+BSPgAAKPEMw9DUhg31+44dTu2d33lHLZ980ktVFcwwDP136FDtXrBAmZcuybDbJbtdARERuu2f/1TDvn29XaLbuJrXCKYAAKBESzl+XG9VqZLvdmtIiP7xx0NJ8A7uMQUAAKWeYbcXGEolKSs1VfN69y6minAtCKYAAKDE2vb55y712/311x6uBO5AMAUAACXWd4W4fzQzLc2DlcAdCKYAAKDEyrx40eW+9sxMD1YCdyCYAgCAEqtqixYu9/ULCfFgJXAHgikAACix7pk3z6V+fmFhslgsHq4G14pgCgAASqzgyEhVa9fuqv1GnjpVDNXgWhFMAQBAifbAypWqdeed+W5/7tIl+fn7F2NFKCpfbxcAAABwrf72zTeSpP0//qg1r72mGh06qO3TT3u5KhQWwRQAAJQacW3aKG7hQm+XgSLiUj4AAABMgWAKAAAAUyCYAgAAwBQIpgAAADAFgikAAABMgWAKAAAAUyCYAgAAwBQIpgAAADAFgikAAABMgWAKAAAAUyCYAgAAwBQIpgAAADAFgikAAABMwdfbBVwrwzAkSSkpKV6uBAAAAHnJyWk5uS0/JT6Ynjt3TpIUGxvr5UoAAABQkHPnzslms+W73WJcLbqanN1u1/HjxxUWFiaLxeLtckq9lJQUxcbG6siRIwoPD/d2ObgM58bcOD/mxvkxN86Pebl6bgzD0Llz51S5cmX5+OR/J2mJnzH18fFR1apVvV1GmRMeHs5fDibFuTE3zo+5cX7MjfNjXq6cm4JmSnPw8BMAAABMgWAKAAAAUyCYolACAgI0duxYBQQEeLsUXIFzY26cH3Pj/Jgb58e83H1uSvzDTwAAACgdmDEFAACAKRBMAQAAYAoEUwAAAJgCwRQAAACmQDCFy+68805Vq1ZNgYGBqlSpkvr376/jx4879dm6davatm2rwMBAxcbGauLEiV6qtuw4ePCgBg0apJo1ayooKEhxcXEaO3as0tPTnfpxbrxn/PjxatWqlYKDgxUREZFnn8OHD6tHjx4KDg5WVFSURo4cqczMzOIttIyaOnWqatSoocDAQLVo0UIbNmzwdkll0qpVq3THHXeocuXKslgsWrBggdN2wzA0ZswYVapUSUFBQerUqZP27t3rnWLLoAkTJuimm25SWFiYoqKi1LNnT+3evdupT1pamoYOHaoKFSooNDRUvXv3VmJiYqHGIZjCZR07dtTnn3+u3bt366uvvtL+/ft1zz33OLanpKSoc+fOql69ujZu3KjXX39d48aN0wcffODFqku/Xbt2yW63a/r06dq+fbveeustvf/++3ruueccfTg33pWenq4+ffro0UcfzXN7VlaWevToofT0dK1Zs0azZs3SzJkzNWbMmGKutOz57LPPNHz4cI0dO1a//PKLGjdurC5duujkyZPeLq3MSU1NVePGjTV16tQ8t0+cOFHvvvuu3n//fa1fv14hISHq0qWL0tLSirnSsmnlypUaOnSo1q1bp6VLlyojI0OdO3dWamqqo8/f//53/ec//9EXX3yhlStX6vjx47r77rsLN5ABFNE333xjWCwWIz093TAMw3jvvfeMcuXKGZcuXXL0eeaZZ4y6det6q8Qya+LEiUbNmjUd7zk35jBjxgzDZrPlav/2228NHx8fIyEhwdE2bdo0Izw83Omcwf1uvvlmY+jQoY73WVlZRuXKlY0JEyZ4sSpIMubPn+94b7fbjZiYGOP11193tJ09e9YICAgwPv30Uy9UiJMnTxqSjJUrVxqGkX0+/Pz8jC+++MLRZ+fOnYYkY+3atS4flxlTFMnp06f1ySefqFWrVvLz85MkrV27Vu3atZO/v7+jX5cuXbR7926dOXPGW6WWScnJySpfvrzjPefG3NauXatGjRopOjra0dalSxelpKRo+/btXqysdEtPT9fGjRvVqVMnR5uPj486deqktWvXerEyXOnAgQNKSEhwOlc2m00tWrTgXHlJcnKyJDn+rdm4caMyMjKczlG9evVUrVq1Qp0jgikK5ZlnnlFISIgqVKigw4cP65tvvnFsS0hIcPqHVZLjfUJCQrHWWZbt27dPkydP1pAhQxxtnBtz4/x4x6lTp5SVlZXnz56fu7nknA/OlTnY7XYNGzZMrVu3VsOGDSVlnyN/f/9c99EX9hwRTMu4Z599VhaLpcDXrl27HP1HjhypTZs2acmSJbJarRowYIAMvjzMIwp7biTp2LFj6tq1q/r06aOHH37YS5WXDUU5PwBQGgwdOlTbtm3TvHnz3H5sX7cfESXKiBEjNHDgwAL7XHfddY7fR0ZGKjIyUnXq1FH9+vUVGxurdevWqWXLloqJicn19F3O+5iYGLfXXtoV9twcP35cHTt2VKtWrXI91MS5cb/Cnp+CxMTE5HoSnPPjeZGRkbJarXn+t8HP3VxyzkdiYqIqVarkaE9MTFSTJk28VFXZ9Pjjj2vhwoVatWqVqlat6miPiYlRenq6zp496zRrWtj/ngimZVzFihVVsWLFIu1rt9slSZcuXZIktWzZUs8//7wyMjIc950uXbpUdevWVbly5dxTcBlSmHNz7NgxdezYUc2aNdOMGTPk4+N8MYRz437X8t/OlVq2bKnx48fr5MmTioqKkpR9fsLDw9WgQQO3jIHc/P391axZMy1btkw9e/aUlP332rJly/T44497tzg4qVmzpmJiYrRs2TJHEE1JSdH69evzXe0C7mUYhp544gnNnz9fK1asUM2aNZ22N2vWTH5+flq2bJl69+4tSdq9e7cOHz6sli1bFmog4KrWrVtnTJ482di0aZNx8OBBY9myZUarVq2MuLg4Iy0tzTCM7CfyoqOjjf79+xvbtm0z5s2bZwQHBxvTp0/3cvWl29GjR41atWoZt956q3H06FHjxIkTjlcOzo13HTp0yNi0aZPx4osvGqGhocamTZuMTZs2GefOnTMMwzAyMzONhg0bGp07dzY2b95sLFq0yKhYsaIxevRoL1de+s2bN88ICAgwZs6caezYscMYPHiwERER4bRCAorHuXPnHP9tSDImTZpkbNq0yTh06JBhGIbx2muvGREREcY333xjbN261bjrrruMmjVrGhcvXvRy5WXDo48+athsNmPFihVO/85cuHDB0eeRRx4xqlWrZvzwww/Gzz//bLRs2dJo2bJlocYhmMIlW7duNTp27GiUL1/eCAgIMGrUqGE88sgjxtGjR536bdmyxWjTpo0REBBgVKlSxXjttde8VHHZMWPGDENSnq/LcW68Jz4+Ps/zs3z5ckefgwcPGt26dTOCgoKMyMhIY8SIEUZGRob3ii5DJk+ebFSrVs3w9/c3br75ZmPdunXeLqlMWr58eZ7/ncTHxxuGkb1k1AsvvGBER0cbAQEBxq233mrs3r3bu0WXIfn9OzNjxgxHn4sXLxqPPfaYUa5cOSM4ONjo1auX0ySJKyx/DAYAAAB4FU/lAwAAwBQIpgAAADAFgikAAABMgWAKAAAAUyCYAgAAwBQIpgAAADAFgikAAABMgWAKAAAAUyCYAgAAwBQIpgAAADAFgikAAABMgWAKAAAAU/h/H8c6p+BYAboAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loader = DataLoader(dataset=close_test_set, batch_size=batch_size, shuffle=False) # False -> to make visualize map fixed\n",
    "model.eval()\n",
    "    # for threshold in thresholds:\n",
    "predicted_list = np.empty((0, 6))\n",
    "one_hot_labels_list = np.empty(0)\n",
    "with torch.no_grad():\n",
    "    softmax = nn.Softmax()\n",
    "    for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "        validation_step_loss = []\n",
    "        signals = torch.tensor(signals)\n",
    "        signals = signals.float()\n",
    "        signals = signals.to(device)\n",
    "        one_hot_labels = one_hot_labels.to(device)\n",
    "        outputs = model(signals)\n",
    "        # validation_loss = triple_joint_loss(outputs, one_hot_labels, alpha)\n",
    "        # validation_step_loss.append(validation_loss.item())\n",
    "        predicted_list = np.append(predicted_list, outputs.cpu(), axis=0)\n",
    "        one_hot_labels_list = np.append(one_hot_labels_list, one_hot_labels.cpu())\n",
    "        # show_2D_tSNE(outputs.cpu(), one_hot_labels.cpu())\n",
    "    # validation_epoch_loss.append(np.array(validation_step_loss).mean())\n",
    "show_2D_tSNE(predicted_list, one_hot_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((308, 12),\n",
       " array([ 7.,  3.,  5.,  5.,  0.,  2.,  3.,  9.,  2., 10., 11.,  1.,  8.,\n",
       "         4., 11., 11.,  3.,  1.,  8., 11.,  5.,  9.,  6.,  1., 11.,  2.,\n",
       "         2.,  8.,  4.,  4.,  9.,  2.,  4.,  3.,  4.,  0.,  2., 10.,  3.,\n",
       "        11.,  6.,  0.,  5.,  4.,  6.,  8.,  3., 10.,  9.,  7.,  0.,  6.,\n",
       "         7.,  3.,  9.,  0.,  3.,  0.,  5., 10.,  1.,  4.,  2.,  5., 10.,\n",
       "        10., 10.,  7.,  4., 10.,  1.,  6.,  6.,  2.,  2.,  6.,  5.,  8.,\n",
       "         8.,  1.,  0.,  3.,  6., 11.,  0., 11.,  7., 10.,  5.,  3.,  9.,\n",
       "         8.,  3.,  9.,  7.,  9., 11.,  7.,  8.,  7.,  7.,  2.,  7.,  8.,\n",
       "         6.,  0.,  4.,  9.,  3.,  2.,  4.,  8.,  3., 10.,  2.,  6.,  4.,\n",
       "         6.,  8.,  5., 11.,  5.,  4.,  7.,  4.,  1., 10.,  5.,  2.,  1.,\n",
       "         8.,  8.,  9.,  1.,  2., 11.,  3.,  3.,  8.,  5.,  1.,  5.,  0.,\n",
       "         9.,  4.,  8.,  0.,  1.,  2.,  8.,  8.,  4.,  8.,  1.,  2.,  6.,\n",
       "         5.,  8.,  2.,  0., 11.,  7.,  0., 11., 10., 11.,  5.,  4.,  4.,\n",
       "         7., 11.,  3.,  3., 11.,  4.,  7.,  3.,  0.,  0.,  9.,  2.,  8.,\n",
       "         8.,  1.,  8., 11.,  4.,  3.,  0.,  8.,  6.,  2.,  3.,  7.,  1.,\n",
       "         2.,  8.,  8.,  8.,  6., 10.,  4., 10.,  8.,  7., 10.,  6.,  0.,\n",
       "         4.,  1., 11.,  2.,  3.,  7.,  1.,  4.,  2.,  2.,  5.,  2., 10.,\n",
       "         4.,  0.,  9.,  5.,  2.,  3.,  4.,  0.,  6., 11.,  9., 11., 11.,\n",
       "         0.,  5., 11.,  1.,  4.,  7.,  9.,  5.,  5.,  0.,  7.,  4.,  5.,\n",
       "        10.,  1.,  7.,  4.,  6.,  8.,  7.,  1.,  3., 11.,  5.,  1.,  3.,\n",
       "        11.,  3.,  7.,  6.,  7.,  5.,  9.,  5.,  8., 10.,  9.,  0.,  0.,\n",
       "         1.,  1., 11.,  1.,  3., 11., 10.,  2.,  3.,  4.,  6.,  1., 11.,\n",
       "         8.,  3.,  9.,  8.,  3.,  8.,  9.,  0.,  1.,  3.,  5.,  4.,  5.,\n",
       "         4., 11.,  3.,  5.,  8.,  3.,  8.,  3.,  1.]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_list.shape, one_hot_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_epoch_loss, label='train_loss')\n",
    "plt.plot(validation_epoch_loss,label='val_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 483 is out of bounds for dimension 0 with size 64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb Cell 29\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m n_total_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m mb:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (signals, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(progress_bar(train_loader, parent\u001b[39m=\u001b[39mmb)):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m         signals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(signals)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m         signals \u001b[39m=\u001b[39m signals\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/fastprogress/fastprogress.py:50\u001b[0m, in \u001b[0;36mProgressBar.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_interrupt()\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/fastprogress/fastprogress.py:41\u001b[0m, in \u001b[0;36mProgressBar.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(\u001b[39m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mfor\u001b[39;00m i,o \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen):\n\u001b[1;32m     42\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal: \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[39myield\u001b[39;00m o\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "\u001b[1;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb Cell 29\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(idx):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m   idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mtolist()        \n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/HCU_elreko_bpf_wavelet_uniThre.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mradar_heartbeat[idx], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabels[idx]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 483 is out of bounds for dimension 0 with size 64"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "# X = dataset\n",
    "# y = labels\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0) # shuffle=Falseだとrandom_stateは何か数字を設定しても意味ないらしい\n",
    "num_epochs = 300\n",
    "mean_acc = 0\n",
    "split_idx = 1535 # 5\n",
    "# split_idx = 2047 # 7\n",
    "# split_idx = 2559 # 9\n",
    "\n",
    "dataset = HCU_Dataset(data_tensor_list, labels_tensor)\n",
    "\n",
    "\n",
    "  # Prepare Open train Dataset\n",
    "open_train_index = [i for i in train_index if i <= split_idx]\n",
    "open_train_set = torch.utils.data.Subset(dataset, open_train_index)\n",
    "open_test_set = torch.utils.data.Subset(dataset, test_index)\n",
    "# Prepare Close train Dataset\n",
    "# train_set = torch.utils.data.Subset(dataset, train_index)\n",
    "# test_set = torch.utils.data.Subset(dataset, test_index) # openの場合も同じ\n",
    "\n",
    "Unknown_label = close_num + 1\n",
    "\n",
    "train_loader = DataLoader(dataset=open_train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=open_test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "model = model.to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "mb = master_bar(range(num_epochs))\n",
    "\n",
    "model.train()\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in mb:\n",
    "    for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "        signals = torch.tensor(signals)\n",
    "        signals = signals.float()\n",
    "        signals = signals.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # print(signals.size())\n",
    "        outputs = model(signals)\n",
    "        outputs = outputs.to(device)\n",
    "        # print(outputs)\n",
    "        loss = triple_joint_loss(outputs, labels, alpha) # will check the shapes of outputs and labels\n",
    "        # test_loss = triple_joint_loss(signals, one_hot_labels, alpha) # from test_loader?\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_centloss.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in center_loss.parameters():\n",
    "            param.grad.data *= (1./alpha) # 98.98%を出したときはこれを書いていなかった→追加しても問題なし．\n",
    "        optimizer.step()\n",
    "        optimizer_centloss.step()\n",
    "    mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "    print(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "\n",
    "# For Confusion Matrix\n",
    "# thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# model.eval()\n",
    "# for threshold in thresholds:\n",
    "#   predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "#   one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "#   with torch.no_grad():\n",
    "#     n_correct = 0\n",
    "#     n_samples = 0\n",
    "#     softmax = nn.Softmax()\n",
    "#     for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "#       signals = torch.tensor(signals)\n",
    "#       signals = signals.float()\n",
    "#       signals = signals.to(device)\n",
    "#       one_hot_labels = one_hot_labels.to(device)\n",
    "#       # print(len(one_hot_labels))\n",
    "#       outputs = model(signals)\n",
    "#       # if i == 1:\n",
    "      \n",
    "#         # print(outputs)\n",
    "#       for j, out in enumerate(outputs):\n",
    "#         outputs[j] = softmax(out)\n",
    "\n",
    "#       _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "      \n",
    "#       for idx in range(len(_)):\n",
    "#         if _[idx] < threshold:\n",
    "#           predicted[idx] = Unknown_label # 15, 20, 25\n",
    "#       # print(_, predicted, one_hot_labels)\n",
    "\n",
    "#       n_samples += one_hot_labels.size(0) # add batch_size\n",
    "#       n_correct += (predicted == one_hot_labels).sum().item()\n",
    "      \n",
    "#       predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "#       one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "#       predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "#       one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "      \n",
    "#       acc = 100.0 * n_correct / n_samples\n",
    "#       # print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
    "#     with open(\"cross_val_result_HCU_BPF_unival_open_level6.txt\", \"a\") as f:\n",
    "#       f.write(f\"Fold{Fold+1}, Threshold{threshold}\\n\")\n",
    "#       f.write(classification_report(one_hot_labels_list, predicted_lists, digits=4) + \"\\n\")\n",
    "\n",
    "\n",
    "#     cm = confusion_matrix(one_hot_labels_list, predicted_lists)\n",
    "#     sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues')\n",
    "#     plt.xlabel(\"Predicted Label\", fontsize=13)\n",
    "#     plt.ylabel(\"Ground Truth\", fontsize=13)\n",
    "#     fig_name = \"cross_val_Fold{}_threshold{}.png\".format(Fold, threshold)\n",
    "#     # plt.savefig(\"./figure/HCU_cross_val_BPF_uniwav_open6-6_level6/\" + fig_name)\n",
    "#     plt.close()\n",
    "  \n",
    "#   if threshold == 0.5:\n",
    "#     mean_acc += acc\n",
    "# print(mean_acc / 10.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Unithre_model_150Open.pickle', mode='wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Unithre_model.pickle', mode='rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_832/2538953729.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase([0.8531, 0.8520, 0.8548, 0.8532, 0.8531, 0.8530, 0.8531, 0.8561,\n",
      "            0.8530, 0.8518, 0.8528, 0.8529, 0.8535, 0.8541, 0.8539, 0.8542,\n",
      "            0.8706, 0.8531, 0.8513, 0.8527, 0.8528, 0.8526, 0.8527, 0.8516,\n",
      "            0.8517, 0.8561, 0.9606, 0.9607, 0.9507, 0.9609, 0.9605, 0.9604,\n",
      "            0.9593, 0.9605, 0.9605, 0.9600, 0.9562, 0.9608, 0.9578, 0.9605,\n",
      "            0.9608, 0.9608, 0.9603, 0.9607, 0.9605, 0.9604, 0.9605, 0.9607,\n",
      "            0.9560, 0.9608, 0.9594, 0.9605, 0.9691, 0.9693, 0.9693, 0.9693,\n",
      "            0.9692, 0.9692, 0.9693, 0.9692, 0.9692, 0.9692, 0.9693, 0.9692],\n",
      "           device='cuda:0') TensorBase([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "            0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "            1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "           device='cuda:0') tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')\n",
      "TensorBase([0.9693, 0.9686, 0.9672, 0.9083, 0.9692, 0.9688, 0.9689, 0.9693,\n",
      "            0.9693, 0.9692, 0.9693, 0.9693, 0.9692, 0.9927, 0.9931, 0.9929,\n",
      "            0.9931, 0.9931, 0.9932, 0.9928, 0.9929, 0.9930, 0.9929, 0.9916,\n",
      "            0.9926, 0.9930, 0.9929, 0.9928, 0.9931, 0.9928, 0.9926, 0.9923,\n",
      "            0.9923, 0.9930, 0.9931, 0.9930, 0.9930, 0.9926, 0.9934, 0.8215,\n",
      "            0.8171, 0.8324, 0.8423, 0.8393, 0.8479, 0.8418, 0.8538, 0.8528,\n",
      "            0.8341, 0.8471, 0.8197, 0.8286, 0.8547, 0.8532, 0.8418, 0.8630,\n",
      "            0.8413, 0.8396, 0.8483, 0.8346, 0.7847, 0.8475, 0.8514, 0.8462],\n",
      "           device='cuda:0') TensorBase([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "            3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "            3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "           device='cuda:0') tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], device='cuda:0')\n",
      "TensorBase([0.9643, 0.9578, 0.9609, 0.9636, 0.9641, 0.9635, 0.9641, 0.9643,\n",
      "            0.9642, 0.9635, 0.9641, 0.9642, 0.9642, 0.9644, 0.9204, 0.8526,\n",
      "            0.9629, 0.9627, 0.6685, 0.7793, 0.4827, 0.5696, 0.9643, 0.9647,\n",
      "            0.9648, 0.8871, 0.7859, 0.7860, 0.7851, 0.7844, 0.7869, 0.7866,\n",
      "            0.7860, 0.7863, 0.7857, 0.7861, 0.7809, 0.7846, 0.7861, 0.7862,\n",
      "            0.7854, 0.7864, 0.7537, 0.7857, 0.7862, 0.7855, 0.7854, 0.7901,\n",
      "            0.7862, 0.7973, 0.9108, 0.9516, 0.9490, 0.9402, 0.9429, 0.9516,\n",
      "            0.9517, 0.9356, 0.9511, 0.9407, 0.9161, 0.9516, 0.9515, 0.9509],\n",
      "           device='cuda:0') TensorBase([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 5,\n",
      "            5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "            0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
      "           device='cuda:0') tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "TensorBase([0.9513, 0.9477, 0.9509, 0.9511, 0.9474, 0.9506, 0.8766, 0.7474,\n",
      "            0.9324, 0.9050, 0.8261, 0.9242, 0.9427, 0.9013, 0.9254, 0.8579,\n",
      "            0.9271, 0.6344, 0.9429, 0.9405, 0.7914, 0.7937, 0.9111, 0.8051,\n",
      "            0.9230, 0.9410, 0.6799, 0.4178, 0.8057, 0.6005, 0.6681, 0.8036,\n",
      "            0.7802, 0.8167, 0.7997, 0.7973, 0.7807, 0.7460, 0.6221, 0.7509,\n",
      "            0.7999, 0.7906, 0.7683, 0.6583, 0.7284, 0.7874, 0.7991, 0.8231,\n",
      "            0.7706, 0.7862, 0.7138, 0.7585, 0.7171, 0.7693, 0.7733, 0.8142,\n",
      "            0.9843, 0.9842, 0.9840, 0.9841, 0.9841, 0.9846, 0.9843, 0.9089],\n",
      "           device='cuda:0') TensorBase([5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0,\n",
      "            0, 0, 0, 6, 6, 5, 6, 6, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 5,\n",
      "            5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "           device='cuda:0') tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "TensorBase([0.9842, 0.9842, 0.9846, 0.9848, 0.9839, 0.9841, 0.9841, 0.9839,\n",
      "            0.9842, 0.9846, 0.9843, 0.9842, 0.9842, 0.9842, 0.9729, 0.9718,\n",
      "            0.9723, 0.9733, 0.9718, 0.9734, 0.9718, 0.9732, 0.9732, 0.9730,\n",
      "            0.9730, 0.9731, 0.9730, 0.9730, 0.9729, 0.9714, 0.9728, 0.9730,\n",
      "            0.9726, 0.9706, 0.9659, 0.9720, 0.9730, 0.9724, 0.9726, 0.9736,\n",
      "            0.9616, 0.9710, 0.9617, 0.9727, 0.9729, 0.9732, 0.9728, 0.9729,\n",
      "            0.9729, 0.9725, 0.9724, 0.9661], device='cuda:0') TensorBase([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "            1, 1, 1, 1, 1, 1], device='cuda:0') tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6], device='cuda:0')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2857    1.0000    0.4444        26\n",
      "           1     0.4062    1.0000    0.5778        26\n",
      "           2     1.0000    1.0000    1.0000        25\n",
      "           3     0.5098    1.0000    0.6753        26\n",
      "           4     0.0000    0.0000    0.0000        25\n",
      "           5     0.3433    0.8846    0.4946        26\n",
      "           6     0.7000    0.0455    0.0854       154\n",
      "\n",
      "    accuracy                         0.4318       308\n",
      "   macro avg     0.4636    0.7043    0.4682       308\n",
      "weighted avg     0.5616    0.4318    0.3089       308\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "model.eval()\n",
    "threshold = 0.7\n",
    "predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    softmax = nn.Softmax()\n",
    "    for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "        signals = torch.tensor(signals)\n",
    "        signals = signals.float()\n",
    "        signals = signals.to(device)\n",
    "        one_hot_labels = one_hot_labels.to(device)\n",
    "        # print(len(one_hot_labels))\n",
    "        outputs = model(signals)\n",
    "        # if i == 1:\n",
    "        \n",
    "        # print(outputs)\n",
    "        for j, out in enumerate(outputs):\n",
    "            outputs[j] = softmax(out)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "        \n",
    "        for idx in range(len(_)):\n",
    "            if _[idx] < threshold:\n",
    "                predicted[idx] = Unknown_label # 15, 20, 25\n",
    "        # print(_, predicted, one_hot_labels)\n",
    "\n",
    "        n_samples += one_hot_labels.size(0) # add batch_size\n",
    "        n_correct += (predicted == one_hot_labels).sum().item()\n",
    "        \n",
    "        predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "        one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "        predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "        one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "        \n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        # print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
    "    # with open(\"cross_val_result_HCU_BPF_unival_open_level6.txt\", \"a\") as f:\n",
    "    #   f.write(f\"Fold{Fold+1}, Threshold{threshold}\\n\")\n",
    "    #   f.write(classification_report(one_hot_labels_list, predicted_lists, digits=4) + \"\\n\")\n",
    "        print(_, predicted, one_hot_labels)\n",
    "print(classification_report(one_hot_labels_list, predicted_lists, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3f59b86193daf02ac44c2d7d891a49d755eb44400e9ea36eaea4c9328767f1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
