{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp models.InceptionTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">An ensemble of deep Convolutional Neural Network (CNN) models, inspired by the Inception-v4 architecture\n",
    "\n",
    "This is an unofficial PyTorch implementation created by Ignacio Oguiza (timeseriesAI@gmail.com) based on:\n",
    "\n",
    "Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J. & Petitjean, F. (2019). \n",
    "<span style=\"color:dodgerblue\">**InceptionTime: Finding AlexNet for Time Series Classification**</span>. arXiv preprint arXiv:1909.04939. \n",
    "\n",
    "Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from tsai.imports import *\n",
    "from tsai.models.layers import *\n",
    "from torchinfo import summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter\n",
    "num_classes = 30\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "down_ratio = 8\n",
    "sequence_len = 2000 * 5 // down_ratio # default 2000Hz\n",
    "overlap = int(sequence_len * 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_frame_list = []\n",
    "scaler = MinMaxScaler((-1, 1)) # or StandardScaler\n",
    "\n",
    "for i in range(1, num_classes + 1):\n",
    "    # wave_2d = [] # input need to be 2d?\n",
    "    file_path = \"./data/radar_raw_%02d.csv\" % i # or ./data/radar_%02d\n",
    "    radar_frame = pd.read_csv(file_path)\n",
    "    wave = radar_frame.to_numpy().flatten()\n",
    "    wave = signal.decimate(wave, down_ratio) # down sampling\n",
    "    \n",
    "    end = len(wave)\n",
    "    n = 0\n",
    "    n_stop = sequence_len\n",
    "    wave_segments = []\n",
    "\n",
    "    while n_stop < end:\n",
    "        n_start = 0 + ((sequence_len - 1) - (overlap - 1)) * n\n",
    "        n_stop = n_start + sequence_len\n",
    "        tmp = []\n",
    "        seg = wave[n_start:n_stop].copy()\n",
    "        wave_segments.append(seg)\n",
    "        n += 1\n",
    "    \n",
    "    radar_frame_list.append(wave_segments)\n",
    "\n",
    "data_df = pd.DataFrame(radar_frame_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data_df.to_numpy().flatten().copy()\n",
    "data_series = pd.Series(tmp).dropna() # remove None (keys are as they are)\n",
    "tmp = data_series.to_numpy().flatten()\n",
    "data_series = pd.Series(tmp)\n",
    "\n",
    "# data_tensor = torch.tensor(pd.Series([1, 2, 3])) # can't convert tensor cause the content of \"data_series\" is list(ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [4.926630240254833e-06, 1.4333222672800183e-05, 2.8563892909722375e-05, 4.5267547909473175e-05, 6.19818007760084e-05, 7.727021769821957e-05, 9.440563781793546e-05, 0.00011050077080447017, 0.00012459753286014913, 0.0001412548158835628, 0.00015643723024782956, 0.00017108300745707184, 0.0001894730804362307, 0.0002012189665638022, 0.00021338230784617452, 0.00023102134098139306, 0.0002447479042512515, 0.0002637025486000091, 0.00028185310723545303, 0.0002943865180758432, 0.00030862292277653133, 0.0003151617968757195, 0.00032458158369599253, 0.00034350742988201893, 0.0003524286546930069, 0.000358...\n",
       "1       [0.0004806375120394482, 0.00048349914887547594, 0.00048186248408651377, 0.00048432513906944354, 0.0004828917417053433, 0.0004768737853656365, 0.00048266986317777564, 0.0004889606224477032, 0.0004940562601142994, 0.0005014884707390447, 0.0005043017088327971, 0.0005029799964282629, 0.0005039479092611615, 0.0005051606703388853, 0.0005076599116711589, 0.0005062868311728891, 0.0004994380524018505, 0.0004935601659947158, 0.00047891120625829256, 0.00046958016302757244, 0.0004640719378096742, 0.00044867933460419565, 0.00043414708058166056, 0.0004204443553070111, 0.00041311770819340215, 0.000402915...\n",
       "2       [0.0008533200388172372, 0.0008678362984273095, 0.0008827997816043199, 0.0009030655292221869, 0.0009215128944386051, 0.0009436504866337365, 0.0009650480974564312, 0.000979950901798201, 0.0010011608639831277, 0.0010232458977253692, 0.0010383565074058335, 0.0010585939310940298, 0.001075708927238976, 0.0010872561317836502, 0.00110871319457411, 0.001128864145209192, 0.0011440108702747166, 0.0011592272229620875, 0.001175420550566396, 0.0011942218218275347, 0.0012072148708667085, 0.0012276833034841799, 0.0012521624074462502, 0.0012692396208602381, 0.0012917152304443322, 0.0013109083269963208, 0.0...\n",
       "3       [0.0019360725603277426, 0.0019350762471280292, 0.0019323415459355535, 0.0019294981288185348, 0.0019301409055526174, 0.0019253309740824534, 0.001921408145135924, 0.001922597186242845, 0.0019213831049179843, 0.001917728028880422, 0.001914923636983654, 0.001912890696925151, 0.0019094071455806878, 0.0019045602488248815, 0.0019006930802207976, 0.0018989724003794172, 0.0018961060390767395, 0.0018934750594250822, 0.001892383432063576, 0.0018889891153756693, 0.001885277442433134, 0.0018814925243776292, 0.001878241247971775, 0.0018743558013978945, 0.0018683560657242657, 0.0018651960978105474, 0.001...\n",
       "4       [0.0014667995987152147, 0.0014745767074384073, 0.0014842930052771687, 0.0014878149089275336, 0.00148972226731818, 0.0014954795275831032, 0.001501791525527881, 0.001507603475506115, 0.001511132915657794, 0.0015170478453758046, 0.001524328371559691, 0.001528083868607195, 0.0015348378668023916, 0.001540607777881359, 0.0015422520500803037, 0.0015459956733445723, 0.0015512548144411232, 0.0015568131542712028, 0.0015616270543917785, 0.0015647901365028647, 0.0015685820091494154, 0.001574895805508341, 0.001579320239214426, 0.0015815206722404767, 0.00158549904618222, 0.0015919756169898713, 0.0015999...\n",
       "                                                                                                                                                                                                                                                                                                                 ...                                                                                                                                                                                                                                                                                                           \n",
       "5437    [-0.0032832961984428383, -0.003285124733401931, -0.0032883874012928104, -0.003291153459779172, -0.003293226522274602, -0.0032950490330973087, -0.0032975082633636896, -0.0032991036285746037, -0.0033009704110169547, -0.0033042518649272893, -0.0033062181305871774, -0.0033074143111271885, -0.003309009197785089, -0.0033094194147631883, -0.003309659122051772, -0.003311303368249155, -0.003311072834275004, -0.0033123508861582006, -0.0033164423098882025, -0.003318225736163282, -0.0033202027915395574, -0.003322703133821613, -0.003323873161384499, -0.0033245724263806483, -0.0033260632507869613, -0.00...\n",
       "5438    [-0.0027320960662612606, -0.00273904676208177, -0.002741730175974122, -0.0027478478380545683, -0.0027539010930390084, -0.0027587180493402405, -0.0027649377958333617, -0.00276962807120901, -0.00277401794498019, -0.0027771661931967192, -0.00277951771513151, -0.0027820150076512257, -0.002782961703760272, -0.0027824094592083736, -0.0027815467000965413, -0.0027804166852518166, -0.0027782940364166767, -0.002776346679835866, -0.0027742611904159583, -0.002772565221573162, -0.002770774583994692, -0.0027682619532645872, -0.002766941566883559, -0.0027652759262086547, -0.0027631304654487897, -0.002760...\n",
       "5439    [0.0017763562212179346, 0.0017707080002019706, 0.0017650291670182454, 0.0017587111702841622, 0.0017524037272177, 0.0017455310149836112, 0.0017386894868048717, 0.0017325810229522592, 0.0017253860887600917, 0.0017171270238613419, 0.0017095130126371148, 0.001703635576575469, 0.001695928164755404, 0.0016878992642055106, 0.0016823333495748832, 0.0016748700393446777, 0.0016684036403295118, 0.0016639601316925624, 0.0016586095026517999, 0.0016518857865914852, 0.0016454717990807294, 0.001641022187353213, 0.0016358589149484454, 0.0016334899070702088, 0.001631560866007123, 0.0016265615033074741, 0.00...\n",
       "5440    [0.002890688020108981, 0.0028788618907979466, 0.0028711354187454883, 0.002862795691759352, 0.00285171306088448, 0.0028415064902425663, 0.0028315348349621837, 0.0028218537462534575, 0.0028120776719784747, 0.00280375008482299, 0.0027935179505120295, 0.002785330412805273, 0.0027789316315102943, 0.002768635731686579, 0.002761167745022442, 0.0027524032734649834, 0.002744152610633356, 0.002740185605429024, 0.0027331838943597557, 0.0027247168536965035, 0.0027185814920324667, 0.00271155106257378, 0.002704152357034218, 0.0027009342520142423, 0.00269596061690139, 0.00269104999383772, 0.0026887755714...\n",
       "5441    [0.0019554440974621644, 0.0019583369736982724, 0.001964144467473413, 0.0019697486306430654, 0.001975236691246404, 0.0019793618770144817, 0.0019819551374374578, 0.001986560997075999, 0.0019897794300542944, 0.001991810212173295, 0.001993756976802005, 0.001993097966317343, 0.0019922629586859764, 0.0019909354420919794, 0.001990106389406588, 0.0019890180551527573, 0.001984821148902846, 0.001981639001207565, 0.0019778893191076995, 0.0019729410166249607, 0.001969781259388063, 0.001966141134751371, 0.0019641744587291427, 0.0019630537912262995, 0.0019597969618953374, 0.001957879129009408, 0.0019577...\n",
       "Length: 5442, dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5442])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i in range(len(radar_frame_list)):\n",
    "    for j in range(len(radar_frame_list[i])):\n",
    "        labels.append(i + 1)\n",
    "\n",
    "labels_df = pd.Series(labels)\n",
    "labels_tensor = torch.tensor(labels_df)\n",
    "labels_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# This is an unofficial PyTorch implementation by Ignacio Oguiza - timeseriesAI@gmail.com based on:\n",
    "\n",
    "# Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... & Petitjean, F. (2019). \n",
    "# InceptionTime: Finding AlexNet for Time Series Classification. arXiv preprint arXiv:1909.04939.\n",
    "# Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime\n",
    "\n",
    "class InceptionModule(Module):\n",
    "    def __init__(self, ni, nf, ks=40, bottleneck=True):\n",
    "        ks = [ks // (2**i) for i in range(3)]\n",
    "        ks = [k if k % 2 != 0 else k - 1 for k in ks]  # ensure odd ks\n",
    "        bottleneck = bottleneck if ni > 1 else False\n",
    "        self.bottleneck = Conv1d(ni, nf, 1, bias=False) if bottleneck else noop\n",
    "        self.convs = nn.ModuleList([Conv1d(nf if bottleneck else ni, nf, k, bias=False) for k in ks])\n",
    "        self.maxconvpool = nn.Sequential(*[nn.MaxPool1d(3, stride=1, padding=1), Conv1d(ni, nf, 1, bias=False)])\n",
    "        self.concat = Concat()\n",
    "        self.bn = BN1d(nf * 4)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x\n",
    "        x = self.bottleneck(input_tensor)\n",
    "        x = self.concat([l(x) for l in self.convs] + [self.maxconvpool(input_tensor)])\n",
    "        return self.act(self.bn(x))\n",
    "\n",
    "\n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionBlock(Module):\n",
    "    def __init__(self, ni, nf=32, residual=True, depth=6, **kwargs):\n",
    "        self.residual, self.depth = residual, depth\n",
    "        self.inception, self.shortcut = nn.ModuleList(), nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            self.inception.append(InceptionModule(ni if d == 0 else nf * 4, nf, **kwargs))\n",
    "            if self.residual and d % 3 == 2: \n",
    "                n_in, n_out = ni if d == 2 else nf * 4, nf * 4\n",
    "                self.shortcut.append(BN1d(n_in) if n_in == n_out else ConvBlock(n_in, n_out, 1, act=None))\n",
    "        self.add = Add()\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inception[d](x)\n",
    "            if self.residual and d % 3 == 2: res = x = self.act(self.add(x, self.shortcut[d//3](res)))\n",
    "        return x\n",
    "\n",
    "    \n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionTime(Module):\n",
    "    def __init__(self, c_in, c_out, seq_len=None, nf=32, nb_filters=None, **kwargs):\n",
    "        nf = ifnone(nf, nb_filters) # for compatibility\n",
    "        self.inceptionblock = InceptionBlock(c_in, nf, **kwargs) # c_in is input channel num of conv1d\n",
    "        self.gap = GAP1d(1)\n",
    "        self.fc = nn.Linear(nf * 4, c_out) # c_out is 1d output size \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inceptionblock(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "vars = 1\n",
    "seq_len = 12\n",
    "c_out = 2\n",
    "xb = torch.rand(bs, vars, seq_len)\n",
    "test_eq(InceptionTime(vars,c_out)(xb).shape, [bs, c_out])\n",
    "test_eq(InceptionTime(vars,c_out, bottleneck=False)(xb).shape, [bs, c_out])\n",
    "test_eq(InceptionTime(vars,c_out, residual=False)(xb).shape, [bs, c_out])\n",
    "test_eq(count_parameters(InceptionTime(3, 2)), 455490)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionTime(3, 2)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset, labels, root_dir, transform=None) -> None:\n",
    "        # super().__init__()\n",
    "        self.radar_heartbeat = dataset\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "          idx = idx.tolist()\n",
    "        \n",
    "        # onehot_label = torch.eye(num_classes)[self.labels[idx] - 1] # one hot encordingは不要らしい　精度悪い場合試す必要あり\n",
    "        # one_hot = torch.nn.functional.one_hot(self.labels, num_classes=num_classes)\n",
    "        return torch.tensor(self.radar_heartbeat[idx]), self.labels[idx] # labels is already tensor (converted in preparation phase)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.radar_heartbeat)\n",
    "\n",
    "\n",
    "dataset = MyDataset(data_series, labels_tensor, \"./data/\", transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5442"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_series.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full: 5442 -> train: 4353, test: 1089\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(data_series.values))\n",
    "test_size = len(data_series.values) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size]) # check whether each data and label set is synchronized \n",
    "print(f\"full: {len(dataset)} -> train: {len(train_set)}, test: {len(test_set)}\")\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionTime(1, num_classes)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16885/3942043653.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 39], expected input[1, 64, 1250] to have 1 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [198], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m \u001b[39m# print(signals.size())\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[39m=\u001b[39m model(signals)\n\u001b[1;32m     11\u001b[0m \u001b[39m# print(outputs)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels) \u001b[39m# will check the shapes of outputs and labels\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [147], line 57\u001b[0m, in \u001b[0;36mInceptionTime.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 57\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minceptionblock(x)\n\u001b[1;32m     58\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgap(x)\n\u001b[1;32m     59\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [147], line 43\u001b[0m, in \u001b[0;36mInceptionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m res \u001b[39m=\u001b[39m x\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m d, l \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth)):\n\u001b[0;32m---> 43\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minception[d](x)\n\u001b[1;32m     44\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresidual \u001b[39mand\u001b[39;00m d \u001b[39m%\u001b[39m \u001b[39m3\u001b[39m \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m: res \u001b[39m=\u001b[39m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshortcut[d\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m3\u001b[39m](res)))\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [147], line 23\u001b[0m, in \u001b[0;36mInceptionModule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m input_tensor \u001b[39m=\u001b[39m x\n\u001b[1;32m     22\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbottleneck(input_tensor)\n\u001b[0;32m---> 23\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcat([l(x) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs] \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxconvpool(input_tensor)])\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn(x))\n",
      "Cell \u001b[0;32mIn [147], line 23\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m input_tensor \u001b[39m=\u001b[39m x\n\u001b[1;32m     22\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbottleneck(input_tensor)\n\u001b[0;32m---> 23\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcat([l(x) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs] \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxconvpool(input_tensor)])\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn(x))\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/nn/modules/conv.py:307\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/nn/modules/conv.py:303\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    301\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    302\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 303\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    304\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 39], expected input[1, 64, 1250] to have 1 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (signals, labels) in enumerate(train_loader):\n",
    "    signals = torch.tensor(signals)\n",
    "    signals = signals.float()\n",
    "    signals = signals.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # print(signals.size())\n",
    "    outputs = model(signals)\n",
    "    # print(outputs)\n",
    "    loss = criterion(outputs, labels) # will check the shapes of outputs and labels\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # if (i + 1) % 15 == 0:\n",
    "  print(f'Epoch [{epoch+1}/`{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  n_correct = 0\n",
    "  n_samples = 0\n",
    "  softmax = nn.Softmax()\n",
    "  for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "    signals = torch.tensor(signals)\n",
    "    signals = signals.float()\n",
    "    signals = signals.to(device)\n",
    "    one_hot_labels = one_hot_labels.to(device)\n",
    "    # print(len(one_hot_labels))\n",
    "    outputs = model(signals)\n",
    "    for j, out in enumerate(outputs):\n",
    "      outputs[j] = softmax(out)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "\n",
    "    n_samples += one_hot_labels.size(0) # add batch_size\n",
    "    # labels = [] # labels per batch size\n",
    "    for k, labels in enumerate(one_hot_labels):\n",
    "      # labels.append(torch.argmax(one_hot_labels[k]))\n",
    "      if predicted[k] == torch.argmax(labels):\n",
    "        # print(predicted[k], torch.argmax(labels[k]))\n",
    "        n_correct += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'{n_correct} / {n_samples} = Acc: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "174",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 174",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [171], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset[\u001b[39m174\u001b[39;49m]\n",
      "Cell \u001b[0;32mIn [148], line 16\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m   idx \u001b[39m=\u001b[39m idx\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     14\u001b[0m \u001b[39m# onehot_label = torch.eye(num_classes)[self.labels[idx] - 1] # one hot encordingは不要らしい　精度悪い場合試す必要あり\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# one_hot = torch.nn.functional.one_hot(self.labels, num_classes=num_classes)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mradar_heartbeat[idx]), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[idx]\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pandas/core/series.py:982\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    981\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 982\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    985\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pandas/core/series.py:1092\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1091\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1093\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 174"
     ]
    }
   ],
   "source": [
    "dataset[174]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3f59b86193daf02ac44c2d7d891a49d755eb44400e9ea36eaea4c9328767f1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
