{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from tsai.imports import *\n",
    "from tsai.models.layers import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import signal\n",
    "# from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter\n",
    "num_classes = 30\n",
    "close_num = 14 # 14, 19, 24, 29\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 300\n",
    "down_ratio = 8\n",
    "sequence_len = 2000 * 5 // down_ratio # default 2000Hz\n",
    "overlap = int(sequence_len * 0.3)\n",
    "threshold = 0.8\n",
    "thresholds = [0.3, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80]\n",
    "close_nums = [14, 19, 24, 29]\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_frame_list = []\n",
    "scaler = MinMaxScaler((-1, 1)) # or StandardScaler\n",
    "\n",
    "for i in range(1, num_classes + 1):\n",
    "    # wave_2d = [] # input need to be 2d?\n",
    "    file_path = \"./data/radar_%02d.csv\" % i # or ./data/radar_%02d\n",
    "    radar_frame = pd.read_csv(file_path)\n",
    "    wave = radar_frame.to_numpy().flatten()\n",
    "    wave = signal.decimate(wave, down_ratio) # down sampling\n",
    "    \n",
    "    end = len(wave)\n",
    "    n = 0\n",
    "    n_stop = sequence_len\n",
    "    wave_segments = []\n",
    "\n",
    "    while n_stop < end:\n",
    "        n_start = 0 + ((sequence_len - 1) - (overlap - 1)) * n\n",
    "        n_stop = n_start + sequence_len\n",
    "        tmp = []\n",
    "        seg = wave[n_start:n_stop].copy()\n",
    "        wave_segments.append([seg])\n",
    "        n += 1\n",
    "    \n",
    "    radar_frame_list.append(wave_segments)\n",
    "\n",
    "data_df = pd.DataFrame(radar_frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(radar_frame_list)):\n",
    "    for j in range(len(radar_frame_list[i])):\n",
    "        if i <= close_num:\n",
    "            labels.append(i)\n",
    "        else:\n",
    "            labels.append(close_num + 1)\n",
    "\n",
    "labels_series = pd.Series(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5441 900\n",
      "5262 838\n",
      "5086 725\n",
      "4911 1219\n",
      "4732 507\n",
      "4497 1107\n",
      "4321 1244\n",
      "4147 838\n",
      "3953 438\n",
      "3764 1232\n",
      "3589 788\n",
      "3406 1150\n",
      "3234 619\n",
      "3052 1188\n",
      "2880 388\n",
      "2705 1113\n",
      "2348 1157\n",
      "2141 1113\n",
      "1956 1232\n",
      "1771 532\n",
      "1588 475\n",
      "1402 644\n",
      "1225 1232\n",
      "1044 482\n",
      "869 1150\n",
      "695 1144\n",
      "523 713\n",
      "351 713\n",
      "173 525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5413,), tensor([ 0,  0,  0,  ..., 15, 15, 15]), torch.Size([5413]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = data_df.to_numpy().flatten().copy()\n",
    "data_series = pd.Series(tmp).dropna() # remove None (keys are as they are)\n",
    "tmp = data_series.to_numpy().flatten()\n",
    "\n",
    "tmp_labels = labels_series.to_numpy().flatten()\n",
    "# len(tmp) = 5442 (30人分のデータ)\n",
    "# len(tmp[0]) = 1 (in_channelが1のため)\n",
    "# len(tmp[0][0]) = 1250 (sequence_len)\n",
    "\n",
    "for i in reversed(range(len(tmp))):\n",
    "  if len(tmp[i][0]) != sequence_len:\n",
    "    print(i, len(tmp[i][0]))\n",
    "    tmp = np.delete(tmp, i)\n",
    "    tmp_labels = np.delete(tmp_labels, i)\n",
    "\n",
    "data_series = pd.Series(tmp)\n",
    "labels_series = pd.Series(tmp_labels)\n",
    "labels_tensor = torch.tensor(labels_series)\n",
    "data_series.shape, labels_tensor, labels_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(Module):\n",
    "    def __init__(self, ni, nf, ks=40, bottleneck=True):\n",
    "        ks = [ks // (2**i) for i in range(3)]\n",
    "        ks = [k if k % 2 != 0 else k - 1 for k in ks]  # ensure odd ks\n",
    "        bottleneck = bottleneck if ni > 1 else False\n",
    "        self.bottleneck = Conv1d(ni, nf, 1, bias=False) if bottleneck else noop\n",
    "        self.convs = nn.ModuleList([Conv1d(nf if bottleneck else ni, nf, k, bias=False) for k in ks])\n",
    "        self.maxconvpool = nn.Sequential(*[nn.MaxPool1d(3, stride=1, padding=1), Conv1d(ni, nf, 1, bias=False)])\n",
    "        self.concat = Concat()\n",
    "        self.bn = BN1d(nf * 4)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x\n",
    "        x = self.bottleneck(input_tensor)\n",
    "        x = self.concat([l(x) for l in self.convs] + [self.maxconvpool(input_tensor)])\n",
    "        return self.act(self.bn(x))\n",
    "\n",
    "\n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionBlock(Module):\n",
    "    def __init__(self, ni, nf=32, residual=True, depth=6, **kwargs):\n",
    "        self.residual, self.depth = residual, depth\n",
    "        self.inception, self.shortcut = nn.ModuleList(), nn.ModuleList()\n",
    "        for d in range(depth):\n",
    "            self.inception.append(InceptionModule(ni if d == 0 else nf * 4, nf, **kwargs))\n",
    "            if self.residual and d % 3 == 2: \n",
    "                n_in, n_out = ni if d == 2 else nf * 4, nf * 4\n",
    "                self.shortcut.append(BN1d(n_in) if n_in == n_out else ConvBlock(n_in, n_out, 1, act=None))\n",
    "        self.add = Add()\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inception[d](x)\n",
    "            if self.residual and d % 3 == 2: res = x = self.act(self.add(x, self.shortcut[d//3](res)))\n",
    "        return x\n",
    "\n",
    "    \n",
    "@delegates(InceptionModule.__init__)\n",
    "class InceptionTime(Module):\n",
    "    def __init__(self, c_in, c_out, seq_len=None, nf=32, nb_filters=None, **kwargs):\n",
    "        nf = ifnone(nf, nb_filters) # for compatibility\n",
    "        self.inceptionblock = InceptionBlock(c_in, nf, **kwargs) # c_in is input channel num of conv1d\n",
    "        self.gap = GAP1d(1)\n",
    "        self.fc = nn.Linear(nf * 4, c_out) # c_out is 1d output size \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.inceptionblock(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset, labels, root_dir, transform=None) -> None:\n",
    "        # super().__init__()\n",
    "        self.radar_heartbeat = dataset\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "          idx = idx.tolist()\n",
    "        \n",
    "        onehot_label = torch.eye(num_classes)[self.labels[idx] - 1] # one hot encodingは不要らしい　精度悪い場合試す必要あり\n",
    "        # one_hot = torch.nn.functional.one_hot(self.labels, num_classes=num_classes)\n",
    "        return torch.tensor(self.radar_heartbeat[idx]), self.labels[idx] # labels is already tensor (converted in preparation phase)\n",
    "        # return torch.tensor(self.radar_heartbeat[idx]), onehot_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.radar_heartbeat)\n",
    "\n",
    "\n",
    "dataset = MyDataset(data_series, labels_tensor, \"./data/\", transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31087/3033810394.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return torch.tensor(self.radar_heartbeat[idx]), self.labels[idx] # labels is already tensor (converted in preparation phase)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(15), tensor(15), tensor(15))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1], dataset[4473][1], dataset[4474][1], dataset[len(dataset)-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(15), tensor(15))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3570][1], dataset[3571][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(14), tensor(15))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2691][1], dataset[2692][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional processing for Open Set\n",
    "\n",
    "e.g.\n",
    "train 0~24\n",
    "\n",
    "test 0~30\n",
    "\n",
    "concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices1 = np.arange(4473)\n",
    "# dataset1 = torch.utils.data.Subset(dataset, indices1) # 0-24\n",
    "# indices2 = np.arange(4474, len(dataset))\n",
    "# dataset2 = torch.utils.data.Subset(dataset, indices2) # 25-30\n",
    "# Unknown_label = close_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices1 = np.arange(3570)\n",
    "# dataset1 = torch.utils.data.Subset(dataset, indices1) # 0-19\n",
    "# indices2 = np.arange(3571, len(dataset))\n",
    "# dataset2 = torch.utils.data.Subset(dataset, indices2) # 20-30\n",
    "# Unknown_label = close_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices1 = np.arange(2691)\n",
    "dataset1 = torch.utils.data.Subset(dataset, indices1) # 0-14\n",
    "indices2 = np.arange(2692, len(dataset))\n",
    "dataset2 = torch.utils.data.Subset(dataset, indices2) # 15-29\n",
    "Unknown_label = close_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size1 = int(0.80 * len(dataset1))\n",
    "test_size1 = len(dataset1) - train_size1\n",
    "\n",
    "train_size2 = int(0.80 * len(dataset2))\n",
    "test_size2 = len(dataset2) - train_size2\n",
    "\n",
    "open_train_set, test_set1 = torch.utils.data.random_split(dataset1, [train_size1, test_size1])\n",
    "train_set2, test_set2 = torch.utils.data.random_split(dataset2, [train_size2, test_size2])\n",
    "\n",
    "indices = np.arange(len(test_set2))\n",
    "test_set2 = torch.utils.data.Subset(test_set2, indices[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train : test = 8 : 2 → 3 : 1で分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2152, 1084)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_test_set = torch.utils.data.ConcatDataset([test_set1, test_set2])\n",
    "len(open_train_set), len(open_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.80 * len(data_series.values))\n",
    "test_size = len(data_series.values) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size]) # check whether each data and label set is synchronized \n",
    "# print(f\"full: {len(dataset)} -> train: {len(train_set)}, test: {len(test_set)}\")\n",
    "\n",
    "train_loader = DataLoader(dataset=open_train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=open_test_set, batch_size=batch_size, shuffle=True) # テストでシャッフルしても同じ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triple Joint Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import log\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def softmax_loss(outputs, labels):\n",
    "    loss = 0\n",
    "    batch_size = len(labels)\n",
    "    softmax_out = softmax(outputs)\n",
    "    for idx in range(batch_size):\n",
    "        loss += 1.0 - log(softmax_out[labels[idx]])\n",
    "    return loss / batch_size\n",
    "\n",
    "\n",
    "from center_loss import CenterLoss\n",
    "center_loss = CenterLoss(num_classes=close_num + 1, feat_dim=1, use_gpu=True)\n",
    "optimizer_centloss = torch.optim.SGD(center_loss.parameters(), lr=0.05)\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type='cosface', eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 30.0 if not s else s\n",
    "            self.m = 0.45 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L)\n",
    "\n",
    "cos_loss = AngularPenaltySMLoss(1, close_num + 1, loss_type=\"cosface\")\n",
    "\n",
    "\n",
    "def triple_joint_loss(output, label, alpha):\n",
    "    # alpha: hyper parameter\n",
    "    output_for_cent = []\n",
    "    for idx, x in enumerate(output):\n",
    "        x = x[label[idx]]\n",
    "        x = torch.tensor(x).to(device)\n",
    "        output_for_cent.append([x])\n",
    "    output_for_cent = torch.tensor(output_for_cent)\n",
    "    output_for_cent = output_for_cent.float()\n",
    "    output_for_cent = output_for_cent.to(device)\n",
    "    return softmax_loss(output, label) + alpha * center_loss(output_for_cent, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "model = model.to(device)\n",
    "# criterion = nn.CrossEntropyLoss() # TJL使うときはコメントアウト\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "InceptionTime                                 --\n",
       "├─InceptionBlock: 1-1                         --\n",
       "│    └─ModuleList: 2-1                        --\n",
       "│    │    └─InceptionModule: 3-1              2,432\n",
       "│    │    └─InceptionModule: 3-2              77,056\n",
       "│    │    └─InceptionModule: 3-3              77,056\n",
       "│    │    └─InceptionModule: 3-4              77,056\n",
       "│    │    └─InceptionModule: 3-5              77,056\n",
       "│    │    └─InceptionModule: 3-6              77,056\n",
       "│    └─ModuleList: 2-2                        --\n",
       "│    │    └─ConvBlock: 3-7                    384\n",
       "│    │    └─BatchNorm1d: 3-8                  256\n",
       "│    └─Add: 2-3                               --\n",
       "│    └─ReLU: 2-4                              --\n",
       "├─GAP1d: 1-2                                  --\n",
       "│    └─AdaptiveAvgPool1d: 2-5                 --\n",
       "│    └─Flatten: 2-6                           --\n",
       "├─Linear: 1-3                                 1,935\n",
       "======================================================================\n",
       "Total params: 390,287\n",
       "Trainable params: 390,287\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22252/1573358285.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/tmp/ipykernel_22252/1573358285.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).to(device)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/center_loss.py:45: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
      "  distmat.addmm_(1, -2, x, self.centers.t())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/`20], Step [12/34], Loss: 0.8664\n",
      "Epoch [1/`20], Step [24/34], Loss: 0.7056\n",
      "Epoch [2/`20], Step [12/34], Loss: 0.6349\n",
      "Epoch [2/`20], Step [24/34], Loss: 0.3538\n",
      "Epoch [3/`20], Step [12/34], Loss: 0.3928\n",
      "Epoch [3/`20], Step [24/34], Loss: 0.2485\n",
      "Epoch [4/`20], Step [12/34], Loss: 0.2200\n",
      "Epoch [4/`20], Step [24/34], Loss: 0.2082\n",
      "Epoch [5/`20], Step [12/34], Loss: 0.1202\n",
      "Epoch [5/`20], Step [24/34], Loss: 0.1365\n",
      "Epoch [6/`20], Step [12/34], Loss: 0.1034\n",
      "Epoch [6/`20], Step [24/34], Loss: 0.0619\n",
      "Epoch [7/`20], Step [12/34], Loss: 0.0591\n",
      "Epoch [7/`20], Step [24/34], Loss: 0.0536\n",
      "Epoch [8/`20], Step [12/34], Loss: 0.0448\n",
      "Epoch [8/`20], Step [24/34], Loss: 0.0444\n",
      "Epoch [9/`20], Step [12/34], Loss: 0.0336\n",
      "Epoch [9/`20], Step [24/34], Loss: 0.0283\n",
      "Epoch [10/`20], Step [12/34], Loss: 0.0175\n",
      "Epoch [10/`20], Step [24/34], Loss: 0.0192\n",
      "Epoch [11/`20], Step [12/34], Loss: 0.0298\n",
      "Epoch [11/`20], Step [24/34], Loss: 0.0177\n",
      "Epoch [12/`20], Step [12/34], Loss: 0.0136\n",
      "Epoch [12/`20], Step [24/34], Loss: 0.0144\n",
      "Epoch [13/`20], Step [12/34], Loss: 0.0147\n",
      "Epoch [13/`20], Step [24/34], Loss: 0.0118\n",
      "Epoch [14/`20], Step [12/34], Loss: 0.0152\n",
      "Epoch [14/`20], Step [24/34], Loss: 0.0151\n",
      "Epoch [15/`20], Step [12/34], Loss: 0.0084\n",
      "Epoch [15/`20], Step [24/34], Loss: 0.0116\n",
      "Epoch [16/`20], Step [12/34], Loss: 0.0100\n",
      "Epoch [16/`20], Step [24/34], Loss: 0.0074\n",
      "Epoch [17/`20], Step [12/34], Loss: 0.0269\n",
      "Epoch [17/`20], Step [24/34], Loss: 0.0133\n",
      "Epoch [18/`20], Step [12/34], Loss: 0.0159\n",
      "Epoch [18/`20], Step [24/34], Loss: 0.0049\n",
      "Epoch [19/`20], Step [12/34], Loss: 0.0102\n",
      "Epoch [19/`20], Step [24/34], Loss: 0.0246\n",
      "Epoch [20/`20], Step [12/34], Loss: 0.0102\n",
      "Epoch [20/`20], Step [24/34], Loss: 0.0180\n"
     ]
    }
   ],
   "source": [
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "  for i, (signals, labels) in enumerate(train_loader):\n",
    "    signals = torch.tensor(signals)\n",
    "    signals = signals.float()\n",
    "    signals = signals.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # print(signals.size())\n",
    "    outputs = model(signals)\n",
    "    # print(outputs)\n",
    "    loss = triple_joint_loss(outputs, labels, alpha) # will check the shapes of outputs and labels\n",
    "    \n",
    "\n",
    "    loss = center_loss(output_for_cent, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_centloss.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer_centloss.step()\n",
    "    if (i + 1) % 12 == 0:\n",
    "      print(f'Epoch [{epoch+1}/`{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labelは0-24までだから，学習はいじらなくて大丈夫\n",
    "\n",
    "testはOpen setの場合，0~24とUnknown label(25)になるから，labelは作り直し\n",
    "\n",
    "25も出力するようなネットワークにしなきゃだめ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22252/1821349815.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBase([0.1256, 0.1308, 0.1252, 0.1031, 0.1097, 0.1097, 0.1138, 0.1134,\n",
      "            0.1231, 0.1182, 0.1043, 0.1081, 0.1097, 0.1133, 0.1187, 0.1106,\n",
      "            0.1115, 0.1222, 0.1147, 0.1229, 0.1022, 0.1225, 0.1041, 0.1236,\n",
      "            0.1081, 0.1107, 0.1022, 0.1106, 0.1123, 0.1151, 0.1319, 0.1289,\n",
      "            0.1117, 0.1085, 0.1071, 0.1151, 0.1047, 0.1180, 0.1184, 0.1054,\n",
      "            0.1211, 0.1038, 0.1067, 0.1265, 0.1181, 0.1152, 0.1081, 0.1160,\n",
      "            0.1031, 0.1174, 0.1242, 0.1126, 0.1069, 0.1179, 0.1055, 0.1158,\n",
      "            0.1197, 0.1303, 0.1095, 0.1149, 0.1319, 0.1177, 0.1242, 0.1098],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15, 15, 15,  6, 15, 15,  9, 12, 15,  0, 15,  9, 15,  7, 15, 11, 14, 15,\n",
      "        15, 15,  9,  3, 11, 15, 15,  1, 15, 15, 10, 14, 15, 15, 15, 15, 15, 14,\n",
      "        10, 15, 15,  7, 15, 15,  9, 15, 13,  2, 15, 15, 15, 15, 15, 15,  7, 15,\n",
      "        15,  2, 15, 15, 13, 15, 12, 15,  5, 15], device='cuda:0')\n",
      "39 / 64 = Acc: 60.9375 %\n",
      "TensorBase([0.0997, 0.1021, 0.1014, 0.0974, 0.0958, 0.1130, 0.1014, 0.1028,\n",
      "            0.1082, 0.1041, 0.0986, 0.0971, 0.0979, 0.1033, 0.1063, 0.1073,\n",
      "            0.1060, 0.1156, 0.1007, 0.1077, 0.1075, 0.1110, 0.1048, 0.1112,\n",
      "            0.1055, 0.1058, 0.0968, 0.1034, 0.0981, 0.1063, 0.1075, 0.1020,\n",
      "            0.1023, 0.1015, 0.1101, 0.1158, 0.1056, 0.1078, 0.1078, 0.3045,\n",
      "            0.1054, 0.1012, 0.1120, 0.1041, 0.1029, 0.0963, 0.1107, 0.0996,\n",
      "            0.1005, 0.0997, 0.0990, 0.1064, 0.1286, 0.1082, 0.1050, 0.1089,\n",
      "            0.1069, 0.1112, 0.1241, 0.1050, 0.1069, 0.1125, 0.0962, 0.1092],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([14, 11, 15,  9, 11,  5,  6,  9,  7, 15,  6,  2, 15, 15,  8, 15,  7, 15,\n",
      "        15, 15, 15,  4, 11, 15,  4, 15, 15, 15, 15,  1,  5, 10,  9,  6,  3, 15,\n",
      "        12,  2, 15, 15, 15,  9, 15, 15,  7, 15, 15, 15,  9,  4,  7, 14, 10, 12,\n",
      "        15, 12,  3, 15,  4, 15, 15, 15,  6, 15], device='cuda:0')\n",
      "68 / 128 = Acc: 53.125 %\n",
      "TensorBase([0.1144, 0.1010, 0.1044, 0.0984, 0.1098, 0.1192, 0.1347, 0.1263,\n",
      "            0.1155, 0.1085, 0.1125, 0.1190, 0.1134, 0.1044, 0.1123, 0.1119,\n",
      "            0.1353, 0.1101, 0.1288, 0.1204, 0.1086, 0.1259, 0.1068, 0.1252,\n",
      "            0.1079, 0.1061, 0.1223, 0.1193, 0.1152, 0.1086, 0.1070, 0.1099,\n",
      "            0.1094, 0.1006, 0.1178, 0.1322, 0.1090, 0.1198, 0.1247, 0.1140,\n",
      "            0.1178, 0.1243, 0.1073, 0.1256, 0.1027, 0.1151, 0.1073, 0.1228,\n",
      "            0.1103, 0.1117, 0.1118, 0.1123, 0.1238, 0.1173, 0.1286, 0.1081,\n",
      "            0.1217, 0.1071, 0.1141, 0.1128, 0.1041, 0.1198, 0.1056, 0.1078],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([ 2,  9, 11, 15, 15, 15, 15, 15, 12,  8, 15, 13, 15,  9, 15, 15, 15,  6,\n",
      "        15, 15,  7, 15, 11,  5, 15, 15, 15, 15, 15,  7, 15, 15, 15, 15, 13,  0,\n",
      "        15, 15,  5, 10,  1, 15, 15,  8, 10,  1,  6,  3, 10,  2,  4, 15, 15, 15,\n",
      "         5,  9, 15, 15,  0, 15, 15, 15,  4, 10], device='cuda:0')\n",
      "102 / 192 = Acc: 53.125 %\n",
      "TensorBase([0.1078, 0.1055, 0.1099, 0.1543, 0.1122, 0.1130, 0.1192, 0.1053,\n",
      "            0.1072, 0.1175, 0.1091, 0.1220, 0.1213, 0.1063, 0.1109, 0.1160,\n",
      "            0.1150, 0.1115, 0.0985, 0.1150, 0.1117, 0.1080, 0.1298, 0.1184,\n",
      "            0.1097, 0.1329, 0.1194, 0.1080, 0.1101, 0.1072, 0.1194, 0.1129,\n",
      "            0.1184, 0.1198, 0.1131, 0.1083, 0.1020, 0.1216, 0.1063, 0.1105,\n",
      "            0.1165, 0.1136, 0.1185, 0.1002, 0.1105, 0.1109, 0.1014, 0.1031,\n",
      "            0.1112, 0.1237, 0.1125, 0.1200, 0.1036, 0.1021, 0.1224, 0.1088,\n",
      "            0.1075, 0.1062, 0.1126, 0.1219, 0.1057, 0.1048, 0.1033, 0.1092],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15, 15, 15,  4, 13, 15, 15,  9, 15,  2,  4, 15,  8,  7, 13,  0,  8, 15,\n",
      "        15, 15, 15, 13, 15, 13,  7,  6, 12, 15, 15, 11, 15, 13,  5, 15,  1, 15,\n",
      "        11,  7, 15, 14,  3, 12, 15,  9,  2, 15, 15, 15,  1,  8,  1,  0, 15, 11,\n",
      "        15, 15, 15, 15,  6,  3, 15,  6, 15,  2], device='cuda:0')\n",
      "131 / 256 = Acc: 51.171875 %\n",
      "TensorBase([0.1150, 0.1090, 0.1074, 0.0926, 0.1051, 0.1325, 0.1091, 0.1137,\n",
      "            0.1060, 0.1092, 0.0981, 0.1071, 0.1153, 0.1126, 0.1071, 0.0991,\n",
      "            0.1068, 0.1097, 0.1127, 0.0994, 0.1009, 0.1013, 0.0988, 0.1064,\n",
      "            0.1092, 0.0963, 0.1093, 0.1124, 0.1030, 0.1119, 0.1125, 0.1181,\n",
      "            0.1023, 0.1053, 0.1024, 0.1130, 0.1122, 0.0953, 0.1165, 0.1112,\n",
      "            0.1129, 0.1086, 0.1096, 0.1040, 0.1084, 0.1236, 0.0985, 0.1015,\n",
      "            0.1100, 0.0997, 0.1815, 0.1106, 0.1064, 0.1107, 0.1411, 0.1137,\n",
      "            0.1165, 0.1107, 0.1049, 0.1010, 0.1093, 0.1120, 0.1017, 0.1181],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15, 10, 15, 15, 15, 15,  8, 15,  2, 15, 15, 14, 15, 15, 15, 15, 11, 15,\n",
      "         6,  2,  6,  2, 15, 15,  2, 15, 10, 15, 11,  1, 15, 15, 15, 10, 15, 14,\n",
      "         0, 15, 15, 14, 15,  3, 15, 15,  7,  0, 15,  6, 11, 10,  6, 15, 15, 14,\n",
      "         3, 13, 15,  1, 15, 11,  6,  9, 15, 15], device='cuda:0')\n",
      "164 / 320 = Acc: 51.25 %\n",
      "TensorBase([0.1136, 0.1104, 0.1018, 0.1662, 0.1031, 0.1079, 0.1151, 0.1144,\n",
      "            0.0967, 0.1119, 0.1222, 0.1022, 0.0945, 0.1071, 0.1156, 0.1129,\n",
      "            0.1079, 0.1059, 0.0996, 0.1042, 0.1094, 0.1095, 0.1051, 0.0981,\n",
      "            0.1200, 0.1078, 0.1078, 0.1043, 0.1295, 0.1163, 0.1233, 0.1065,\n",
      "            0.1139, 0.1121, 0.1083, 0.0938, 0.1147, 0.1111, 0.0950, 0.1046,\n",
      "            0.1142, 0.1197, 0.1302, 0.1732, 0.1171, 0.1121, 0.1080, 0.1156,\n",
      "            0.1056, 0.1095, 0.1126, 0.1093, 0.1090, 0.1053, 0.0973, 0.1123,\n",
      "            0.1046, 0.1037, 0.1182, 0.1205, 0.1159, 0.1027, 0.0940, 0.1063],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15, 14, 15, 15, 10, 15,  4, 15, 15, 15,  6, 15, 15,  4,  2,  8,  6,  2,\n",
      "        15,  7,  6,  5, 15, 15, 15,  7,  4, 15, 15, 15, 15,  3,  1, 15,  7, 15,\n",
      "        13,  1, 15, 11,  7,  5,  4,  8,  5,  3, 14, 14, 15, 10, 15, 15,  0, 15,\n",
      "        15, 15, 15, 11, 15, 12, 15, 15, 15,  4], device='cuda:0')\n",
      "195 / 384 = Acc: 50.78125 %\n",
      "TensorBase([0.1026, 0.1155, 0.1154, 0.1073, 0.1136, 0.1095, 0.1118, 0.1123,\n",
      "            0.1077, 0.1035, 0.1441, 0.1143, 0.1114, 0.1219, 0.1030, 0.1054,\n",
      "            0.1154, 0.1057, 0.1088, 0.1129, 0.1039, 0.1049, 0.0977, 0.1182,\n",
      "            0.1147, 0.1018, 0.1203, 0.0998, 0.1004, 0.1255, 0.1108, 0.1068,\n",
      "            0.1162, 0.1200, 0.1006, 0.1054, 0.1056, 0.1169, 0.1085, 0.1275,\n",
      "            0.1124, 0.1046, 0.1241, 0.1181, 0.1048, 0.1164, 0.1029, 0.1395,\n",
      "            0.1064, 0.1113, 0.1031, 0.1143, 0.1207, 0.0953, 0.1067, 0.1266,\n",
      "            0.1164, 0.1175, 0.1076, 0.1048, 0.1116, 0.1083, 0.0993, 0.1086],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([11, 15, 15,  1, 15, 15, 12,  4, 15, 15,  5,  1,  3,  0, 11, 15,  3, 11,\n",
      "        11,  7,  7, 15, 15, 15, 15, 15,  8, 11, 15, 15, 15, 15, 15, 15, 15, 10,\n",
      "        15, 15, 15, 15, 13,  5,  1, 15,  0, 12, 15,  5, 14,  4, 15,  1,  0,  6,\n",
      "        11, 15, 12, 15, 15,  9, 15, 15,  4,  1], device='cuda:0')\n",
      "226 / 448 = Acc: 50.44642857142857 %\n",
      "TensorBase([0.1043, 0.1280, 0.0973, 0.1136, 0.1150, 0.1087, 0.1192, 0.0991,\n",
      "            0.1093, 0.0985, 0.1097, 0.1269, 0.1180, 0.1181, 0.1265, 0.1154,\n",
      "            0.1052, 0.1195, 0.1095, 0.1022, 0.1192, 0.1178, 0.1163, 0.1185,\n",
      "            0.0972, 0.1149, 0.1123, 0.1128, 0.1104, 0.1103, 0.1134, 0.1152,\n",
      "            0.1064, 0.1089, 0.1141, 0.1075, 0.1091, 0.1072, 0.1296, 0.1204,\n",
      "            0.1111, 0.1037, 0.1001, 0.1181, 0.1079, 0.1309, 0.1190, 0.1031,\n",
      "            0.1192, 0.1173, 0.1164, 0.1105, 0.1237, 0.1135, 0.1036, 0.1051,\n",
      "            0.1069, 0.1134, 0.1083, 0.1147, 0.1149, 0.1096, 0.1086, 0.1354],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15, 15, 11,  8, 13, 15, 12,  9, 15, 15,  9,  5, 15, 14, 15,  2, 15, 15,\n",
      "         5, 15, 12,  6, 15, 12, 15, 15, 15, 15, 15, 15,  3,  2, 15, 15,  0,  2,\n",
      "        14, 15, 15, 13,  1, 10, 15, 15, 11, 15, 15, 15, 15,  4, 15, 15,  4, 15,\n",
      "        15,  9,  3, 15, 15,  7, 15, 12,  3, 15], device='cuda:0')\n",
      "261 / 512 = Acc: 50.9765625 %\n",
      "TensorBase([0.1007, 0.1153, 0.1036, 0.1124, 0.1144, 0.1144, 0.1112, 0.1083,\n",
      "            0.1094, 0.1151, 0.1076, 0.1180, 0.1100, 0.1135, 0.1150, 0.1100,\n",
      "            0.1184, 0.1177, 0.1108, 0.1120, 0.1078, 0.1095, 0.1016, 0.1089,\n",
      "            0.1026, 0.1029, 0.1053, 0.1169, 0.1126, 0.1275, 0.1075, 0.1038,\n",
      "            0.1068, 0.1114, 0.1121, 0.1104, 0.1055, 0.1097, 0.1121, 0.1170,\n",
      "            0.1197, 0.1103, 0.1159, 0.1270, 0.1209, 0.1134, 0.1115, 0.1174,\n",
      "            0.1172, 0.1239, 0.1155, 0.1065, 0.1261, 0.1090, 0.1117, 0.1147,\n",
      "            0.1034, 0.1119, 0.1338, 0.1093, 0.1188, 0.1149, 0.1200, 0.1279],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15, 14,  6, 15, 15, 15, 12, 15, 15, 15, 10, 15,  7,  0, 15, 15, 13,  1,\n",
      "        15, 15,  9, 14, 10, 13, 14, 15, 15,  1,  0, 15,  1, 15, 15, 15, 15,  2,\n",
      "        15, 15,  0,  3,  1, 10,  1, 15, 15, 15, 15, 15, 15,  4,  6, 15, 15, 15,\n",
      "        15, 10,  7,  5, 15,  4,  5, 15,  3,  3], device='cuda:0')\n",
      "294 / 576 = Acc: 51.041666666666664 %\n",
      "TensorBase([0.1115, 0.1227, 0.1029, 0.1127, 0.1048, 0.1132, 0.1118, 0.1035,\n",
      "            0.1143, 0.1116, 0.1187, 0.1128, 0.1131, 0.1123, 0.1154, 0.1046,\n",
      "            0.1138, 0.0976, 0.1050, 0.1119, 0.1124, 0.1091, 0.1154, 0.1049,\n",
      "            0.1119, 0.1051, 0.1084, 0.1157, 0.1101, 0.1115, 0.1044, 0.1185,\n",
      "            0.1025, 0.1198, 0.1096, 0.1128, 0.1079, 0.1063, 0.1158, 0.1067,\n",
      "            0.1130, 0.1061, 0.1071, 0.0940, 0.1148, 0.1181, 0.1113, 0.1149,\n",
      "            0.1231, 0.1168, 0.1391, 0.1184, 0.1121, 0.1167, 0.1133, 0.1307,\n",
      "            0.1092, 0.1142, 0.1089, 0.1049, 0.1021, 0.1143, 0.1115, 0.1018],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15,  6, 15, 15,  4,  7, 15, 15, 12,  0,  8,  2, 15, 13,  7,  2,  2, 15,\n",
      "        11,  7,  2,  9, 15, 10,  3, 15,  8, 12, 15, 11, 14, 15, 10, 15, 15,  0,\n",
      "         9, 15,  7, 15, 14, 15, 15, 15, 12,  0, 15, 14, 15,  8, 15, 13, 15, 15,\n",
      "        15, 15,  0, 15,  7,  5, 15,  3, 15,  6], device='cuda:0')\n",
      "322 / 640 = Acc: 50.3125 %\n",
      "TensorBase([0.1066, 0.1003, 0.1222, 0.1139, 0.0983, 0.1064, 0.0970, 0.1115,\n",
      "            0.1091, 0.1172, 0.1040, 0.1100, 0.1022, 0.1060, 0.1047, 0.1111,\n",
      "            0.1147, 0.1108, 0.1094, 0.1050, 0.1207, 0.0978, 0.1072, 0.1173,\n",
      "            0.1138, 0.1147, 0.1111, 0.1081, 0.1026, 0.1080, 0.1031, 0.1111,\n",
      "            0.1067, 0.1067, 0.0984, 0.1218, 0.1003, 0.1464, 0.1454, 0.1083,\n",
      "            0.0970, 0.1010, 0.0989, 0.1049, 0.1145, 0.1170, 0.1002, 0.1091,\n",
      "            0.1054, 0.1200, 0.1079, 0.1087, 0.1011, 0.1071, 0.1129, 0.1039,\n",
      "            0.1076, 0.0960, 0.1014, 0.1154, 0.0983, 0.1099, 0.0947, 0.1153],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15, 15, 15,  1, 15, 15,  9, 15, 13, 15, 14,  5, 15,  7, 15, 15, 15, 15,\n",
      "         7,  6, 15,  6, 15, 15, 15, 15, 15,  1,  3, 15, 15, 15, 15, 13, 10,  4,\n",
      "         6, 15, 15, 15, 15,  6, 15,  0,  3,  5, 15, 15, 15, 15, 15, 14,  3,  2,\n",
      "        15, 15, 15, 15, 15, 15, 15, 13, 11, 15], device='cuda:0')\n",
      "362 / 704 = Acc: 51.42045454545455 %\n",
      "TensorBase([0.1142, 0.1528, 0.1075, 0.1216, 0.1249, 0.1251, 0.1012, 0.1135,\n",
      "            0.1265, 0.1199, 0.1067, 0.1129, 0.0988, 0.1118, 0.1245, 0.1069,\n",
      "            0.1215, 0.1119, 0.1116, 0.1028, 0.1107, 0.1079, 0.1075, 0.1049,\n",
      "            0.1025, 0.1137, 0.1064, 0.1242, 0.1209, 0.1064, 0.0957, 0.1159,\n",
      "            0.1052, 0.1078, 0.1186, 0.1111, 0.1021, 0.1116, 0.1019, 0.1238,\n",
      "            0.1168, 0.1072, 0.1050, 0.1164, 0.1021, 0.1089, 0.0992, 0.1097,\n",
      "            0.1064, 0.1208, 0.1154, 0.1005, 0.1195, 0.1079, 0.1127, 0.1165,\n",
      "            0.1250, 0.1225, 0.1111, 0.1078, 0.1099, 0.1096, 0.1145, 0.1182],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([ 3,  8, 15,  8, 15, 15, 11, 14,  3, 13, 15, 15, 15,  0, 15, 15, 15,  3,\n",
      "        15, 15,  5, 11, 15, 15, 15, 15,  6,  5, 15, 15, 15, 15,  2,  9,  1,  2,\n",
      "        10, 15,  9,  4, 15, 10,  7,  2, 15, 14, 15, 10, 15, 15,  4, 15, 15, 13,\n",
      "        15, 12, 15, 15, 14, 15, 14, 15,  6, 15], device='cuda:0')\n",
      "395 / 768 = Acc: 51.432291666666664 %\n",
      "TensorBase([0.1116, 0.1042, 0.1126, 0.1086, 0.1104, 0.1036, 0.1110, 0.0987,\n",
      "            0.1066, 0.1105, 0.1015, 0.1088, 0.1111, 0.1062, 0.1126, 0.0936,\n",
      "            0.1067, 0.1084, 0.1040, 0.1075, 0.1047, 0.1084, 0.1067, 0.1113,\n",
      "            0.0969, 0.1022, 0.1100, 0.1034, 0.1202, 0.0964, 0.1119, 0.1086,\n",
      "            0.1076, 0.1110, 0.1784, 0.1090, 0.1155, 0.0974, 0.1078, 0.0985,\n",
      "            0.1145, 0.0992, 0.1015, 0.1091, 0.1018, 0.1030, 0.0964, 0.1164,\n",
      "            0.1145, 0.1055, 0.0933, 0.1088, 0.0935, 0.1054, 0.1118, 0.1000,\n",
      "            0.1036, 0.1112, 0.0954, 0.1042, 0.0968, 0.1156, 0.0958, 0.1070],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15, 15, 15, 15, 15, 15,  2, 15, 15, 12,  5,  7, 15, 15, 13, 15,  7, 11,\n",
      "        15,  3,  9, 15, 14,  1, 15,  7,  0, 15,  2, 15, 12, 15, 12, 15,  4,  8,\n",
      "        15,  5, 15, 15, 15, 10,  9, 15, 15, 11,  9, 15,  8, 10, 15, 15, 10, 15,\n",
      "         8, 15, 14, 15,  6,  0,  6, 15,  6, 15], device='cuda:0')\n",
      "427 / 832 = Acc: 51.32211538461539 %\n",
      "TensorBase([0.1243, 0.1118, 0.1166, 0.1119, 0.1119, 0.1220, 0.1113, 0.0981,\n",
      "            0.1181, 0.1205, 0.1156, 0.1089, 0.1141, 0.1010, 0.1111, 0.1165,\n",
      "            0.1121, 0.1079, 0.1407, 0.1157, 0.1136, 0.1142, 0.1058, 0.1264,\n",
      "            0.1022, 0.1092, 0.1272, 0.1224, 0.1239, 0.1074, 0.1035, 0.1066,\n",
      "            0.1071, 0.1178, 0.1059, 0.1031, 0.1057, 0.1064, 0.1068, 0.1043,\n",
      "            0.1019, 0.1094, 0.1113, 0.0917, 0.1003, 0.1093, 0.1144, 0.1101,\n",
      "            0.1156, 0.1223, 0.1094, 0.1106, 0.1110, 0.1289, 0.1090, 0.1153,\n",
      "            0.1191, 0.1050, 0.1056, 0.1058, 0.0972, 0.1215, 0.1265, 0.1013],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15,  9, 15,  7, 15, 15, 13, 15, 15, 15, 13,  7,  4, 15,  3, 15, 15, 15,\n",
      "         3,  4, 15,  7, 15,  8, 15,  7,  5, 15, 12,  3, 15,  3,  8, 15, 15,  2,\n",
      "        10, 15,  9, 15, 15,  7,  6, 15, 15,  3, 15,  5, 14, 15, 15, 15, 15, 15,\n",
      "        11,  4, 15,  0,  9,  6, 15, 15, 15, 15], device='cuda:0')\n",
      "461 / 896 = Acc: 51.450892857142854 %\n",
      "TensorBase([0.1124, 0.1070, 0.1037, 0.2067, 0.0936, 0.1049, 0.1099, 0.1135,\n",
      "            0.1107, 0.0968, 0.1242, 0.1112, 0.1049, 0.1127, 0.1128, 0.1070,\n",
      "            0.1016, 0.1104, 0.1025, 0.0994, 0.1053, 0.1186, 0.1098, 0.0957,\n",
      "            0.1071, 0.1092, 0.1100, 0.1124, 0.1059, 0.1125, 0.1102, 0.1452,\n",
      "            0.1110, 0.1076, 0.1145, 0.1120, 0.1155, 0.1087, 0.1088, 0.1089,\n",
      "            0.0979, 0.1129, 0.1177, 0.1019, 0.1084, 0.1228, 0.1070, 0.1090,\n",
      "            0.1130, 0.1065, 0.1214, 0.1019, 0.1139, 0.1069, 0.1160, 0.1120,\n",
      "            0.1058, 0.1061, 0.1015, 0.1051, 0.1101, 0.0975, 0.1116, 0.1064],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15,  9,  8, 15, 15,  2, 13, 13, 12, 10, 12,  2,  3, 15, 15, 15, 11, 14,\n",
      "         9, 15,  3, 15,  2,  6,  4, 15,  1,  1, 11,  5, 15,  7, 15,  2,  5,  1,\n",
      "        15,  6, 12, 15, 15,  5,  5,  0,  2, 15,  3,  4,  1, 15,  3, 11,  1,  0,\n",
      "         8, 15, 15, 15, 15,  1, 15, 15, 15,  2], device='cuda:0')\n",
      "484 / 960 = Acc: 50.416666666666664 %\n",
      "TensorBase([0.1096, 0.1137, 0.1110, 0.1045, 0.1228, 0.1215, 0.1148, 0.1130,\n",
      "            0.1108, 0.1135, 0.1081, 0.1184, 0.1068, 0.1079, 0.1135, 0.1261,\n",
      "            0.1146, 0.1089, 0.1115, 0.1140, 0.1079, 0.0992, 0.1167, 0.1197,\n",
      "            0.1095, 0.1070, 0.1026, 0.1135, 0.1157, 0.1443, 0.1075, 0.1287,\n",
      "            0.1038, 0.1128, 0.1096, 0.1158, 0.1150, 0.1047, 0.1175, 0.1010,\n",
      "            0.1112, 0.1150, 0.0949, 0.1056, 0.1195, 0.1185, 0.1017, 0.1162,\n",
      "            0.1057, 0.1315, 0.1326, 0.1024, 0.1133, 0.1033, 0.1057, 0.1079,\n",
      "            0.1102, 0.1145, 0.1013, 0.1068, 0.1170, 0.1119, 0.1112, 0.1115],\n",
      "           device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "           device='cuda:0') tensor([15,  2,  2, 15, 15, 15, 15,  8, 13, 15, 15, 15, 15,  1,  8,  5, 15, 14,\n",
      "         1, 15, 13,  7,  8, 15, 14, 14, 15,  4, 12,  4, 15, 15, 15, 15, 15, 15,\n",
      "        12,  9, 12, 15, 15, 13, 15, 15,  0, 15, 15,  1,  7, 15, 15, 15, 15,  6,\n",
      "        15, 15, 15, 15, 11, 15, 15, 15, 13,  3], device='cuda:0')\n",
      "520 / 1024 = Acc: 50.78125 %\n",
      "TensorBase([0.1114, 0.1115, 0.1104, 0.1039, 0.1018, 0.1088, 0.1151, 0.1270,\n",
      "            0.1238, 0.1245, 0.1072, 0.1111, 0.1108, 0.1028, 0.1106, 0.1241,\n",
      "            0.1282, 0.1095, 0.1055, 0.0947, 0.1193, 0.1216, 0.1057, 0.1044,\n",
      "            0.0974, 0.1137, 0.1196, 0.1135, 0.1178, 0.1108, 0.1160, 0.1023,\n",
      "            0.1061, 0.1193, 0.1005, 0.1220, 0.1060, 0.1211, 0.1326, 0.1142,\n",
      "            0.1117, 0.1123, 0.1113, 0.1215, 0.1198, 0.1203, 0.1167, 0.1192,\n",
      "            0.1172, 0.1150, 0.1134, 0.1010, 0.1156, 0.0997, 0.1111, 0.1094,\n",
      "            0.1095, 0.1179, 0.1150, 0.1211], device='cuda:0') TensorBase([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
      "            15, 15, 15, 15, 15, 15, 15, 15, 15], device='cuda:0') tensor([15,  4,  9, 15, 15,  3, 12, 15, 12,  8,  7, 15,  8,  4,  9, 15,  5,  0,\n",
      "        15, 15, 15, 12,  9, 15, 15,  2, 15,  3,  8, 15, 12, 15, 15, 13,  6, 15,\n",
      "         3, 15, 15,  5,  4, 10, 15, 12,  4,  5,  9, 15, 15, 12, 15, 15, 10, 10,\n",
      "        15, 14, 11,  0,  1, 15], device='cuda:0')\n",
      "545 / 1084 = Acc: 50.276752767527675 %\n"
     ]
    }
   ],
   "source": [
    "# For Confusion Matrix\n",
    "predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "  n_correct = 0\n",
    "  n_samples = 0\n",
    "  softmax = nn.Softmax()\n",
    "  for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "    signals = torch.tensor(signals)\n",
    "    signals = signals.float()\n",
    "    signals = signals.to(device)\n",
    "    one_hot_labels = one_hot_labels.to(device)\n",
    "    # print(len(one_hot_labels))\n",
    "    outputs = model(signals)\n",
    "    for j, out in enumerate(outputs):\n",
    "      outputs[j] = softmax(out)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "    \n",
    "    \n",
    "    for idx in range(len(_)):\n",
    "      if _[idx] < threshold:\n",
    "        predicted[idx] = Unknown_label # 15, 20, 25\n",
    "    print(_, predicted, one_hot_labels)\n",
    "\n",
    "    n_samples += one_hot_labels.size(0) # add batch_size\n",
    "    n_correct += (predicted == one_hot_labels).sum().item()\n",
    "    \n",
    "    predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "    one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "    predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "    one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'{n_correct} / {n_samples} = Acc: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_lists[700:], one_hot_labels_list[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_for_cent = []\n",
    "for idx, x in enumerate(outputs):\n",
    "    x = x[labels[idx]]\n",
    "    output_for_cent.append([x])\n",
    "output_for_cent = torch.tensor(output_for_cent)\n",
    "output_for_cent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(one_hot_labels_list, predicted_lists)\n",
    "sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues')\n",
    "plt.xlabel(\"Predicted Label\", fontsize=13)\n",
    "plt.ylabel(\"Ground Truth\", fontsize=13)\n",
    "fig_name = \"sklearn_confusion_matrix_{}_{}.png\".format(Unknown_label, threshold)\n",
    "plt.savefig(\"./figure/\" + fig_name)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.30, 0.80, 11)\n",
    "y1 = [86.33, 88.00, 89.94, 91.32, 92.70, 93.26, 93.81, 94.45, 94.92, 94.55, 93.63]\n",
    "y2 = [71.01, 73.68, 76.55, 78.85, 82.83, 84.03, 85.78, 87.07, 87.72, 88.64, 88.27]\n",
    "y3 = [55.44, 59.79, 64.76, 70.85, 75.37, 78.41, 80.72, 82.84, 86.25, 87.73, 89.30]\n",
    "y0 = [99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08]\n",
    "plt.ylim(55, 100)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "plt.plot(x, y0, label=\"Openness=0, (threshold=0)\")\n",
    "plt.plot(x, y1, marker=\"o\", label=\"Openness=0.087\")\n",
    "plt.plot(x, y2, marker=\"*\", label=\"Openness=0.184\")\n",
    "plt.plot(x, y3, marker=\"x\", label=\"Openness=0.293\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.30, 0.80, 11)\n",
    "y1 = []\n",
    "y2 = [71.01, 73.68, 76.55, 78.85, 82.83, 84.03, 85.78, 87.07, 87.72, 88.64, 88.27]\n",
    "y3 = [55.44, 59.79, 64.76, 70.85, 75.37, 78.41, 80.72, 82.84, 86.25, 87.73, 89.30]\n",
    "y0 = [99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08]\n",
    "plt.ylim(55, 100)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "plt.plot(x, y0, label=\"Openness=0, (threshold=0)\")\n",
    "plt.plot(x, y1, marker=\"o\", label=\"Openness=0.087\")\n",
    "plt.plot(x, y2, marker=\"*\", label=\"Openness=0.184\")\n",
    "plt.plot(x, y3, marker=\"x\", label=\"Openness=0.293\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f91700efb80>"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.array([55.35055350553505, 61.99261992619926, 64.11439114391143, 70.75645756457564, 74.6309963099631, 73.5239852398524, 77.58302583025831, 84.5940959409594, 81.91881918819188, 90.59040590405904, 88.46863468634686])\n",
    "b = np.array([55.71955719557196, 57.564575645756456, 61.62361623616236, 70.9409594095941, 71.58671586715867, 76.56826568265683, 75.27675276752767, 76.19926199261992, 81.2730627306273, 84.96309963099631, 88.00738007380073])\n",
    "c = np.array([51.93726937269373, 54.7970479704797, 58.025830258302584, 62.08487084870849, 66.32841328413284, 71.03321033210332, 74.72324723247233, 78.50553505535055, 81.91881918819188, 84.77859778597787, 87.82287822878229])\n",
    "d = np.array([52.859778597785976, 56.91881918819188, 61.254612546125465, 66.14391143911439, 70.84870848708488, 75.46125461254613, 78.87453874538745, 82.10332103321034, 85.05535055350553, 87.63837638376384, 90.59040590405904])\n",
    "e = np.array([52.5830258302583, 56.18081180811808, 60.42435424354244, 64.11439114391143, 67.98892988929889, 72.32472324723247, 75.09225092250922, 78.78228782287823, 82.380073800738, 85.23985239852398, 88.09963099630997])\n",
    "ave14 = np.mean([a, b, c, d, e], axis=0)\n",
    "\n",
    "a1 = np.array([68.88273314866113, 73.40720221606648, 77.65466297322253, 78.67036011080333, 78.76269621421976, 84.57987072945522, 83.28716528162512, 87.44228993536473, 85.96491228070175, 88.9196675900277, 88.73499538319483])\n",
    "b1 = np.array([69.3444136657433, 71.46814404432133, 76.08494921514313, 78.02400738688827, 78.30101569713759, 76.5466297322253, 83.10249307479225, 83.28716528162512, 87.07294552169898, 87.6269621421976, 90.2123730378578])\n",
    "c1 = np.array([69.43674976915975, 71.83748845798708, 74.33056325023084, 76.36195752539243, 78.20867959372114, 81.4404432132964, 83.10249307479225, 85.68790397045245, 86.79593721144968, 89.10433979686057, 91.68975069252078])\n",
    "d1 = np.array([68.69806094182826, 70.3601108033241, 72.11449676823638, 74.42289935364728, 75.53093259464451, 76.73130193905817, 78.02400738688827, 78.76269621421976, 80.33240997229917, 81.80978762696215, 84.11819021237304])\n",
    "e1 = np.array([69.71375807940905, 72.29916897506925, 74.9769159741459, 77.93167128347184, 79.87072945521699, 81.4404432132964, 82.82548476454294, 84.57987072945522, 86.0572483841182, 87.44228993536473, 88.73499538319483])\n",
    "\n",
    "ave19 = np.mean([a1, b1, c1, d1, e1], axis=0)\n",
    "\n",
    "a2 = np.array([88.36565096952909, 91.87442289935365, 91.59741458910435, 93.62880886426593, 92.89012003693445, 93.90581717451524, 96.67590027700831, 95.10618651892891, 98.33795013850416, 95.38319482917821, 97.78393351800554])\n",
    "b2 = np.array([87.90397045244691, 88.82733148661127, 91.59741458910435, 88.6426592797784, 91.2280701754386, 94.73684210526316, 94.73684210526316, 93.72114496768236, 95.93721144967682, 95.66020313942752, 97.04524469067405])\n",
    "c2 = np.array([85.87257617728532, 87.53462603878117, 89.47368421052632, 91.59741458910435, 92.05909510618652, 93.25946445060019, 93.8134810710988, 95.01385041551247, 95.8448753462604, 96.67590027700831, 97.96860572483841])\n",
    "d2 = np.array([86.88827331486611, 88.18097876269621, 89.38134810710989, 90.39704524469067, 91.5050784856879, 92.89012003693445, 94.45983379501385, 95.29085872576178, 96.02954755309327, 96.86057248384118, 97.4145891043398])\n",
    "e2 = np.array([86.0572483841182, 87.16528162511543, 88.6426592797784, 91.13573407202216, 92.98245614035088, 94.73684210526316, 96.21421975992614, 97.4145891043398, 97.87626962142198, 98.15327793167128, 98.52262234533703])\n",
    "\n",
    "ave24 = np.mean([a2, b2, c2, d2, e2], axis=0)\n",
    "\n",
    "x = np.linspace(0.30, 0.80, 11)\n",
    "y1 = ave14\n",
    "y2 = ave19\n",
    "y3 = ave24\n",
    "y0 = [99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08, 99.08]\n",
    "plt.ylim(55, 100)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "# plt.plot(x, y0, label=\"Openness=0, (threshold=0)\")\n",
    "plt.plot(x, y3, marker=\"o\", label=\"Openness=0.087\")\n",
    "plt.plot(x, y2, marker=\"*\", label=\"Openness=0.184\")\n",
    "plt.plot(x, y1, marker=\"x\", label=\"Openness=0.293\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後のfc層の重みとバイアスを使用する\n",
    "損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc.weight, model.fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def softmax_loss(outputs, labels):\n",
    "    loss = 0\n",
    "    batch_size = len(labels)\n",
    "    softmax_out = softmax(outputs)\n",
    "    for idx in range(batch_size):\n",
    "        loss += 1.0 - log(softmax_out[labels[idx]])\n",
    "    return loss / batch_size\n",
    "\n",
    "\n",
    "from center_loss import CenterLoss\n",
    "center_loss = CenterLoss(num_classes=close_num + 1, feat_dim=1, use_gpu=True)\n",
    "optimizer_centloss = torch.optim.SGD(center_loss.parameters(), lr=0.5)\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type='cosface', eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 30.0 if not s else s\n",
    "            self.m = 0.4 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L)\n",
    "\n",
    "cos_loss = AngularPenaltySMLoss(1, close_num + 1, loss_type=\"cosface\")\n",
    "\n",
    "\n",
    "def triple_joint_loss(output, label):\n",
    "    return softmax_loss(output, label) + center_loss(output, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "class LMCL_loss(nn.Module):\n",
    "    \"\"\"\n",
    "        Refer to paper:\n",
    "        Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou,Zhifeng Li, and Wei Liu\n",
    "        CosFace: Large Margin Cosine Loss for Deep Face Recognition. CVPR2018\n",
    "        re-implement by yirong mao\n",
    "        2018 07/02\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, feat_dim, s=7.00, m=0.2):\n",
    "        super(LMCL_loss, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.centers = nn.Parameter(torch.randn(num_classes, feat_dim))\n",
    "\n",
    "    def forward(self, feat, label):\n",
    "        batch_size = feat.shape[0]\n",
    "        norms = torch.norm(feat, p=2, dim=-1, keepdim=True)\n",
    "        nfeat = torch.div(feat, norms)\n",
    "\n",
    "        norms_c = torch.norm(self.centers, p=2, dim=-1, keepdim=True)\n",
    "        ncenters = torch.div(self.centers, norms_c)\n",
    "        logits = torch.matmul(nfeat, torch.transpose(ncenters, 0, 1))\n",
    "\n",
    "        y_onehot = torch.FloatTensor(batch_size, self.num_classes)\n",
    "        y_onehot.zero_()\n",
    "        y_onehot = Variable(y_onehot).cuda()\n",
    "        y_onehot.scatter_(1, torch.unsqueeze(label, dim=-1), self.m)\n",
    "        margin_logits = self.s * (logits - y_onehot)\n",
    "\n",
    "        return logits, margin_logits"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation for Open set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "# X = dataset\n",
    "# y = labels\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0) # shuffle=Falseだとrandom_stateは何か数字を設定しても意味ないらしい\n",
    "\n",
    "mean_acc = 0\n",
    "# split_idx = 4473\n",
    "split_idx = 3570\n",
    "\n",
    "dataset = MyDataset(data_series, labels_tensor, \"./data/\", transform=transforms.ToTensor())\n",
    "\n",
    "for Fold, (train_index, test_index) in enumerate(skf.split(data_series, labels_tensor)):\n",
    "    print(f\"Fold{Fold+1} Start!\")\n",
    "    # Prepare Open train Dataset\n",
    "    open_train_index = [i for i in train_index if i <= split_idx]\n",
    "    open_train_set = torch.utils.data.Subset(dataset, open_train_index)\n",
    "    open_test_set = torch.utils.data.Subset(dataset, test_index)\n",
    "    # Prepare Close train Dataset\n",
    "    # train_set = torch.utils.data.Subset(dataset, train_index)\n",
    "    # test_set = torch.utils.data.Subset(dataset, test_index) # openの場合も同じ\n",
    "\n",
    "    Unknown_label = close_num + 1\n",
    "\n",
    "    train_loader = DataLoader(dataset=open_train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=open_test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "    model = model.to(device)\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    from fastprogress.fastprogress import master_bar, progress_bar\n",
    "    mb = master_bar(range(num_epochs))\n",
    "\n",
    "    model.train()\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in mb:\n",
    "        for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "            signals = torch.tensor(signals)\n",
    "            signals = signals.float()\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # print(signals.size())\n",
    "            outputs = model(signals)\n",
    "            outputs = outputs.to(device)\n",
    "            # print(outputs)\n",
    "            loss = triple_joint_loss(outputs, labels, alpha) # will check the shapes of outputs and labels\n",
    "            # test_loss = triple_joint_loss(signals, one_hot_labels, alpha) # from test_loader?\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_centloss.zero_grad()\n",
    "            loss.backward()\n",
    "            for param in center_loss.parameters():\n",
    "                param.grad.data *= (1./alpha) # 98.98%を出したときはこれを書いていなかった→追加しても問題なし．\n",
    "            optimizer.step()\n",
    "            optimizer_centloss.step()\n",
    "        mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "\n",
    "    # For Confusion Matrix\n",
    "    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    model.eval()\n",
    "    for threshold in thresholds:\n",
    "      predicted_lists = np.zeros(0, dtype=np.int64)\n",
    "      one_hot_labels_list = np.zeros(0, dtype=np.int64)\n",
    "      with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        softmax = nn.Softmax()\n",
    "        for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "          signals = torch.tensor(signals)\n",
    "          signals = signals.float()\n",
    "          signals = signals.to(device)\n",
    "          one_hot_labels = one_hot_labels.to(device)\n",
    "          # print(len(one_hot_labels))\n",
    "          outputs = model(signals)\n",
    "          # if i == 1:\n",
    "          \n",
    "            # print(outputs)\n",
    "          for j, out in enumerate(outputs):\n",
    "            outputs[j] = softmax(out)\n",
    "\n",
    "          _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "          \n",
    "          for idx in range(len(_)):\n",
    "            if _[idx] < threshold:\n",
    "              predicted[idx] = Unknown_label # 15, 20, 25\n",
    "          # print(_, predicted, one_hot_labels)\n",
    "\n",
    "          n_samples += one_hot_labels.size(0) # add batch_size\n",
    "          n_correct += (predicted == one_hot_labels).sum().item()\n",
    "          \n",
    "          predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "          one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "          predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "          one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "          \n",
    "          acc = 100.0 * n_correct / n_samples\n",
    "          # print(f'{n_correct} / {n_samples} = Acc: {acc} %')\n",
    "        with open(\"second_cross_val_result_open.txt\", \"a\") as f:\n",
    "          f.write(f\"Fold{Fold+1}, Threshold{threshold}\\n\")\n",
    "          f.write(classification_report(one_hot_labels_list, predicted_lists, digits=4) + \"\\n\")\n",
    "\n",
    "\n",
    "        cm = confusion_matrix(one_hot_labels_list, predicted_lists)\n",
    "        sns.heatmap(cm, square=True, cbar=True, annot=True, cmap='Blues')\n",
    "        plt.xlabel(\"Predicted Label\", fontsize=13)\n",
    "        plt.ylabel(\"Ground Truth\", fontsize=13)\n",
    "        fig_name = \"second_cross_val_Fold{}_threshold{}.png\".format(Fold, threshold)\n",
    "        plt.savefig(\"./figure/cross_val_open20-10/\" + fig_name)\n",
    "        plt.close()\n",
    "      \n",
    "      if threshold == 0.6:\n",
    "        mean_acc += acc\n",
    "print(mean_acc / 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import log\n",
    "softmax = nn.Softmax()\n",
    "\n",
    "def softmax_loss(outputs, labels):\n",
    "    loss = 0\n",
    "    batch_size = len(labels)\n",
    "    logsoftmax_out = log(softmax(outputs))\n",
    "    for idx in range(batch_size):\n",
    "        loss += 1.0 - logsoftmax_out[idx][labels[idx]]\n",
    "    \n",
    "    return loss / batch_size\n",
    "\n",
    "\n",
    "from center_loss import CenterLoss\n",
    "center_loss = CenterLoss(num_classes=close_num + 1, feat_dim=close_num + 1, use_gpu=True) # 入出力が同じだと一見変な感じがするが，交差エントロピーと違ってcenterlossを使うと最初から決めていれば，モデルの出力サイズを必ずしもクラス数に一致させる必要がないからfeat_dimを任意に設定できる．\n",
    "optimizer_centloss = torch.optim.SGD(center_loss.parameters(), lr=0.05)\n",
    "\n",
    "center_loss_test = CenterLoss(num_classes=close_num + 2, feat_dim=close_num + 2, use_gpu=True)\n",
    "optimizer_centloss_test = torch.optim.SGD(center_loss_test.parameters(), lr=0.05)\n",
    "\n",
    "\n",
    "class AngularPenaltySMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, loss_type='cosface', eps=1e-7, s=None, m=None):\n",
    "        '''\n",
    "        Angular Penalty Softmax Loss\n",
    "        Three 'loss_types' available: ['arcface', 'sphereface', 'cosface']\n",
    "        These losses are described in the following papers: \n",
    "        \n",
    "        ArcFace: https://arxiv.org/abs/1801.07698\n",
    "        SphereFace: https://arxiv.org/abs/1704.08063\n",
    "        CosFace/Ad Margin: https://arxiv.org/abs/1801.05599\n",
    "        '''\n",
    "        super(AngularPenaltySMLoss, self).__init__()\n",
    "        loss_type = loss_type.lower()\n",
    "        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n",
    "        if loss_type == 'arcface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 0.5 if not m else m\n",
    "        if loss_type == 'sphereface':\n",
    "            self.s = 64.0 if not s else s\n",
    "            self.m = 1.35 if not m else m\n",
    "        if loss_type == 'cosface':\n",
    "            self.s = 32.0 if not s else s\n",
    "            self.m = 0.2 if not m else m\n",
    "        self.loss_type = loss_type\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.fc.to(device)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, p=2, dim=1)\n",
    "\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        # logを引き算に変えて計算\n",
    "        wf = self.fc(x)\n",
    "        if self.loss_type == 'cosface':\n",
    "            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        if self.loss_type == 'arcface':\n",
    "            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n",
    "        if self.loss_type == 'sphereface':\n",
    "            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n",
    "\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L)\n",
    "\n",
    "cos_loss = AngularPenaltySMLoss(close_num + 1, close_num + 1, loss_type=\"cosface\") # center_lossと同じ理由でin_featuresはクラス数でよい．\n",
    "\n",
    "\n",
    "def triple_joint_loss(output, label, alpha, isTest=False):\n",
    "    # alpha: hyper parameter\n",
    "    if isTest: # validation lossはクラス数を変える必要があるため分岐\n",
    "        return softmax_loss(output, label) + alpha * center_loss_test(output, label)\n",
    "    return softmax_loss(output, label) + alpha * center_loss(output, label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve (Open set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_643/3685862955.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n",
      "/mnt/c/Users/grpro/workspace/grad_thesis/InceptionTime/env/lib/python3.9/site-packages/torch/overrides.py:1498: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = torch_func_method(public_api, types, args, kwargs)\n",
      "/tmp/ipykernel_643/3685862955.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  signals = torch.tensor(signals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 / 64 = Acc: 51.5625 %, loss: 4.903443336486816\n",
      "64 / 128 = Acc: 50.0 %, loss: 5.15139102935791\n",
      "95 / 192 = Acc: 49.479166666666664 %, loss: 4.988882541656494\n",
      "127 / 256 = Acc: 49.609375 %, loss: 4.845625400543213\n",
      "152 / 320 = Acc: 47.5 %, loss: 5.050849914550781\n",
      "188 / 384 = Acc: 48.958333333333336 %, loss: 4.968164920806885\n",
      "221 / 448 = Acc: 49.330357142857146 %, loss: 4.979575157165527\n",
      "246 / 512 = Acc: 48.046875 %, loss: 5.088995456695557\n",
      "281 / 576 = Acc: 48.78472222222222 %, loss: 4.859890937805176\n",
      "310 / 640 = Acc: 48.4375 %, loss: 5.04631233215332\n",
      "344 / 704 = Acc: 48.86363636363637 %, loss: 5.046250343322754\n",
      "384 / 768 = Acc: 50.0 %, loss: 4.740178108215332\n",
      "421 / 832 = Acc: 50.60096153846154 %, loss: 4.861331462860107\n",
      "454 / 896 = Acc: 50.669642857142854 %, loss: 4.847240924835205\n",
      "485 / 960 = Acc: 50.520833333333336 %, loss: 4.977033615112305\n",
      "520 / 1024 = Acc: 50.78125 %, loss: 4.88539457321167\n",
      "545 / 1084 = Acc: 50.276752767527675 %, loss: 5.029929161071777\n",
      "30 / 64 = Acc: 46.875 %, loss: 4.961167335510254\n",
      "69 / 128 = Acc: 53.90625 %, loss: 4.739646911621094\n",
      "98 / 192 = Acc: 51.041666666666664 %, loss: 4.978890419006348\n",
      "131 / 256 = Acc: 51.171875 %, loss: 4.957993984222412\n",
      "168 / 320 = Acc: 52.5 %, loss: 4.899905204772949\n",
      "201 / 384 = Acc: 52.34375 %, loss: 4.983124732971191\n",
      "232 / 448 = Acc: 51.785714285714285 %, loss: 4.942553520202637\n",
      "262 / 512 = Acc: 51.171875 %, loss: 4.913105010986328\n",
      "297 / 576 = Acc: 51.5625 %, loss: 4.883274078369141\n",
      "328 / 640 = Acc: 51.25 %, loss: 5.048410415649414\n",
      "361 / 704 = Acc: 51.27840909090909 %, loss: 4.895022869110107\n",
      "389 / 768 = Acc: 50.651041666666664 %, loss: 5.043792724609375\n",
      "421 / 832 = Acc: 50.60096153846154 %, loss: 5.083316326141357\n",
      "447 / 896 = Acc: 49.888392857142854 %, loss: 5.158156871795654\n",
      "483 / 960 = Acc: 50.3125 %, loss: 4.888360977172852\n",
      "521 / 1024 = Acc: 50.87890625 %, loss: 4.746031761169434\n",
      "545 / 1084 = Acc: 50.276752767527675 %, loss: 5.155590534210205\n",
      "33 / 64 = Acc: 51.5625 %, loss: 4.962822914123535\n",
      "71 / 128 = Acc: 55.46875 %, loss: 4.874842643737793\n",
      "101 / 192 = Acc: 52.604166666666664 %, loss: 4.930608749389648\n",
      "136 / 256 = Acc: 53.125 %, loss: 4.801365375518799\n",
      "167 / 320 = Acc: 52.1875 %, loss: 4.926596641540527\n",
      "195 / 384 = Acc: 50.78125 %, loss: 4.9516143798828125\n",
      "224 / 448 = Acc: 50.0 %, loss: 5.011083126068115\n",
      "259 / 512 = Acc: 50.5859375 %, loss: 4.954121112823486\n",
      "291 / 576 = Acc: 50.520833333333336 %, loss: 4.97420072555542\n",
      "320 / 640 = Acc: 50.0 %, loss: 5.030339241027832\n",
      "349 / 704 = Acc: 49.57386363636363 %, loss: 5.0205278396606445\n",
      "378 / 768 = Acc: 49.21875 %, loss: 5.0552239418029785\n",
      "414 / 832 = Acc: 49.75961538461539 %, loss: 4.8937554359436035\n",
      "450 / 896 = Acc: 50.223214285714285 %, loss: 5.005057334899902\n",
      "487 / 960 = Acc: 50.729166666666664 %, loss: 4.848525047302246\n",
      "521 / 1024 = Acc: 50.87890625 %, loss: 4.915417194366455\n",
      "545 / 1084 = Acc: 50.276752767527675 %, loss: 5.120018005371094\n",
      "32 / 64 = Acc: 50.0 %, loss: 5.0278000831604\n",
      "59 / 128 = Acc: 46.09375 %, loss: 5.102237224578857\n",
      "92 / 192 = Acc: 47.916666666666664 %, loss: 4.979815483093262\n",
      "125 / 256 = Acc: 48.828125 %, loss: 4.954150199890137\n",
      "157 / 320 = Acc: 49.0625 %, loss: 4.912056922912598\n",
      "189 / 384 = Acc: 49.21875 %, loss: 4.92234992980957\n",
      "219 / 448 = Acc: 48.88392857142857 %, loss: 4.815842628479004\n",
      "257 / 512 = Acc: 50.1953125 %, loss: 4.873107433319092\n",
      "290 / 576 = Acc: 50.34722222222222 %, loss: 4.8962016105651855\n",
      "319 / 640 = Acc: 49.84375 %, loss: 5.020240306854248\n",
      "354 / 704 = Acc: 50.28409090909091 %, loss: 4.845566272735596\n",
      "387 / 768 = Acc: 50.390625 %, loss: 4.992193222045898\n",
      "418 / 832 = Acc: 50.24038461538461 %, loss: 5.000319004058838\n",
      "456 / 896 = Acc: 50.892857142857146 %, loss: 4.869678497314453\n",
      "485 / 960 = Acc: 50.520833333333336 %, loss: 5.103641986846924\n",
      "513 / 1024 = Acc: 50.09765625 %, loss: 5.0053229331970215\n",
      "545 / 1084 = Acc: 50.276752767527675 %, loss: 4.944635391235352\n",
      "31 / 64 = Acc: 48.4375 %, loss: 5.060621738433838\n",
      "56 / 128 = Acc: 43.75 %, loss: 5.110265731811523\n",
      "76 / 192 = Acc: 39.583333333333336 %, loss: 5.171876430511475\n",
      "106 / 256 = Acc: 41.40625 %, loss: 5.176314353942871\n",
      "142 / 320 = Acc: 44.375 %, loss: 4.726465225219727\n",
      "170 / 384 = Acc: 44.270833333333336 %, loss: 5.052816390991211\n",
      "199 / 448 = Acc: 44.419642857142854 %, loss: 5.025168418884277\n",
      "230 / 512 = Acc: 44.921875 %, loss: 4.9588470458984375\n",
      "262 / 576 = Acc: 45.486111111111114 %, loss: 4.96740198135376\n",
      "288 / 640 = Acc: 45.0 %, loss: 5.125110149383545\n",
      "328 / 704 = Acc: 46.59090909090909 %, loss: 4.769237518310547\n",
      "361 / 768 = Acc: 47.005208333333336 %, loss: 4.887084007263184\n",
      "397 / 832 = Acc: 47.71634615384615 %, loss: 4.8550848960876465\n",
      "436 / 896 = Acc: 48.660714285714285 %, loss: 4.877243995666504\n",
      "472 / 960 = Acc: 49.166666666666664 %, loss: 4.887697696685791\n",
      "507 / 1024 = Acc: 49.51171875 %, loss: 4.828383445739746\n",
      "546 / 1084 = Acc: 50.3690036900369 %, loss: 4.761532306671143\n",
      "30 / 64 = Acc: 46.875 %, loss: 5.016308784484863\n",
      "59 / 128 = Acc: 46.09375 %, loss: 5.023344039916992\n",
      "96 / 192 = Acc: 50.0 %, loss: 5.028655529022217\n",
      "127 / 256 = Acc: 49.609375 %, loss: 4.936511516571045\n",
      "153 / 320 = Acc: 47.8125 %, loss: 5.086749076843262\n",
      "189 / 384 = Acc: 49.21875 %, loss: 4.879845142364502\n",
      "218 / 448 = Acc: 48.660714285714285 %, loss: 4.953566551208496\n",
      "250 / 512 = Acc: 48.828125 %, loss: 4.958940029144287\n",
      "280 / 576 = Acc: 48.611111111111114 %, loss: 4.930332183837891\n",
      "312 / 640 = Acc: 48.75 %, loss: 5.033369541168213\n",
      "342 / 704 = Acc: 48.57954545454545 %, loss: 5.084546089172363\n",
      "374 / 768 = Acc: 48.697916666666664 %, loss: 4.960636138916016\n",
      "414 / 832 = Acc: 49.75961538461539 %, loss: 4.836631774902344\n",
      "454 / 896 = Acc: 50.669642857142854 %, loss: 4.706056594848633\n",
      "480 / 960 = Acc: 50.0 %, loss: 5.075630187988281\n",
      "515 / 1024 = Acc: 50.29296875 %, loss: 4.831424713134766\n",
      "545 / 1084 = Acc: 50.276752767527675 %, loss: 4.921142101287842\n",
      "31 / 64 = Acc: 48.4375 %, loss: 4.962862968444824\n",
      "58 / 128 = Acc: 45.3125 %, loss: 5.1112518310546875\n",
      "95 / 192 = Acc: 49.479166666666664 %, loss: 4.892706394195557\n",
      "126 / 256 = Acc: 49.21875 %, loss: 5.011579990386963\n",
      "158 / 320 = Acc: 49.375 %, loss: 4.967311382293701\n",
      "196 / 384 = Acc: 51.041666666666664 %, loss: 4.869608402252197\n",
      "232 / 448 = Acc: 51.785714285714285 %, loss: 4.880331516265869\n",
      "258 / 512 = Acc: 50.390625 %, loss: 5.070404052734375\n",
      "288 / 576 = Acc: 50.0 %, loss: 4.816011428833008\n",
      "318 / 640 = Acc: 49.6875 %, loss: 4.962124347686768\n",
      "356 / 704 = Acc: 50.56818181818182 %, loss: 4.90858793258667\n",
      "390 / 768 = Acc: 50.78125 %, loss: 4.917110443115234\n",
      "425 / 832 = Acc: 51.08173076923077 %, loss: 4.895876884460449\n",
      "455 / 896 = Acc: 50.78125 %, loss: 5.016522407531738\n",
      "484 / 960 = Acc: 50.416666666666664 %, loss: 5.015189170837402\n",
      "519 / 1024 = Acc: 50.68359375 %, loss: 4.8880295753479\n",
      "545 / 1084 = Acc: 50.276752767527675 %, loss: 5.088653564453125\n",
      "28 / 64 = Acc: 43.75 %, loss: 4.907420635223389\n",
      "66 / 128 = Acc: 51.5625 %, loss: 4.906164646148682\n",
      "98 / 192 = Acc: 51.041666666666664 %, loss: 4.911631107330322\n",
      "135 / 256 = Acc: 52.734375 %, loss: 4.82415771484375\n",
      "168 / 320 = Acc: 52.5 %, loss: 5.000838279724121\n",
      "194 / 384 = Acc: 50.520833333333336 %, loss: 5.0327582359313965\n",
      "228 / 448 = Acc: 50.892857142857146 %, loss: 4.933319091796875\n",
      "265 / 512 = Acc: 51.7578125 %, loss: 4.879426002502441\n",
      "297 / 576 = Acc: 51.5625 %, loss: 4.90321683883667\n",
      "321 / 640 = Acc: 50.15625 %, loss: 5.177340507507324\n",
      "352 / 704 = Acc: 50.0 %, loss: 4.921500205993652\n",
      "387 / 768 = Acc: 50.390625 %, loss: 4.900568962097168\n",
      "414 / 832 = Acc: 49.75961538461539 %, loss: 5.1566057205200195\n",
      "452 / 896 = Acc: 50.44642857142857 %, loss: 4.77222204208374\n",
      "486 / 960 = Acc: 50.625 %, loss: 5.029537200927734\n",
      "518 / 1024 = Acc: 50.5859375 %, loss: 4.9056620597839355\n",
      "545 / 1084 = Acc: 50.276752767527675 %, loss: 5.113333702087402\n",
      "23 / 64 = Acc: 35.9375 %, loss: 5.132813930511475\n",
      "57 / 128 = Acc: 44.53125 %, loss: 4.8619842529296875\n",
      "90 / 192 = Acc: 46.875 %, loss: 4.969472408294678\n",
      "116 / 256 = Acc: 45.3125 %, loss: 5.085824966430664\n",
      "141 / 320 = Acc: 44.0625 %, loss: 5.004272937774658\n",
      "171 / 384 = Acc: 44.53125 %, loss: 5.027131080627441\n",
      "201 / 448 = Acc: 44.86607142857143 %, loss: 5.168539524078369\n",
      "237 / 512 = Acc: 46.2890625 %, loss: 4.956478118896484\n",
      "269 / 576 = Acc: 46.701388888888886 %, loss: 4.865323066711426\n",
      "302 / 640 = Acc: 47.1875 %, loss: 5.0690107345581055\n",
      "337 / 704 = Acc: 47.86931818181818 %, loss: 4.90095329284668\n",
      "372 / 768 = Acc: 48.4375 %, loss: 4.8328447341918945\n",
      "403 / 832 = Acc: 48.4375 %, loss: 5.037655830383301\n",
      "441 / 896 = Acc: 49.21875 %, loss: 4.758857727050781\n",
      "472 / 960 = Acc: 49.166666666666664 %, loss: 4.946944236755371\n",
      "508 / 1024 = Acc: 49.609375 %, loss: 4.85774040222168\n",
      "546 / 1084 = Acc: 50.3690036900369 %, loss: 4.765641689300537\n",
      "31 / 64 = Acc: 48.4375 %, loss: 4.936903476715088\n",
      "67 / 128 = Acc: 52.34375 %, loss: 4.779908180236816\n",
      "99 / 192 = Acc: 51.5625 %, loss: 4.905274391174316\n",
      "139 / 256 = Acc: 54.296875 %, loss: 4.779971599578857\n",
      "172 / 320 = Acc: 53.75 %, loss: 5.018930435180664\n",
      "200 / 384 = Acc: 52.083333333333336 %, loss: 4.940163612365723\n",
      "233 / 448 = Acc: 52.00892857142857 %, loss: 5.003067970275879\n",
      "262 / 512 = Acc: 51.171875 %, loss: 4.975151538848877\n",
      "292 / 576 = Acc: 50.69444444444444 %, loss: 4.996861457824707\n",
      "325 / 640 = Acc: 50.78125 %, loss: 4.940943717956543\n",
      "363 / 704 = Acc: 51.5625 %, loss: 4.8346099853515625\n",
      "393 / 768 = Acc: 51.171875 %, loss: 5.008868217468262\n",
      "424 / 832 = Acc: 50.96153846153846 %, loss: 4.990903377532959\n",
      "453 / 896 = Acc: 50.558035714285715 %, loss: 5.0913777351379395\n",
      "484 / 960 = Acc: 50.416666666666664 %, loss: 5.0609002113342285\n",
      "510 / 1024 = Acc: 49.8046875 %, loss: 5.144343852996826\n",
      "546 / 1084 = Acc: 50.3690036900369 %, loss: 4.837355136871338\n",
      "27 / 64 = Acc: 42.1875 %, loss: 5.01180362701416\n",
      "56 / 128 = Acc: 43.75 %, loss: 5.02773904800415\n",
      "91 / 192 = Acc: 47.395833333333336 %, loss: 4.990414142608643\n",
      "121 / 256 = Acc: 47.265625 %, loss: 4.960482597351074\n",
      "153 / 320 = Acc: 47.8125 %, loss: 4.945600986480713\n",
      "184 / 384 = Acc: 47.916666666666664 %, loss: 5.011796474456787\n",
      "219 / 448 = Acc: 48.88392857142857 %, loss: 4.869826316833496\n",
      "251 / 512 = Acc: 49.0234375 %, loss: 5.015883445739746\n",
      "289 / 576 = Acc: 50.173611111111114 %, loss: 4.837797164916992\n",
      "324 / 640 = Acc: 50.625 %, loss: 4.969878673553467\n",
      "360 / 704 = Acc: 51.13636363636363 %, loss: 4.871559143066406\n",
      "388 / 768 = Acc: 50.520833333333336 %, loss: 4.949027061462402\n",
      "419 / 832 = Acc: 50.36057692307692 %, loss: 5.0410661697387695\n",
      "449 / 896 = Acc: 50.111607142857146 %, loss: 4.974165916442871\n",
      "481 / 960 = Acc: 50.104166666666664 %, loss: 4.957123279571533\n",
      "517 / 1024 = Acc: 50.48828125 %, loss: 4.8625054359436035\n",
      "548 / 1084 = Acc: 50.55350553505535 %, loss: 4.927937984466553\n",
      "35 / 64 = Acc: 54.6875 %, loss: 4.938447952270508\n",
      "72 / 128 = Acc: 56.25 %, loss: 4.781484127044678\n",
      "108 / 192 = Acc: 56.25 %, loss: 4.872925758361816\n",
      "135 / 256 = Acc: 52.734375 %, loss: 5.005291938781738\n",
      "169 / 320 = Acc: 52.8125 %, loss: 4.936587333679199\n",
      "202 / 384 = Acc: 52.604166666666664 %, loss: 4.9349188804626465\n",
      "229 / 448 = Acc: 51.11607142857143 %, loss: 5.104007720947266\n",
      "261 / 512 = Acc: 50.9765625 %, loss: 4.941274166107178\n",
      "289 / 576 = Acc: 50.173611111111114 %, loss: 5.051791191101074\n",
      "320 / 640 = Acc: 50.0 %, loss: 4.894787311553955\n",
      "352 / 704 = Acc: 50.0 %, loss: 5.045694351196289\n",
      "383 / 768 = Acc: 49.869791666666664 %, loss: 4.939069747924805\n",
      "413 / 832 = Acc: 49.63942307692308 %, loss: 4.976337432861328\n",
      "455 / 896 = Acc: 50.78125 %, loss: 4.809238910675049\n",
      "483 / 960 = Acc: 50.3125 %, loss: 4.990148067474365\n",
      "512 / 1024 = Acc: 50.0 %, loss: 5.152621746063232\n",
      "546 / 1084 = Acc: 50.3690036900369 %, loss: 4.873102188110352\n",
      "34 / 64 = Acc: 53.125 %, loss: 4.9880051612854\n",
      "70 / 128 = Acc: 54.6875 %, loss: 4.931430339813232\n",
      "105 / 192 = Acc: 54.6875 %, loss: 4.8459978103637695\n",
      "134 / 256 = Acc: 52.34375 %, loss: 5.097803115844727\n",
      "166 / 320 = Acc: 51.875 %, loss: 4.987271308898926\n",
      "203 / 384 = Acc: 52.864583333333336 %, loss: 4.821056365966797\n",
      "228 / 448 = Acc: 50.892857142857146 %, loss: 5.047043800354004\n",
      "258 / 512 = Acc: 50.390625 %, loss: 4.920270919799805\n",
      "291 / 576 = Acc: 50.520833333333336 %, loss: 4.915302753448486\n",
      "325 / 640 = Acc: 50.78125 %, loss: 4.9870781898498535\n",
      "362 / 704 = Acc: 51.42045454545455 %, loss: 4.781156063079834\n",
      "393 / 768 = Acc: 51.171875 %, loss: 5.031867980957031\n",
      "426 / 832 = Acc: 51.20192307692308 %, loss: 4.868494510650635\n",
      "457 / 896 = Acc: 51.004464285714285 %, loss: 4.9470014572143555\n",
      "488 / 960 = Acc: 50.833333333333336 %, loss: 5.000857353210449\n",
      "520 / 1024 = Acc: 50.78125 %, loss: 5.020989418029785\n",
      "549 / 1084 = Acc: 50.64575645756457 %, loss: 5.013802528381348\n",
      "32 / 64 = Acc: 50.0 %, loss: 4.933229446411133\n",
      "65 / 128 = Acc: 50.78125 %, loss: 4.873136043548584\n",
      "95 / 192 = Acc: 49.479166666666664 %, loss: 4.9762959480285645\n",
      "128 / 256 = Acc: 50.0 %, loss: 4.802751541137695\n",
      "160 / 320 = Acc: 50.0 %, loss: 5.051769733428955\n",
      "193 / 384 = Acc: 50.260416666666664 %, loss: 4.981357574462891\n",
      "224 / 448 = Acc: 50.0 %, loss: 4.983696937561035\n",
      "257 / 512 = Acc: 50.1953125 %, loss: 4.999831199645996\n",
      "288 / 576 = Acc: 50.0 %, loss: 4.979626655578613\n",
      "317 / 640 = Acc: 49.53125 %, loss: 5.063031196594238\n",
      "359 / 704 = Acc: 50.99431818181818 %, loss: 4.73103666305542\n",
      "393 / 768 = Acc: 51.171875 %, loss: 4.974794387817383\n",
      "432 / 832 = Acc: 51.92307692307692 %, loss: 4.756962776184082\n",
      "467 / 896 = Acc: 52.120535714285715 %, loss: 4.964114189147949\n",
      "500 / 960 = Acc: 52.083333333333336 %, loss: 4.994246959686279\n",
      "525 / 1024 = Acc: 51.26953125 %, loss: 5.053496360778809\n",
      "551 / 1084 = Acc: 50.830258302583026 %, loss: 5.070384502410889\n",
      "35 / 64 = Acc: 54.6875 %, loss: 4.848666191101074\n",
      "61 / 128 = Acc: 47.65625 %, loss: 5.149595260620117\n",
      "99 / 192 = Acc: 51.5625 %, loss: 4.759207725524902\n",
      "129 / 256 = Acc: 50.390625 %, loss: 4.9719414710998535\n",
      "161 / 320 = Acc: 50.3125 %, loss: 4.949962139129639\n",
      "191 / 384 = Acc: 49.739583333333336 %, loss: 5.0573201179504395\n",
      "221 / 448 = Acc: 49.330357142857146 %, loss: 4.894030570983887\n",
      "257 / 512 = Acc: 50.1953125 %, loss: 4.918218612670898\n",
      "288 / 576 = Acc: 50.0 %, loss: 4.949706554412842\n",
      "325 / 640 = Acc: 50.78125 %, loss: 4.830729961395264\n",
      "352 / 704 = Acc: 50.0 %, loss: 5.07528018951416\n",
      "385 / 768 = Acc: 50.130208333333336 %, loss: 4.967143535614014\n",
      "420 / 832 = Acc: 50.48076923076923 %, loss: 4.929871082305908\n",
      "454 / 896 = Acc: 50.669642857142854 %, loss: 5.017261028289795\n",
      "489 / 960 = Acc: 50.9375 %, loss: 4.911882400512695\n",
      "520 / 1024 = Acc: 50.78125 %, loss: 5.04272985458374\n",
      "552 / 1084 = Acc: 50.92250922509225 %, loss: 4.911603927612305\n",
      "32 / 64 = Acc: 50.0 %, loss: 4.981965065002441\n",
      "55 / 128 = Acc: 42.96875 %, loss: 5.056246757507324\n",
      "90 / 192 = Acc: 46.875 %, loss: 4.792182922363281\n",
      "121 / 256 = Acc: 47.265625 %, loss: 4.951200485229492\n",
      "158 / 320 = Acc: 49.375 %, loss: 4.899814605712891\n",
      "197 / 384 = Acc: 51.302083333333336 %, loss: 4.87365198135376\n",
      "237 / 448 = Acc: 52.901785714285715 %, loss: 4.7586188316345215\n",
      "275 / 512 = Acc: 53.7109375 %, loss: 4.86978816986084\n",
      "312 / 576 = Acc: 54.166666666666664 %, loss: 4.904241561889648\n",
      "341 / 640 = Acc: 53.28125 %, loss: 4.849820613861084\n",
      "374 / 704 = Acc: 53.125 %, loss: 4.860104560852051\n",
      "402 / 768 = Acc: 52.34375 %, loss: 5.098970413208008\n",
      "433 / 832 = Acc: 52.04326923076923 %, loss: 5.005882263183594\n",
      "465 / 896 = Acc: 51.89732142857143 %, loss: 4.981261730194092\n",
      "505 / 960 = Acc: 52.604166666666664 %, loss: 4.875264644622803\n",
      "539 / 1024 = Acc: 52.63671875 %, loss: 4.94683837890625\n",
      "569 / 1084 = Acc: 52.49077490774908 %, loss: 5.071198463439941\n",
      "36 / 64 = Acc: 56.25 %, loss: 4.811944961547852\n",
      "71 / 128 = Acc: 55.46875 %, loss: 4.896366596221924\n",
      "101 / 192 = Acc: 52.604166666666664 %, loss: 4.971510887145996\n",
      "142 / 256 = Acc: 55.46875 %, loss: 4.7457170486450195\n",
      "178 / 320 = Acc: 55.625 %, loss: 4.900352478027344\n",
      "210 / 384 = Acc: 54.6875 %, loss: 4.977801322937012\n",
      "242 / 448 = Acc: 54.017857142857146 %, loss: 5.0095133781433105\n",
      "269 / 512 = Acc: 52.5390625 %, loss: 5.0043044090271\n",
      "303 / 576 = Acc: 52.604166666666664 %, loss: 4.946568965911865\n",
      "338 / 640 = Acc: 52.8125 %, loss: 4.987483024597168\n",
      "368 / 704 = Acc: 52.27272727272727 %, loss: 4.902609825134277\n",
      "391 / 768 = Acc: 50.911458333333336 %, loss: 5.198105335235596\n",
      "428 / 832 = Acc: 51.44230769230769 %, loss: 4.939978122711182\n",
      "457 / 896 = Acc: 51.004464285714285 %, loss: 5.117718696594238\n",
      "485 / 960 = Acc: 50.520833333333336 %, loss: 5.016761779785156\n",
      "526 / 1024 = Acc: 51.3671875 %, loss: 4.763460636138916\n",
      "560 / 1084 = Acc: 51.66051660516605 %, loss: 4.757016658782959\n",
      "35 / 64 = Acc: 54.6875 %, loss: 5.024995803833008\n",
      "55 / 128 = Acc: 42.96875 %, loss: 5.231229305267334\n",
      "88 / 192 = Acc: 45.833333333333336 %, loss: 4.91025447845459\n",
      "122 / 256 = Acc: 47.65625 %, loss: 4.826671600341797\n",
      "151 / 320 = Acc: 47.1875 %, loss: 5.027556419372559\n",
      "185 / 384 = Acc: 48.177083333333336 %, loss: 4.981049537658691\n",
      "224 / 448 = Acc: 50.0 %, loss: 4.794020175933838\n",
      "259 / 512 = Acc: 50.5859375 %, loss: 4.80306339263916\n",
      "294 / 576 = Acc: 51.041666666666664 %, loss: 4.830840110778809\n",
      "327 / 640 = Acc: 51.09375 %, loss: 5.0136494636535645\n",
      "364 / 704 = Acc: 51.70454545454545 %, loss: 4.888805389404297\n",
      "393 / 768 = Acc: 51.171875 %, loss: 5.106790065765381\n",
      "428 / 832 = Acc: 51.44230769230769 %, loss: 4.882506370544434\n",
      "460 / 896 = Acc: 51.339285714285715 %, loss: 4.9237060546875\n",
      "499 / 960 = Acc: 51.979166666666664 %, loss: 4.704432964324951\n",
      "528 / 1024 = Acc: 51.5625 %, loss: 5.06813907623291\n",
      "559 / 1084 = Acc: 51.56826568265683 %, loss: 5.0631632804870605\n",
      "37 / 64 = Acc: 57.8125 %, loss: 4.851539611816406\n",
      "70 / 128 = Acc: 54.6875 %, loss: 4.94880485534668\n",
      "106 / 192 = Acc: 55.208333333333336 %, loss: 4.798879146575928\n",
      "144 / 256 = Acc: 56.25 %, loss: 4.905763149261475\n",
      "175 / 320 = Acc: 54.6875 %, loss: 5.029050350189209\n",
      "210 / 384 = Acc: 54.6875 %, loss: 4.893026828765869\n",
      "247 / 448 = Acc: 55.13392857142857 %, loss: 4.834837436676025\n",
      "282 / 512 = Acc: 55.078125 %, loss: 4.928414344787598\n",
      "310 / 576 = Acc: 53.81944444444444 %, loss: 4.9487223625183105\n",
      "336 / 640 = Acc: 52.5 %, loss: 5.063242435455322\n",
      "365 / 704 = Acc: 51.84659090909091 %, loss: 5.067750930786133\n",
      "407 / 768 = Acc: 52.994791666666664 %, loss: 4.714749813079834\n",
      "439 / 832 = Acc: 52.76442307692308 %, loss: 4.954786777496338\n",
      "475 / 896 = Acc: 53.013392857142854 %, loss: 4.894430637359619\n",
      "516 / 960 = Acc: 53.75 %, loss: 4.712573051452637\n",
      "554 / 1024 = Acc: 54.1015625 %, loss: 4.839422225952148\n",
      "591 / 1084 = Acc: 54.52029520295203 %, loss: 5.032153606414795\n",
      "38 / 64 = Acc: 59.375 %, loss: 4.936163902282715\n",
      "73 / 128 = Acc: 57.03125 %, loss: 5.0029144287109375\n",
      "110 / 192 = Acc: 57.291666666666664 %, loss: 4.881295204162598\n",
      "148 / 256 = Acc: 57.8125 %, loss: 4.785822868347168\n",
      "181 / 320 = Acc: 56.5625 %, loss: 4.91933536529541\n",
      "216 / 384 = Acc: 56.25 %, loss: 4.812469005584717\n",
      "248 / 448 = Acc: 55.357142857142854 %, loss: 4.894754409790039\n",
      "283 / 512 = Acc: 55.2734375 %, loss: 4.929177284240723\n",
      "311 / 576 = Acc: 53.99305555555556 %, loss: 5.118926525115967\n",
      "344 / 640 = Acc: 53.75 %, loss: 4.9895405769348145\n",
      "379 / 704 = Acc: 53.83522727272727 %, loss: 4.863668441772461\n",
      "409 / 768 = Acc: 53.255208333333336 %, loss: 5.016057014465332\n",
      "435 / 832 = Acc: 52.28365384615385 %, loss: 5.120450496673584\n",
      "479 / 896 = Acc: 53.45982142857143 %, loss: 4.652168273925781\n",
      "515 / 960 = Acc: 53.645833333333336 %, loss: 4.860744476318359\n",
      "549 / 1024 = Acc: 53.61328125 %, loss: 4.922665119171143\n",
      "580 / 1084 = Acc: 53.505535055350556 %, loss: 5.024415969848633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0)\n",
    "\n",
    "mean_acc = 0\n",
    "num_epochs = 20\n",
    "threshold = 0.8\n",
    "\n",
    "# dataset = HCU_Dataset(data_tensor_list, labels_tensor)\n",
    "# close_train_size = int(0.90 * len(dataset)) # 10 cross validationと合わせる\n",
    "# close_test_size = len(dataset) - close_train_size\n",
    "# close_train_set, close_test_set = torch.utils.data.random_split(dataset, [close_train_size, close_test_size])\n",
    "\n",
    "Unknown_label = close_num + 1\n",
    "\n",
    "# train_loader = DataLoader(dataset=close_train_set, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(dataset=close_test_set, batch_size=batch_size, shuffle=True) # to calculate validation loss randomly\n",
    "\n",
    "model = InceptionTime(1, close_num + 1) # 0-?+Unknownを出力\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "mb = master_bar(range(num_epochs))\n",
    "\n",
    "# Prepare the List\n",
    "all_train_features = []\n",
    "all_train_labels = []\n",
    "all_test_features = []\n",
    "all_test_labels = []\n",
    "training_epoch_loss = []\n",
    "validation_epoch_loss = []\n",
    "\n",
    "#****************************Train*************************************\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in mb:\n",
    "    model.train()\n",
    "    training_step_loss = []\n",
    "    for i, (signals, labels) in enumerate(progress_bar(train_loader, parent=mb)):\n",
    "        signals = torch.tensor(signals)\n",
    "        signals = signals.float()\n",
    "        signals = signals.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(signals)\n",
    "        outputs = outputs.to(device)\n",
    "        loss = triple_joint_loss(outputs, labels, alpha)\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_centloss.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in center_loss.parameters():\n",
    "            param.grad.data *= (1./alpha)\n",
    "        optimizer.step()\n",
    "        optimizer_centloss.step()\n",
    "        training_step_loss.append(loss.item())\n",
    "    mb.write(\"Finished Epoch: {0:02d}, Training Loss: {1:10.5f}\".format(epoch+1, loss.item()))\n",
    "    training_epoch_loss.append(np.array(training_step_loss).mean())\n",
    "\n",
    "\n",
    "#*******************************Test***********************************\n",
    "    model.eval()\n",
    "    # for threshold in thresholds:\n",
    "    predicted_lists = []\n",
    "    one_hot_labels_list = []\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        softmax = nn.Softmax()\n",
    "        for i, (signals, one_hot_labels) in enumerate(test_loader):\n",
    "            validation_step_loss = []\n",
    "            signals = torch.tensor(signals)\n",
    "            signals = signals.float()\n",
    "            signals = signals.to(device)\n",
    "            one_hot_labels = one_hot_labels.to(device)\n",
    "            outputs = model(signals)\n",
    "\n",
    "            for j, out in enumerate(outputs): # これ消すとthreshold処理がちゃんとできない\n",
    "                outputs[j] = softmax(out)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1) # predicted per batch size\n",
    "            \n",
    "            outputs_extend = []\n",
    "            for i in range(len(outputs)):\n",
    "                zero = torch.tensor([0]).to(device)\n",
    "                outputs_extend_row = torch.cat((outputs[i], zero), 0) # 0を後ろに追加，あとはつなげる\n",
    "                outputs_extend.append(outputs_extend_row)\n",
    "            outputs_extend = torch.stack(outputs_extend, dim=0)\n",
    "\n",
    "            for idx in range(len(_)):\n",
    "                if _[idx] < threshold: # maxの値を並べててしきい値以下なら15を代入\n",
    "                    predicted[idx] = Unknown_label # 15, 20, 25\n",
    "                    outputs_extend[idx, -1] = 1.0\n",
    "                    outputs_extend[idx, :-1] = 0.0\n",
    "\n",
    "            validation_loss = triple_joint_loss(outputs_extend, one_hot_labels, alpha, isTest=True)\n",
    "            validation_step_loss.append(validation_loss.item())\n",
    "\n",
    "            optimizer_centloss_test.zero_grad() # できればcenter_lossの学習も行わせたい\n",
    "            # for param in center_loss_test.parameters():\n",
    "            #     param.grad.data *= (1./alpha)\n",
    "            optimizer_centloss_test.step()\n",
    "            # show_2D_tSNE(outputs, one_hot_labels)\n",
    "\n",
    "            n_samples += one_hot_labels.size(0) # add batch_size\n",
    "            n_correct += (predicted == one_hot_labels).sum().item()\n",
    "            \n",
    "            predicted_cp = predicted.to('cpu').detach().numpy().copy()\n",
    "            one_hot_labels_cp = one_hot_labels.to('cpu').detach().numpy().copy()\n",
    "            predicted_lists = np.concatenate([predicted_lists, predicted_cp])\n",
    "            one_hot_labels_list = np.concatenate([one_hot_labels_list, one_hot_labels_cp])\n",
    "            \n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "            print(f'{n_correct} / {n_samples} = Acc: {acc} %, loss: {validation_loss}')\n",
    "\n",
    "        validation_epoch_loss.append(np.array(validation_step_loss).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_epoch_loss, label='train_loss')\n",
    "plt.plot(validation_epoch_loss,label='val_loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f0cee1d93a3f453c87d2fc7ea34167ba7e841aa689af4edcc0624fd2f7da055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
